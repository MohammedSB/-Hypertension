{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00000\",\n  \"config\": {\n    \"learning_rate\": 0.005,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 0.005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"0_batch_size=2,epochs=15,learning_rate=0.0050,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6955486851879674,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.024821043014526,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00000\",\n    \"experiment_id\": \"705f71f530324688a418567eb1fbdfd6\",\n    \"date\": \"2022-11-27_16-36-28\",\n    \"timestamp\": 1669556188,\n    \"time_total_s\": 479.3107557296753,\n    \"pid\": 26756,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.005,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 479.3107557296753,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.003251314163208008,\n    \"experiment_tag\": \"0_batch_size=2,epochs=15,learning_rate=0.0050,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669556188.2106016,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6990361661992521,\n      \"min\": 0.6890479193793403,\n      \"avg\": 0.6947445426571404,\n      \"last\": 0.6955486851879674,\n      \"last-5-avg\": 0.6946888328617454,\n      \"last-10-avg\": 0.6948402404785157\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324785,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.43460488319397,\n      \"min\": 31.395118951797485,\n      \"avg\": 31.954050381978348,\n      \"last\": 32.024821043014526,\n      \"last-5-avg\": 31.807511281967162,\n      \"last-10-avg\": 31.8244647026062\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 479.3107557296753,\n      \"min\": 33.43460488319397,\n      \"avg\": 256.519801012675,\n      \"last\": 479.3107557296753,\n      \"last-5-avg\": 415.6775887966156,\n      \"last-10-avg\": 336.1639555931091\n    },\n    \"time_since_restore\": {\n      \"max\": 479.3107557296753,\n      \"min\": 33.43460488319397,\n      \"avg\": 256.519801012675,\n      \"last\": 479.3107557296753,\n      \"last-5-avg\": 415.6775887966156,\n      \"last-10-avg\": 336.1639555931091\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.003251314163208008,\n      \"min\": 0.003251314163208008,\n      \"avg\": 0.003251314163208008,\n      \"last\": 0.003251314163208008,\n      \"last-5-avg\": 0.003251314163208008,\n      \"last-10-avg\": 0.003251314163208008\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62f3c2bc2bc2c473fe65c0578578578473fe60cae38e38e39473fe64c9532532532473fe641ef50f50f51652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe65e8118118118473fe61fa834834835473fe63ab13b13b13b473fe64df66d66d66d473fe62c0aaaaaaaab473fe62f3c2bc2bc2c473fe65c0578578578473fe60cae38e38e39473fe64c9532532532473fe641ef50f50f51652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740401598f000000047403f89012400000047403f65268400000047403fe9e918000000474040032d56000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ff2c53000000047403fe655ac00000047403fb34a3c00000047403fd21d0400000047403fd681c80000004740401598f000000047403f89012400000047403f65268400000047403fe9e918000000474040032d56000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076071224400000474077ffa236800000474079f5f49ec0000047407bf4933040000047407df4f8db000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406820763600000047406c1d40eb80000047407009d51980000047407206f6e9c00000474074045f06400000474076071224400000474077ffa236800000474079f5f49ec0000047407bf4933040000047407df4f8db000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076071224400000474077ffa236800000474079f5f49ec0000047407bf4933040000047407df4f8db000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406820763600000047406c1d40eb80000047407009d51980000047407206f6e9c00000474074045f06400000474076071224400000474077ffa236800000474079f5f49ec0000047407bf4933040000047407df4f8db000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000473f6aa28000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669555703.9929903,\n  \"relative_logdir\": \"tune_hp_5e0ed_00000_0_batch_size=2,epochs=15,learning_rate=0.0050,model=custom_2022-11-27_16-28-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00001\",\n  \"config\": {\n    \"learning_rate\": 0.005,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 0.005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"1_batch_size=4,epochs=15,learning_rate=0.0050,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6968615931323451,\n    \"accuracy\": 50.85470085470085,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.86904215812683,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00001\",\n    \"experiment_id\": \"24b47f148ab543d385d96a76bb6c478c\",\n    \"date\": \"2022-11-27_16-44-33\",\n    \"timestamp\": 1669556673,\n    \"time_total_s\": 480.3402259349823,\n    \"pid\": 23272,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.005,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 480.3402259349823,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"1_batch_size=4,epochs=15,learning_rate=0.0050,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669556673.4673529,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6971862010466747,\n      \"min\": 0.696198487893129,\n      \"avg\": 0.6967809606481481,\n      \"last\": 0.6968615931323451,\n      \"last-5-avg\": 0.6968409872462606,\n      \"last-10-avg\": 0.6967704512115217\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 50.85470085470085,\n      \"avg\": 50.85470085470084,\n      \"last\": 50.85470085470085,\n      \"last-5-avg\": 50.85470085470085,\n      \"last-10-avg\": 50.85470085470086\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.61014699935913,\n      \"min\": 31.464603662490845,\n      \"avg\": 32.02268172899882,\n      \"last\": 31.86904215812683,\n      \"last-5-avg\": 32.06456785202026,\n      \"last-10-avg\": 31.89645948410034\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 480.3402259349823,\n      \"min\": 33.61014699935913,\n      \"avg\": 256.8503925800323,\n      \"last\": 480.3402259349823,\n      \"last-5-avg\": 416.27985100746156,\n      \"last-10-avg\": 336.51945090293884\n    },\n    \"time_since_restore\": {\n      \"max\": 480.3402259349823,\n      \"min\": 33.61014699935913,\n      \"avg\": 256.8503925800323,\n      \"last\": 480.3402259349823,\n      \"last-5-avg\": 416.27985100746156,\n      \"last-10-avg\": 336.51945090293884\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe64b96f96f96f9473fe64dc690690690473fe64d596f96f970473fe64b33b13b13b1473fe64cb0af0af0af652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64c72bc2bc2bc473fe647420d20d20d473fe64ddf96f96f97473fe64b508c08c08c473fe64bef2df2df2e473fe64b96f96f96f9473fe64dc690690690473fe64d596f96f970473fe64b33b13b13b1473fe64cb0af0af0af652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040047ce400000047404023124a00000047403fe1ec2c0000004740402190c200000047403fde798c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040179d4000000047403f9805cc00000047403f76f04400000047403fd3a0f400000047403f927894000000474040047ce400000047404023124a00000047403fe1ec2c0000004740402190c200000047403fde798c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407600d6d3c0000047407805391d00000047407a0357dfc0000047407c0789f800000047407e057190c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406831ec7b80000047406c24ed3500000047407009e59ec00000474072071fae00000047407400473740000047407600d6d3c0000047407805391d00000047407a0357dfc0000047407c0789f800000047407e057190c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407600d6d3c0000047407805391d00000047407a0357dfc0000047407c0789f800000047407e057190c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406831ec7b80000047406c24ed3500000047407009e59ec00000474072071fae00000047407400473740000047407600d6d3c0000047407805391d00000047407a0357dfc0000047407c0789f800000047407e057190c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669556189.1080668,\n  \"relative_logdir\": \"tune_hp_5e0ed_00001_1_batch_size=4,epochs=15,learning_rate=0.0050,model=custom_2022-11-27_16-36-29\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00015\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"15_batch_size=16,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6899843134431758,\n    \"accuracy\": 46.15384615384615,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.05546307563782,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00015\",\n    \"experiment_id\": \"b725b11e17d144a894950d6103e75ac1\",\n    \"date\": \"2022-11-27_18-39-16\",\n    \"timestamp\": 1669563556,\n    \"time_total_s\": 491.89654660224915,\n    \"pid\": 26524,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 491.89654660224915,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"15_batch_size=16,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669563556.4867527,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6904112987029247,\n      \"min\": 0.6897804716713408,\n      \"avg\": 0.6900303462971311,\n      \"last\": 0.6899843134431758,\n      \"last-5-avg\": 0.6899713499933227,\n      \"last-10-avg\": 0.6900468418740818\n    },\n    \"accuracy\": {\n      \"max\": 46.15384615384615,\n      \"min\": 46.15384615384615,\n      \"avg\": 46.15384615384616,\n      \"last\": 46.15384615384615,\n      \"last-5-avg\": 46.15384615384615,\n      \"last-10-avg\": 46.153846153846146\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.93115496635437,\n      \"min\": 31.868494987487793,\n      \"avg\": 32.79310310681661,\n      \"last\": 32.05546307563782,\n      \"last-5-avg\": 32.239909934997556,\n      \"last-10-avg\": 32.258857536315915\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 491.89654660224915,\n      \"min\": 34.93115496635437,\n      \"avg\": 265.45920939445494,\n      \"last\": 491.89654660224915,\n      \"last-5-avg\": 427.36734766960143,\n      \"last-10-avg\": 346.7527152776718\n    },\n    \"time_since_restore\": {\n      \"max\": 491.89654660224915,\n      \"min\": 34.93115496635437,\n      \"avg\": 265.45920939445494,\n      \"last\": 491.89654660224915,\n      \"last-5-avg\": 427.36734766960143,\n      \"last-10-avg\": 346.7527152776718\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe61560f50f50f5473fe6141299299299473fe612ae7ee7ee7f473fe614bdf2df2df3473fe61459fb9fb9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe61659b59b59b6473fe6140e38e38e39473fe617d96f96f970473fe612edcfdcfdd0473fe61639fb9fb9fc473fe61560f50f50f5473fe6141299299299473fe612ae7ee7ee7f473fe614bdf2df2df3473fe61459fb9fb9fc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040134a300000004740400b091000000047404031194e0000004740404304e000000047404007196a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040172a14000000474040232da40000004740403f17120000004740401d1a860000004740401b4248000000474040134a300000004740400b091000000047404031194e0000004740404304e000000047404007196a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076ad902c400000474078aef14e40000047407ab5147800000047407cbd751400000047407ebe5841400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740692fa56b80000047406d3870d4800000474070a41b4c800000474072a7be9d400000474074ab26e6400000474076ad902c400000474078aef14e40000047407ab5147800000047407cbd751400000047407ebe5841400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076ad902c400000474078aef14e40000047407ab5147800000047407cbd751400000047407ebe5841400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740692fa56b80000047406d3870d4800000474070a41b4c800000474072a7be9d400000474074ab26e6400000474076ad902c400000474078aef14e40000047407ab5147800000047407cbd751400000047407ebe5841400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669563060.7317429,\n  \"relative_logdir\": \"tune_hp_5e0ed_00015_15_batch_size=16,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-31-00\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00005\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"5_batch_size=4,epochs=15,learning_rate=0.0010,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6964146540715144,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.015503875968992248,\n    \"time_this_iter_s\": 32.071863889694214,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00005\",\n    \"experiment_id\": \"240f0f164c1c4c20ba8b3305e777f92f\",\n    \"date\": \"2022-11-27_17-17-31\",\n    \"timestamp\": 1669558651,\n    \"time_total_s\": 478.5404567718506,\n    \"pid\": 25192,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 478.5404567718506,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"5_batch_size=4,epochs=15,learning_rate=0.0010,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669558651.1744466,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6981917161207932,\n      \"min\": 0.6943628686106104,\n      \"avg\": 0.6960524817137975,\n      \"last\": 0.6964146540715144,\n      \"last-5-avg\": 0.695919656345987,\n      \"last-10-avg\": 0.6960702423356536\n    },\n    \"accuracy\": {\n      \"max\": 46.58119658119658,\n      \"min\": 45.2991452991453,\n      \"avg\": 45.840455840455846,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.769230769230774\n    },\n    \"f1_score\": {\n      \"max\": 0.031007751937984496,\n      \"min\": 0.015384615384615385,\n      \"avg\": 0.01655436588427341,\n      \"last\": 0.015503875968992248,\n      \"last-5-avg\": 0.015504621347644604,\n      \"last-10-avg\": 0.017042896541443052\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.274203062057495,\n      \"min\": 31.430609464645386,\n      \"avg\": 31.902697118123367,\n      \"last\": 32.071863889694214,\n      \"last-5-avg\": 31.98722424507141,\n      \"last-10-avg\": 31.883938026428222\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 478.5404567718506,\n      \"min\": 33.274203062057495,\n      \"avg\": 255.2347225824992,\n      \"last\": 478.5404567718506,\n      \"last-5-avg\": 414.4535442829132,\n      \"last-10-avg\": 334.5872356891632\n    },\n    \"time_since_restore\": {\n      \"max\": 478.5404567718506,\n      \"min\": 33.274203062057495,\n      \"avg\": 255.2347225824992,\n      \"last\": 478.5404567718506,\n      \"last-5-avg\": 414.4535442829132,\n      \"last-10-avg\": 334.5872356891632\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe63f73d43d43d4473fe65416b36b36b3473fe644141a41a41a473fe638387a87a87b473fe6490762762762652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6426785785785473fe64ccf50f50f51473fe63b6aaaaaaaab473fe64c4b36b36b37473fe64e47cb7cb7cb473fe63f73d43d43d4473fe65416b36b36b3473fe644141a41a41a473fe638387a87a87b473fe6490762762762652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b474046a64a64a64a65474046a64a64a64a6547404713b13b13b13b474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046a64a64a64a654740474a64a64a64a647404713b13b13b13b474046a64a64a64a65474046dcfdcfdcfdd047404713b13b13b13b474046a64a64a64a65474046a64a64a64a6547404713b13b13b13b474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000903f94869452946807680d430820f8811ff8818f3f94869452946807680d430820f8811ff8818f3f94869452946807680d4308000000000000903f94869452946807680d4308f007fc017fc08f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430820f8811ff8818f3f94869452946807680d4308f007fc017fc09f3f94869452946807680d4308000000000000903f94869452946807680d430820f8811ff8818f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d4308000000000000903f94869452946807680d430820f8811ff8818f3f94869452946807680d430820f8811ff8818f3f94869452946807680d4308000000000000903f94869452946807680d4308f007fc017fc08f3f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fe23fd400000047403fda8d500000004740400b1e80000000474040051aea0000004740400932d6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f6e3c6c00000047403f9a45cc00000047403fd6176000000047403ffe3ad40000004740400533c800000047403fe23fd400000047403fda8d500000004740400b1e80000000474040051aea0000004740400932d6000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e7cf59000000474077e5782e000000474079e6dbfe00000047407be77f5b40000047407de8a5b6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067e436c580000047406bd77f7f00000047406fd2426b000000474071e904e2c00000474073e9ab5bc00000474075e7cf59000000474077e5782e000000474079e6dbfe00000047407be77f5b40000047407de8a5b6000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e7cf59000000474077e5782e000000474079e6dbfe00000047407be77f5b40000047407de8a5b6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067e436c580000047406bd77f7f00000047406fd2426b000000474071e904e2c00000474073e9ab5bc00000474075e7cf59000000474077e5782e000000474079e6dbfe00000047407be77f5b40000047407de8a5b6000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669558168.6661732,\n  \"relative_logdir\": \"tune_hp_5e0ed_00005_5_batch_size=4,epochs=15,learning_rate=0.0010,model=custom_2022-11-27_17-09-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00011\",\n  \"config\": {\n    \"learning_rate\": 0.0005,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"11_batch_size=16,epochs=15,learning_rate=0.0005,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7034832555004674,\n    \"accuracy\": 41.88034188034188,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.65003848075867,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00011\",\n    \"experiment_id\": \"85190084b64f4c57a04b53b34bd0345f\",\n    \"date\": \"2022-11-27_18-06-25\",\n    \"timestamp\": 1669561585,\n    \"time_total_s\": 486.4024634361267,\n    \"pid\": 9740,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0005,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 486.4024634361267,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"11_batch_size=16,epochs=15,learning_rate=0.0005,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669561585.2873604,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7035126645340879,\n      \"min\": 0.7034438695663061,\n      \"avg\": 0.7034690574363427,\n      \"last\": 0.7034832555004674,\n      \"last-5-avg\": 0.7034592587723691,\n      \"last-10-avg\": 0.7034627213437332\n    },\n    \"accuracy\": {\n      \"max\": 41.88034188034188,\n      \"min\": 41.88034188034188,\n      \"avg\": 41.880341880341874,\n      \"last\": 41.88034188034188,\n      \"last-5-avg\": 41.88034188034188,\n      \"last-10-avg\": 41.880341880341874\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.43096876144409,\n      \"min\": 31.853342533111572,\n      \"avg\": 32.42683089574179,\n      \"last\": 32.65003848075867,\n      \"last-5-avg\": 32.84338488578796,\n      \"last-10-avg\": 32.4855795621872\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 486.4024634361267,\n      \"min\": 33.118343114852905,\n      \"avg\": 258.7692543665568,\n      \"last\": 486.4024634361267,\n      \"last-5-avg\": 420.9904811859131,\n      \"last-10-avg\": 339.46514563560487\n    },\n    \"time_since_restore\": {\n      \"max\": 486.4024634361267,\n      \"min\": 33.118343114852905,\n      \"avg\": 258.7692543665568,\n      \"last\": 486.4024634361267,\n      \"last-5-avg\": 420.9904811859131,\n      \"last-10-avg\": 339.46514563560487\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe682c7ee7ee7ee473fe682bb13b13b14473fe682a1ea1ea1ea473fe6829cb7cb7cb8473fe682ef50f50f51652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe682ab7cb7cb7d473fe682d627627627473fe682f87a87a87b473fe682cb36b36b37473fe682b43d43d43d473fe682c7ee7ee7ee473fe682bb13b13b14473fe682a1ea1ea1ea473fe6829cb7cb7cb8473fe682ef50f50f51652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408718100000004740406931d4000000474040b729fc000000474040211bd8000000474040533476000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401f18f00000004740401f602e00000047403fe2174800000047403fda74a80000004740403507720000004740408718100000004740406931d4000000474040b729fc000000474040211bd8000000474040533476000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407633daf9c0000047407841013440000047407a57e673c0000047407c5c09eec0000047407e66707d800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406839448980000047406c411c950000004740701eafbf0000004740721c570980000047407422f7f7c0000047407633daf9c0000047407841013440000047407a57e673c0000047407c5c09eec0000047407e66707d800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407633daf9c0000047407841013440000047407a57e673c0000047407c5c09eec0000047407e66707d800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406839448980000047406c411c950000004740701eafbf0000004740721c570980000047407422f7f7c0000047407633daf9c0000047407841013440000047407a57e673c0000047407c5c09eec0000047407e66707d800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669561094.948327,\n  \"relative_logdir\": \"tune_hp_5e0ed_00011_11_batch_size=16,epochs=15,learning_rate=0.0005,model=custom_2022-11-27_17-58-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00006\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"6_batch_size=8,epochs=15,learning_rate=0.0010,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6936573126377203,\n    \"accuracy\": 50.85470085470085,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.10179328918457,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00006\",\n    \"experiment_id\": \"6274c7f3d11f4fbb8ecc68ebb4c1b887\",\n    \"date\": \"2022-11-27_17-25-38\",\n    \"timestamp\": 1669559138,\n    \"time_total_s\": 482.72967004776,\n    \"pid\": 13760,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 482.72967004776,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"6_batch_size=8,epochs=15,learning_rate=0.0010,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669559138.199954,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6936681372487646,\n      \"min\": 0.6936305119441106,\n      \"avg\": 0.6936475270154469,\n      \"last\": 0.6936573126377203,\n      \"last-5-avg\": 0.6936521611661993,\n      \"last-10-avg\": 0.6936497549725394\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 50.85470085470085,\n      \"avg\": 50.85470085470084,\n      \"last\": 50.85470085470085,\n      \"last-5-avg\": 50.85470085470085,\n      \"last-10-avg\": 50.85470085470086\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.55582571029663,\n      \"min\": 31.541237354278564,\n      \"avg\": 32.181978003184,\n      \"last\": 32.10179328918457,\n      \"last-5-avg\": 32.07148976325989,\n      \"last-10-avg\": 32.049653601646426\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 482.72967004776,\n      \"min\": 33.55582571029663,\n      \"avg\": 258.37676917711894,\n      \"last\": 482.72967004776,\n      \"last-5-avg\": 418.74598107337954,\n      \"last-10-avg\": 338.5640773534775\n    },\n    \"time_since_restore\": {\n      \"max\": 482.72967004776,\n      \"min\": 33.55582571029663,\n      \"avg\": 258.37676917711894,\n      \"last\": 482.72967004776,\n      \"last-5-avg\": 418.74598107337954,\n      \"last-10-avg\": 338.5640773534775\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6324acdacdace473fe632764a64a64a473fe6327c4ec4ec4f473fe6324fdcfdcfdd473fe63270d20d20d2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6328785785785473fe6324325325325473fe632543d43d43d473fe6323fb9fb9fba473fe6326cfdcfdcfe473fe6324acdacdace473fe632764a64a64a473fe6327c4ec4ec4f473fe6324fdcfdcfdd473fe63270d20d20d2652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040270738000000474040332ed800000047403f8a8e88000000474040013bfe0000004740400d0790000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040173d4c00000047403fe214f000000047404015322600000047403fe6384c00000047404001378c000000474040270738000000474040332ed800000047403f8a8e88000000474040013bfe0000004740400d0790000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762ad585400000474078313b6040000047407a29e448c0000047407c2a0bc880000047407e2bacba800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684d452880000047406c4987c6800000474070276a2800000047407225cdacc0000047407425f49e4000004740762ad585400000474078313b6040000047407a29e448c0000047407c2a0bc880000047407e2bacba800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762ad585400000474078313b6040000047407a29e448c0000047407c2a0bc880000047407e2bacba800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684d452880000047406c4987c6800000474070276a2800000047407225cdacc0000047407425f49e4000004740762ad585400000474078313b6040000047407a29e448c0000047407c2a0bc880000047407e2bacba800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669558651.5652578,\n  \"relative_logdir\": \"tune_hp_5e0ed_00006_6_batch_size=8,epochs=15,learning_rate=0.0010,model=custom_2022-11-27_17-17-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00009\",\n  \"config\": {\n    \"learning_rate\": 0.0005,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"9_batch_size=4,epochs=15,learning_rate=0.0005,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6950696635450053,\n    \"accuracy\": 54.27350427350427,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.82168173789978,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00009\",\n    \"experiment_id\": \"d3ab9f7377af4f75aa9a71317871b695\",\n    \"date\": \"2022-11-27_17-50-04\",\n    \"timestamp\": 1669560604,\n    \"time_total_s\": 488.0419337749481,\n    \"pid\": 19684,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0005,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 488.0419337749481,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"9_batch_size=4,epochs=15,learning_rate=0.0005,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669560604.0826075,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6957261175171942,\n      \"min\": 0.694691649868957,\n      \"avg\": 0.695245952551861,\n      \"last\": 0.6950696635450053,\n      \"last-5-avg\": 0.6952950893304287,\n      \"last-10-avg\": 0.6951759077544905\n    },\n    \"accuracy\": {\n      \"max\": 54.27350427350427,\n      \"min\": 54.27350427350427,\n      \"avg\": 54.27350427350427,\n      \"last\": 54.27350427350427,\n      \"last-5-avg\": 54.27350427350427,\n      \"last-10-avg\": 54.27350427350427\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.47776412963867,\n      \"min\": 31.82168173789978,\n      \"avg\": 32.53612891832987,\n      \"last\": 31.82168173789978,\n      \"last-5-avg\": 32.14615669250488,\n      \"last-10-avg\": 32.5277539730072\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 488.0419337749481,\n      \"min\": 33.41564893722534,\n      \"avg\": 261.3199122111003,\n      \"last\": 488.0419337749481,\n      \"last-5-avg\": 424.14917821884154,\n      \"last-10-avg\": 343.0287616014481\n    },\n    \"time_since_restore\": {\n      \"max\": 488.0419337749481,\n      \"min\": 33.41564893722534,\n      \"avg\": 261.3199122111003,\n      \"last\": 488.0419337749481,\n      \"last-5-avg\": 424.14917821884154,\n      \"last-10-avg\": 343.0287616014481\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6405c94c94c95473fe6405857857858473fe63f34ec4ec4ec473fe6415cdacdacdb473fe63e02bc2bc2bc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe63fa785785785473fe6424762762762473fe63ae9fb9fb9fc473fe63d7690690690473fe63b3690690690473fe6405c94c94c95473fe6405857857858473fe63f34ec4ec4ec473fe6415cdacdacdb473fe63e02bc2bc2bc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b230230230230652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b23023023023047404b230230230230652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740406b031c00000047404003198000000047403ffe64d0000000474040070e6e00000047403fd259bc000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040bd27600000004740409b4d5a0000004740402f3da60000004740407123f60000004740404d25c60000004740406b031c00000047404003198000000047403ffe64d0000000474040070e6e00000047403fd259bc000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076825adc40000047407882be0c40000047407a82a45940000047407c83862700000047407e80abc2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406887bfc280000047406cae93190000004740705d31414000004740726b55c000000047407474fa78c00000474076825adc40000047407882be0c40000047407a82a45940000047407c83862700000047407e80abc2c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076825adc40000047407882be0c40000047407a82a45940000047407c83862700000047407e80abc2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406887bfc280000047406cae93190000004740705d31414000004740726b55c000000047407474fa78c00000474076825adc40000047407882be0c40000047407a82a45940000047407c83862700000047407e80abc2c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669560111.9013138,\n  \"relative_logdir\": \"tune_hp_5e0ed_00009_9_batch_size=4,epochs=15,learning_rate=0.0005,model=custom_2022-11-27_17-41-51\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00012\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"12_batch_size=2,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6891179533086271,\n    \"accuracy\": 45.2991452991453,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.94626212120056,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00012\",\n    \"experiment_id\": \"93ed37e4c8ca4b8da430f24ff23b80e3\",\n    \"date\": \"2022-11-27_18-14-26\",\n    \"timestamp\": 1669562066,\n    \"time_total_s\": 477.27905440330505,\n    \"pid\": 27896,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 477.27905440330505,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"12_batch_size=2,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669562066.9404147,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6898790669237447,\n      \"min\": 0.6881919926048344,\n      \"avg\": 0.6890268266031206,\n      \"last\": 0.6891179533086271,\n      \"last-5-avg\": 0.6888924231896033,\n      \"last-10-avg\": 0.6890600155561398\n    },\n    \"accuracy\": {\n      \"max\": 45.2991452991453,\n      \"min\": 45.2991452991453,\n      \"avg\": 45.299145299145295,\n      \"last\": 45.2991452991453,\n      \"last-5-avg\": 45.2991452991453,\n      \"last-10-avg\": 45.29914529914531\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.80703258514404,\n      \"min\": 31.556315898895264,\n      \"avg\": 31.818603626887004,\n      \"last\": 31.94626212120056,\n      \"last-5-avg\": 31.740462398529054,\n      \"last-10-avg\": 31.69502122402191\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 477.27905440330505,\n      \"min\": 33.80703258514404,\n      \"avg\": 255.35885661443078,\n      \"last\": 477.27905440330505,\n      \"last-5-avg\": 413.6610777378082,\n      \"last-10-avg\": 334.50661702156066\n    },\n    \"time_since_restore\": {\n      \"max\": 477.27905440330505,\n      \"min\": 33.80703258514404,\n      \"avg\": 255.35885661443078,\n      \"last\": 477.27905440330505,\n      \"last-5-avg\": 413.6610777378082,\n      \"last-10-avg\": 334.50661702156066\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe605ab36b36b37473fe60bc0af0af0af473fe60d94ec4ec4ec473fe60cc6b36b36b3473fe60d4118118118652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe60f6dcfdcfdd0473fe60c77a87a87a8473fe60f6483483483473fe60e220d20d20d473fe60d573f73f73f473fe605ab36b36b37473fe60bc0af0af0af473fe60d94ec4ec4ec473fe60cc6b36b36b3473fe60d4118118118652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fa660f000000047403fa6892400000047403fb666b400000047403fbe3bb400000047403ff23e3c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fb6239800000047403fb2404400000047403faa3f4000000047403f9a938400000047403f923fc400000047403fa660f000000047403fa6892400000047403fb666b400000047403fbe3bb400000047403ff23e3c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e3a065400000474077de08f7800000474079d96f62c0000047407bd5531e00000047407dd47701c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068014a5300000047406bf7925b80000047406fecda43800000474071f0165a000000474073e93a56400000474075e3a065400000474077de08f7800000474079d96f62c0000047407bd5531e00000047407dd47701c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e3a065400000474077de08f7800000474079d96f62c0000047407bd5531e00000047407dd47701c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068014a5300000047406bf7925b80000047406fecda43800000474071f0165a000000474073e93a56400000474075e3a065400000474077de08f7800000474079d96f62c0000047407bd5531e00000047407dd47701c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669561585.7719128,\n  \"relative_logdir\": \"tune_hp_5e0ed_00012_12_batch_size=2,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-06-25\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00014\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"14_batch_size=8,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6923609676524105,\n    \"accuracy\": 52.991452991452995,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 33.55677795410156,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00014\",\n    \"experiment_id\": \"43991cc6f54d41879c269b71dd0fb918\",\n    \"date\": \"2022-11-27_18-31-00\",\n    \"timestamp\": 1669563060,\n    \"time_total_s\": 501.8975713253021,\n    \"pid\": 26628,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 501.8975713253021,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"14_batch_size=8,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669563060.4974241,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6951747796474359,\n      \"min\": 0.689634013379741,\n      \"avg\": 0.692411930268986,\n      \"last\": 0.6923609676524105,\n      \"last-5-avg\": 0.6919402163252871,\n      \"last-10-avg\": 0.6924371311807225\n    },\n    \"accuracy\": {\n      \"max\": 52.991452991452995,\n      \"min\": 52.991452991452995,\n      \"avg\": 52.99145299145298,\n      \"last\": 52.991452991452995,\n      \"last-5-avg\": 52.99145299145299,\n      \"last-10-avg\": 52.99145299145299\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.774643898010254,\n      \"min\": 32.961037397384644,\n      \"avg\": 33.45983808835348,\n      \"last\": 33.55677795410156,\n      \"last-5-avg\": 33.50601344108581,\n      \"last-10-avg\": 33.55427017211914\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 501.8975713253021,\n      \"min\": 33.477872371673584,\n      \"avg\": 267.22873152097065,\n      \"last\": 501.8975713253021,\n      \"last-5-avg\": 434.80085735321046,\n      \"last-10-avg\": 350.9677786588669\n    },\n    \"time_since_restore\": {\n      \"max\": 501.8975713253021,\n      \"min\": 33.477872371673584,\n      \"avg\": 267.22873152097065,\n      \"last\": 501.8975713253021,\n      \"last-5-avg\": 434.80085735321046,\n      \"last-10-avg\": 350.9677786588669\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe621cf73f73f74473fe61dc0af0af0af473fe61e613b13b13b473fe6301b7cb7cb7d473fe627d230230230652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe63edf2df2df2e473fe62b7e38e38e39473fe6263762762762473fe631d9fb9fb9fc473fe61c2555555555473fe621cf73f73f74473fe61dc0af0af0af473fe61e613b13b13b473fe6301b7cb7cb7d473fe627d230230230652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040ad1274000000474040bf4446000000474040cf2ab4000000474040c11350000000474040c74480000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040cd382c000000474040cf1c0c000000474040cd2250000000474040b4fff2000000474040e32788000000474040ad1274000000474040bf4446000000474040cf2ab4000000474040c11350000000474040c74480000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076fb839a800000474079136c2340000047407b2d5179c0000047407d4573e3c0000047407f5e5c73c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068fea92280000047406d327025800000474070b2dc5cc00000474072c97c5b000000474074e5e14c000000474076fb839a800000474079136c2340000047407b2d5179c0000047407d4573e3c0000047407f5e5c73c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076fb839a800000474079136c2340000047407b2d5179c0000047407d4573e3c0000047407f5e5c73c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068fea92280000047406d327025800000474070b2dc5cc00000474072c97c5b000000474074e5e14c000000474076fb839a800000474079136c2340000047407b2d5179c0000047407d4573e3c0000047407f5e5c73c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669562554.6164148,\n  \"relative_logdir\": \"tune_hp_5e0ed_00014_14_batch_size=8,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-22-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00007\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"7_batch_size=16,epochs=15,learning_rate=0.0010,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6942049988314637,\n    \"accuracy\": 51.70940170940172,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.851654052734375,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00007\",\n    \"experiment_id\": \"6f0bf9a9145a4c5994688785b35345f0\",\n    \"date\": \"2022-11-27_17-33-49\",\n    \"timestamp\": 1669559629,\n    \"time_total_s\": 487.28262424468994,\n    \"pid\": 26244,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 487.28262424468994,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"7_batch_size=16,epochs=15,learning_rate=0.0010,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669559629.591003,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6942176492805154,\n      \"min\": 0.6941554403712606,\n      \"avg\": 0.6941882098162616,\n      \"last\": 0.6942049988314637,\n      \"last-5-avg\": 0.6942065899188702,\n      \"last-10-avg\": 0.6941934047601162\n    },\n    \"accuracy\": {\n      \"max\": 51.70940170940172,\n      \"min\": 51.70940170940172,\n      \"avg\": 51.70940170940171,\n      \"last\": 51.70940170940172,\n      \"last-5-avg\": 51.70940170940172,\n      \"last-10-avg\": 51.70940170940172\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.618852615356445,\n      \"min\": 32.0237500667572,\n      \"avg\": 32.485508282979325,\n      \"last\": 32.851654052734375,\n      \"last-5-avg\": 32.43101458549499,\n      \"last-10-avg\": 32.36403980255127\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 487.28262424468994,\n      \"min\": 33.618852615356445,\n      \"avg\": 260.4696082909902,\n      \"last\": 487.28262424468994,\n      \"last-5-avg\": 422.2084578990936,\n      \"last-10-avg\": 341.41159291267394\n    },\n    \"time_since_restore\": {\n      \"max\": 487.28262424468994,\n      \"min\": 33.618852615356445,\n      \"avg\": 260.4696082909902,\n      \"last\": 487.28262424468994,\n      \"last-5-avg\": 422.2084578990936,\n      \"last-10-avg\": 341.41159291267394\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe63706d66d66d6473fe636e50f50f50f473fe63707ee7ee7ee473fe636d276276276473fe636ed66d66d67652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe636b555555555473fe6368578578578473fe636adacdacdad473fe63700af0af0af473fe636b604604604473fe63706d66d66d6473fe636e50f50f50f473fe63707ee7ee7ee473fe636d276276276473fe636ed66d66d67652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040252c1e0000004740404344a4000000474040030a3e0000004740403b5b6e0000004740406d0300000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402940c40000004740402d2bd000000047404029550000000047404031170c0000004740400d4682000000474040252c1e0000004740404344a4000000474040030a3e0000004740403b5b6e0000004740406d0300000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407656aff70000004740785f188b80000047407a5f79d340000047407c66e54100000047407e7485a1000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740687edd4f00000047406c8a28430000004740704a3ec18000004740725061a3000000474074520a7340000047407656aff70000004740785f188b80000047407a5f79d340000047407c66e54100000047407e7485a1000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407656aff70000004740785f188b80000047407a5f79d340000047407c66e54100000047407e7485a1000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740687edd4f00000047406c8a28430000004740704a3ec18000004740725061a3000000474074520a7340000047407656aff70000004740785f188b80000047407a5f79d340000047407c66e54100000047407e7485a1000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669559138.4811642,\n  \"relative_logdir\": \"tune_hp_5e0ed_00007_7_batch_size=16,epochs=15,learning_rate=0.0010,model=custom_2022-11-27_17-25-38\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00003\",\n  \"config\": {\n    \"learning_rate\": 0.005,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 0.005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"3_batch_size=16,epochs=15,learning_rate=0.0050,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6846190884581997,\n    \"accuracy\": 49.572649572649574,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.961493730545044,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00003\",\n    \"experiment_id\": \"78cc8a606e39443f8d301903653f1892\",\n    \"date\": \"2022-11-27_17-01-28\",\n    \"timestamp\": 1669557688,\n    \"time_total_s\": 507.38003039360046,\n    \"pid\": 27280,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.005,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 507.38003039360046,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"3_batch_size=16,epochs=15,learning_rate=0.0050,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669557688.0394728,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6928368592873598,\n      \"min\": 0.6836513291057359,\n      \"avg\": 0.6889372040403534,\n      \"last\": 0.6846190884581997,\n      \"last-5-avg\": 0.6881379869249132,\n      \"last-10-avg\": 0.6885764749641092\n    },\n    \"accuracy\": {\n      \"max\": 49.572649572649574,\n      \"min\": 49.572649572649574,\n      \"avg\": 49.57264957264957,\n      \"last\": 49.572649572649574,\n      \"last-5-avg\": 49.572649572649574,\n      \"last-10-avg\": 49.57264957264958\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.664313077926636,\n      \"min\": 32.961493730545044,\n      \"avg\": 33.82533535957336,\n      \"last\": 32.961493730545044,\n      \"last-5-avg\": 33.808762073516846,\n      \"last-10-avg\": 33.8211633682251\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 507.38003039360046,\n      \"min\": 34.664313077926636,\n      \"avg\": 270.96812477111814,\n      \"last\": 507.38003039360046,\n      \"last-5-avg\": 440.3063733577728,\n      \"last-10-avg\": 355.4861501455307\n    },\n    \"time_since_restore\": {\n      \"max\": 507.38003039360046,\n      \"min\": 34.664313077926636,\n      \"avg\": 270.96812477111814,\n      \"last\": 507.38003039360046,\n      \"last-5-avg\": 440.3063733577728,\n      \"last-10-avg\": 355.4861501455307\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5ed6785785785473fe6265a64a64a65473fe6172e5be5be5c473fe606cb36b36b37473fe5e8664a64a64a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6168df2df2df3473fe5f6bc71c71c72473fe6249230230230473fe62bb834834835473fe5e078c08c08c1473fe5ed6785785785473fe6265a64a64a65473fe6172e5be5be5c473fe606cb36b36b37473fe5e8664a64a64a652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404103380400000047404154fb1e000000474040a922b60000004740410933820000004740407b123a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040f8fb7a000000474040f3291c000000474040d33c42000000474040c50e5e000000474041110c0600000047404103380400000047404154fb1e000000474040a922b60000004740410933820000004740407b123a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407745c828c0000047407970678c80000047407b858be340000047407da6b25380000047407fb6149ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406963a26000000047406da06ca7000000474070ea9ddbc00000474073033fa780000047407525612840000047407745c828c0000047407970678c80000047407b858be340000047407da6b25380000047407fb6149ac00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407745c828c0000047407970678c80000047407b858be340000047407da6b25380000047407fb6149ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406963a26000000047406da06ca7000000474070ea9ddbc00000474073033fa780000047407525612840000047407745c828c0000047407970678c80000047407b858be340000047407da6b25380000047407fb6149ac00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669557176.676032,\n  \"relative_logdir\": \"tune_hp_5e0ed_00003_3_batch_size=16,epochs=15,learning_rate=0.0050,model=custom_2022-11-27_16-52-56\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00010\",\n  \"config\": {\n    \"learning_rate\": 0.0005,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"10_batch_size=8,epochs=15,learning_rate=0.0005,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6928802229400374,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.211159229278564,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00010\",\n    \"experiment_id\": \"a4595ba6cf0a4266ab72ec0adf984642\",\n    \"date\": \"2022-11-27_17-58-14\",\n    \"timestamp\": 1669561094,\n    \"time_total_s\": 485.1951243877411,\n    \"pid\": 16800,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0005,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 485.1951243877411,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"10_batch_size=8,epochs=15,learning_rate=0.0005,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669561094.9170835,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6928895477555755,\n      \"min\": 0.6927781716371194,\n      \"avg\": 0.6928335858206461,\n      \"last\": 0.6928802229400374,\n      \"last-5-avg\": 0.6928400675455728,\n      \"last-10-avg\": 0.6928309513972357\n    },\n    \"accuracy\": {\n      \"max\": 48.29059829059829,\n      \"min\": 48.29059829059829,\n      \"avg\": 48.29059829059828,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 48.29059829059829,\n      \"last-10-avg\": 48.29059829059828\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.491894006729126,\n      \"min\": 31.680060386657715,\n      \"avg\": 32.34634162584941,\n      \"last\": 32.211159229278564,\n      \"last-5-avg\": 31.94011583328247,\n      \"last-10-avg\": 32.030805706977844\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 485.1951243877411,\n      \"min\": 34.491894006729126,\n      \"avg\": 260.78836619059246,\n      \"last\": 485.1951243877411,\n      \"last-5-avg\": 421.25958795547484,\n      \"last-10-avg\": 341.299479341507\n    },\n    \"time_since_restore\": {\n      \"max\": 485.1951243877411,\n      \"min\": 34.491894006729126,\n      \"avg\": 260.78836619059246,\n      \"last\": 485.1951243877411,\n      \"last-5-avg\": 421.25958795547484,\n      \"last-10-avg\": 341.299479341507\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62b9b59b59b5a473fe62b61a41a41a4473fe62bddf2df2df3473fe62bcc94c94c95473fe62c1325325325652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe62b966d66d66d473fe62bdfdcfdcfdd473fe62b9cfdcfdcfe473fe62b3d20d20d21473fe62bab13b13b14473fe62b9b59b59b5a473fe62b61a41a41a4473fe62bddf2df2df3473fe62bcc94c94c95473fe62c1325325325652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040013f0000000047403fce6f3c00000047403ffe44f400000047403fae18700000004740401b0744000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404033194e00000047403ffea2b400000047403fea3fb40000004740401f1e940000004740400718c0000000474040013f0000000047403fce6f3c00000047403ffe44f400000047403fae18700000004740401b0744000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407658118840000047407854f87c00000047407a54dccb40000047407c4fbe5240000047407e531f3ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a9292e80000047406ca8fd850000004740705322bdc0000047407257069040000047407457e9a840000047407658118840000047407854f87c00000047407a54dccb40000047407c4fbe5240000047407e531f3ac00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407658118840000047407854f87c00000047407a54dccb40000047407c4fbe5240000047407e531f3ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a9292e80000047406ca8fd850000004740705322bdc0000047407257069040000047407457e9a840000047407658118840000047407854f87c00000047407a54dccb40000047407c4fbe5240000047407e531f3ac00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669560605.8793726,\n  \"relative_logdir\": \"tune_hp_5e0ed_00010_10_batch_size=8,epochs=15,learning_rate=0.0005,model=custom_2022-11-27_17-50-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00016\",\n  \"config\": {\n    \"learning_rate\": 5e-05,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"16_batch_size=2,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6938067705203326,\n    \"accuracy\": 51.70940170940172,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.49490213394165,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00016\",\n    \"experiment_id\": \"2f75307e58bb4709a440b2edb831ae40\",\n    \"date\": \"2022-11-27_18-47-16\",\n    \"timestamp\": 1669564036,\n    \"time_total_s\": 475.6231417655945,\n    \"pid\": 25996,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-05,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 475.6231417655945,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"16_batch_size=2,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669564036.4103763,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6938346797584468,\n      \"min\": 0.693766602084168,\n      \"avg\": 0.6938085833166399,\n      \"last\": 0.6938067705203326,\n      \"last-5-avg\": 0.6938004322541065,\n      \"last-10-avg\": 0.6938057337051783\n    },\n    \"accuracy\": {\n      \"max\": 51.70940170940172,\n      \"min\": 51.70940170940172,\n      \"avg\": 51.70940170940171,\n      \"last\": 51.70940170940172,\n      \"last-5-avg\": 51.70940170940172,\n      \"last-10-avg\": 51.70940170940172\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.46089053153992,\n      \"min\": 31.36817455291748,\n      \"avg\": 31.708209451039632,\n      \"last\": 31.49490213394165,\n      \"last-5-avg\": 31.540749740600585,\n      \"last-10-avg\": 31.579659199714662\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 475.6231417655945,\n      \"min\": 33.46089053153992,\n      \"avg\": 254.61569987932842,\n      \"last\": 475.6231417655945,\n      \"last-5-avg\": 412.6160152435303,\n      \"last-10-avg\": 333.6163682699204\n    },\n    \"time_since_restore\": {\n      \"max\": 475.6231417655945,\n      \"min\": 33.46089053153992,\n      \"avg\": 254.61569987932842,\n      \"last\": 475.6231417655945,\n      \"last-5-avg\": 412.6160152435303,\n      \"last-10-avg\": 333.6163682699204\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6339cb7cb7cb8473fe633a762762762473fe6339b9fb9fba0473fe63386d66d66d6473fe633aa41a41a42652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe633da1ea1ea1f473fe633e4c94c94c9473fe633b483483483473fe6335604604604473fe633b690690690473fe6339cb7cb7cb8473fe633a762762762473fe6339b9fb9fba0473fe63386d66d66d6473fe633aa41a41a42652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae474049dacdacdacdae652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fc263b000000047403f5e40b000000047403f8e60e000000047403f8671b800000047403f7eb1e8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403faa589c00000047403f766c8800000047403f823fb800000047403fca7f5c00000047403faa405c00000047403fc263b000000047403f5e40b000000047403f8e60e000000047403f8671b800000047403f7eb1e8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075dadc10800000474077d0c01b800000474079c9a62980000047407bc20d4500000047407db9f863800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067efbe2c00000047406bde8bbd00000047406fced3b4000000474071e411cfc00000474073deb5d5800000474075dadc10800000474077d0c01b800000474079c9a62980000047407bc20d4500000047407db9f863800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075dadc10800000474077d0c01b800000474079c9a62980000047407bc20d4500000047407db9f863800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067efbe2c00000047406bde8bbd00000047406fced3b4000000474071e411cfc00000474073deb5d5800000474075dadc10800000474077d0c01b800000474079c9a62980000047407bc20d4500000047407db9f863800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669563556.8286457,\n  \"relative_logdir\": \"tune_hp_5e0ed_00016_16_batch_size=2,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-39-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00013\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"13_batch_size=4,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7005230504223424,\n    \"accuracy\": 52.991452991452995,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.305683851242065,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00013\",\n    \"experiment_id\": \"cf559d703b1f48e29635154c44bb74f3\",\n    \"date\": \"2022-11-27_18-22-34\",\n    \"timestamp\": 1669562554,\n    \"time_total_s\": 483.16140580177307,\n    \"pid\": 27032,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 483.16140580177307,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"13_batch_size=4,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669562554.5851438,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7005679790790265,\n      \"min\": 0.7005132039388021,\n      \"avg\": 0.7005291278545673,\n      \"last\": 0.7005230504223424,\n      \"last-5-avg\": 0.7005279801849625,\n      \"last-10-avg\": 0.7005285409780649\n    },\n    \"accuracy\": {\n      \"max\": 52.991452991452995,\n      \"min\": 52.991452991452995,\n      \"avg\": 52.99145299145298,\n      \"last\": 52.991452991452995,\n      \"last-5-avg\": 52.99145299145299,\n      \"last-10-avg\": 52.99145299145299\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.82072925567627,\n      \"min\": 31.57096838951111,\n      \"avg\": 32.21076038678487,\n      \"last\": 32.305683851242065,\n      \"last-5-avg\": 32.13406858444214,\n      \"last-10-avg\": 32.0744423866272\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 483.16140580177307,\n      \"min\": 33.82072925567627,\n      \"avg\": 258.393183072408,\n      \"last\": 483.16140580177307,\n      \"last-5-avg\": 418.8497176170349,\n      \"last-10-avg\": 338.5852394580841\n    },\n    \"time_since_restore\": {\n      \"max\": 483.16140580177307,\n      \"min\": 33.82072925567627,\n      \"avg\": 258.393183072408,\n      \"last\": 483.16140580177307,\n      \"last-5-avg\": 418.8497176170349,\n      \"last-10-avg\": 338.5852394580841\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe66ab555555555473fe66ad38e38e38e473fe66ab43d43d43d473fe66ab3d43d43d4473fe66aaf50f50f51652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe66a9aaaaaaaab473fe66a9d20d20d21473fe66aa64a64a64a473fe66ac069069069473fe66b0d89d89d8a473fe66ab555555555473fe66ad38e38e38e473fe66ab43d43d43d473fe66ab3d43d43d4473fe66aaf50f50f51652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040171aa80000004740400749480000004740400d2c84000000474040031cb20000004740402720a6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040090920000000474040032f9600000047403f922afc00000047403ff222f80000004740403b1bcc000000474040171aa80000004740400749480000004740400d2c84000000474040031cb20000004740402720a6000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762abeb9c000004740782ba7e2c0000047407a2d4d7340000047407c2db10980000047407e32951e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684f9a3280000047406c5066180000004740702155bbc000004740722077eb40000047407427db64c000004740762abeb9c000004740782ba7e2c0000047407a2d4d7340000047407c2db10980000047407e32951e400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762abeb9c000004740782ba7e2c0000047407a2d4d7340000047407c2db10980000047407e32951e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684f9a3280000047406c5066180000004740702155bbc000004740722077eb40000047407427db64c000004740762abeb9c000004740782ba7e2c0000047407a2d4d7340000047407c2db10980000047407e32951e400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669562067.5497549,\n  \"relative_logdir\": \"tune_hp_5e0ed_00013_13_batch_size=4,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-14-27\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00008\",\n  \"config\": {\n    \"learning_rate\": 0.0005,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 0.0005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"8_batch_size=2,epochs=15,learning_rate=0.0005,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6888783120701456,\n    \"accuracy\": 46.58119658119658,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.60291862487793,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00008\",\n    \"experiment_id\": \"716da809ae984d2b8012d5934c7757d8\",\n    \"date\": \"2022-11-27_17-41-50\",\n    \"timestamp\": 1669560110,\n    \"time_total_s\": 476.43639612197876,\n    \"pid\": 1248,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0005,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 476.43639612197876,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015603065490722656,\n    \"experiment_tag\": \"8_batch_size=2,epochs=15,learning_rate=0.0005,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669560110.448245,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6888783120701456,\n      \"min\": 0.686331528883714,\n      \"avg\": 0.6875554880864941,\n      \"last\": 0.6888783120701456,\n      \"last-5-avg\": 0.6879220946222289,\n      \"last-10-avg\": 0.6876204596625434\n    },\n    \"accuracy\": {\n      \"max\": 47.008547008547005,\n      \"min\": 46.15384615384615,\n      \"avg\": 46.581196581196565,\n      \"last\": 46.58119658119658,\n      \"last-5-avg\": 46.32478632478633,\n      \"last-10-avg\": 46.45299145299145\n    },\n    \"f1_score\": {\n      \"max\": 0.015873015873015872,\n      \"min\": 0.0,\n      \"avg\": 0.005282672999208432,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0015873015873015873\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.617953062057495,\n      \"min\": 31.36885714530945,\n      \"avg\": 31.762426408131915,\n      \"last\": 31.60291862487793,\n      \"last-5-avg\": 31.525075006484986,\n      \"last-10-avg\": 31.57334449291229\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 476.43639612197876,\n      \"min\": 33.617953062057495,\n      \"avg\": 255.26980547904964,\n      \"last\": 476.43639612197876,\n      \"last-5-avg\": 413.2361694335938,\n      \"last-10-avg\": 334.35642354488374\n    },\n    \"time_since_restore\": {\n      \"max\": 476.43639612197876,\n      \"min\": 33.617953062057495,\n      \"avg\": 255.26980547904964,\n      \"last\": 476.43639612197876,\n      \"last-5-avg\": 413.2361694335938,\n      \"last-10-avg\": 334.35642354488374\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015603065490722656,\n      \"min\": 0.015603065490722656,\n      \"avg\": 0.015603065490722656,\n      \"last\": 0.015603065490722656,\n      \"last-5-avg\": 0.015603065490722656,\n      \"last-10-avg\": 0.015603065490722656\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60346b36b36b3473fe5ff5118118118473fe5fc5118118118473fe6071690690690473fe60b4a87a87a88652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5f66d89d89d8a473fe6075046046046473fe6038a41a41a42473fe5fc4348348348473fe5fb08e38e38e4473fe60346b36b36b3473fe5ff5118118118473fe5fc5118118118473fe6071690690690473fe60b4a87a87a88652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b4740474a64a64a64a647404713b13b13b13b47404713b13b13b13b4740474a64a64a64a6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740478118118118114740474a64a64a64a64740474a64a64a64a647404713b13b13b13b4740474a64a64a64a647404713b13b13b13b4740474a64a64a64a647404713b13b13b13b47404713b13b13b13b4740474a64a64a64a6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308100441100441903f94869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f5e6d6c00000047403f7a6ff800000047403f6a302000000047403fc2b23000000047403f9a58e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f7e1cb000000047403fbe609400000047403f6e6ee000000047403fb241fc00000047403fbe7c5800000047403f5e6d6c00000047403f7a6ff800000047403f6a302000000047403fc2b23000000047403f9a58e0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e2e0c8000000474077da87c7800000474079d12ac980000047407bcd55ec80000047407dc6fb7a800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406806422980000047406bfe0e3c00000047406febdc18000000474071f1122bc00000474073ecf9f1400000474075e2e0c8000000474077da87c7800000474079d12ac980000047407bcd55ec80000047407dc6fb7a800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e2e0c8000000474077da87c7800000474079d12ac980000047407bcd55ec80000047407dc6fb7a800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406806422980000047406bfe0e3c00000047406febdc18000000474071f1122bc00000474073ecf9f1400000474075e2e0c8000000474077da87c7800000474079d12ac980000047407bcd55ec80000047407dc6fb7a800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000473f8ff48000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669559630.1693118,\n  \"relative_logdir\": \"tune_hp_5e0ed_00008_8_batch_size=2,epochs=15,learning_rate=0.0005,model=custom_2022-11-27_17-33-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00002\",\n  \"config\": {\n    \"learning_rate\": 0.005,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 0.005,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"2_batch_size=8,epochs=15,learning_rate=0.0050,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6979991554195045,\n    \"accuracy\": 44.871794871794876,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 33.69565010070801,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00002\",\n    \"experiment_id\": \"ec607149b7d240a9ad5562f63415a61e\",\n    \"date\": \"2022-11-27_16-52-56\",\n    \"timestamp\": 1669557176,\n    \"time_total_s\": 498.25666213035583,\n    \"pid\": 15356,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.005,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 498.25666213035583,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015618085861206055,\n    \"experiment_tag\": \"2_batch_size=8,epochs=15,learning_rate=0.0050,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669557176.238606,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6983332837748731,\n      \"min\": 0.6979561178093283,\n      \"avg\": 0.6980994982597154,\n      \"last\": 0.6979991554195045,\n      \"last-5-avg\": 0.6980313553769364,\n      \"last-10-avg\": 0.6980896256927751\n    },\n    \"accuracy\": {\n      \"max\": 44.871794871794876,\n      \"min\": 44.871794871794876,\n      \"avg\": 44.87179487179488,\n      \"last\": 44.871794871794876,\n      \"last-5-avg\": 44.871794871794876,\n      \"last-10-avg\": 44.87179487179487\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.243857622146606,\n      \"min\": 31.75932288169861,\n      \"avg\": 33.217110808690386,\n      \"last\": 33.69565010070801,\n      \"last-5-avg\": 33.69588589668274,\n      \"last-10-avg\": 33.47805240154266\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 498.25666213035583,\n      \"min\": 34.05635595321655,\n      \"avg\": 264.0187582174937,\n      \"last\": 498.25666213035583,\n      \"last-5-avg\": 430.60284600257876,\n      \"last-10-avg\": 346.50596249103546\n    },\n    \"time_since_restore\": {\n      \"max\": 498.25666213035583,\n      \"min\": 34.05635595321655,\n      \"avg\": 264.0187582174937,\n      \"last\": 498.25666213035583,\n      \"last-5-avg\": 430.60284600257876,\n      \"last-10-avg\": 346.50596249103546\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015618085861206055,\n      \"min\": 0.015618085861206055,\n      \"avg\": 0.015618085861206055,\n      \"last\": 0.015618085861206055,\n      \"last-5-avg\": 0.015618085861206055,\n      \"last-10-avg\": 0.015618085861206055\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6572276276276473fe656a89d89d89e473fe655b785785785473fe655d857857858473fe6560253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe656fcfdcfdcfe473fe655a811811812473fe6576f0af0af0b473fe6575023023023473fe658bf0af0af0b473fe6572276276276473fe656a89d89d89e473fe655b785785785473fe655d857857858473fe6560253253253652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040cd2e5c0000004740408f16da000000474040e8fae20000004740411f12ca000000474040d90b10000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404005f1a00000004740408b301e000000474040aafe980000004740411f36ba000000474040cb3334000000474040cd2e5c0000004740408f16da000000474040e8fae20000004740411f12ca000000474040d90b10000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076b61557000000474078c7f83240000047407ae5178e80000047407d08f9e7c0000047407f241b49c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406870b8ee00000047406c9384f58000004740705f224dc000004740728309250000004740749c6f8b800000474076b61557000000474078c7f83240000047407ae5178e80000047407d08f9e7c0000047407f241b49c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076b61557000000474078c7f83240000047407ae5178e80000047407d08f9e7c0000047407f241b49c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406870b8ee00000047406c9384f58000004740705f224dc000004740728309250000004740749c6f8b800000474076b61557000000474078c7f83240000047407ae5178e80000047407d08f9e7c0000047407f241b49c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000473f8ffc6000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669556673.951614,\n  \"relative_logdir\": \"tune_hp_5e0ed_00002_2_batch_size=8,epochs=15,learning_rate=0.0050,model=custom_2022-11-27_16-44-33\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00004\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"4_batch_size=2,epochs=15,learning_rate=0.0010,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.693426018087273,\n    \"accuracy\": 49.14529914529914,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.477540254592896,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00004\",\n    \"experiment_id\": \"80136575e6ed4e9ca45139d2b3d9e038\",\n    \"date\": \"2022-11-27_17-09-28\",\n    \"timestamp\": 1669558168,\n    \"time_total_s\": 475.721572637558,\n    \"pid\": 23588,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 475.721572637558,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"4_batch_size=2,epochs=15,learning_rate=0.0010,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669558168.6349304,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6935623690613315,\n      \"min\": 0.6932810595911792,\n      \"avg\": 0.6934232010800615,\n      \"last\": 0.693426018087273,\n      \"last-5-avg\": 0.693434051774506,\n      \"last-10-avg\": 0.6934269570896767\n    },\n    \"accuracy\": {\n      \"max\": 49.14529914529914,\n      \"min\": 49.14529914529914,\n      \"avg\": 49.145299145299155,\n      \"last\": 49.14529914529914,\n      \"last-5-avg\": 49.14529914529914,\n      \"last-10-avg\": 49.14529914529914\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.930413007736206,\n      \"min\": 31.243481636047363,\n      \"avg\": 31.714771509170532,\n      \"last\": 31.477540254592896,\n      \"last-5-avg\": 31.425425577163697,\n      \"last-10-avg\": 31.484828853607176\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 475.721572637558,\n      \"min\": 33.930413007736206,\n      \"avg\": 255.40736606915792,\n      \"last\": 475.721572637558,\n      \"last-5-avg\": 412.9092168331146,\n      \"last-10-avg\": 334.2819339752197\n    },\n    \"time_since_restore\": {\n      \"max\": 475.721572637558,\n      \"min\": 33.930413007736206,\n      \"avg\": 255.40736606915792,\n      \"last\": 475.721572637558,\n      \"last-5-avg\": 412.9092168331146,\n      \"last-10-avg\": 334.2819339752197\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62fbdacdacdad473fe630541a41a41a473fe631a9b59b59b6473fe630c7cb7cb7cb473fe6308bc2bc2bc3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6317c71c71c72473fe6311e5be5be5c473fe62fab7cb7cb7d473fe630d834834835473fe62f5bc2bc2bc3473fe62fbdacdacdad473fe630541a41a41a473fe631a9b59b59b6473fe630c7cb7cb7cb473fe6308bc2bc2bc3652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f6aaf7800000047403f8ebc3000000047403f6e8ae800000047403f3e54d000000047403f7a4014000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fa2352800000047403fba673400000047403f72645c00000047403f92b56800000047403f56e7dc00000047403f6aaf7800000047403f8ebc3000000047403f6e8ae800000047403f3e54d000000047403f7a4014000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e02dd0000000474077d91993000000474079d0024180000047407bc3e78e80000047407dbb8b8fc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406810389680000047406c07857d00000047406ff5d208800000474071f4145ac00000474073e982d8800000474075e02dd0000000474077d91993000000474079d0024180000047407bc3e78e80000047407dbb8b8fc00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e02dd0000000474077d91993000000474079d0024180000047407bc3e78e80000047407dbb8b8fc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406810389680000047406c07857d00000047406ff5d208800000474071f4145ac00000474073e982d8800000474075e02dd0000000474077d91993000000474079d0024180000047407bc3e78e80000047407dbb8b8fc00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669557689.0395496,\n  \"relative_logdir\": \"tune_hp_5e0ed_00004_4_batch_size=2,epochs=15,learning_rate=0.0010,model=custom_2022-11-27_17-01-29\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00017\",\n  \"config\": {\n    \"learning_rate\": 5e-05,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"17_batch_size=4,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.696847899347289,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.15101718902588,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00017\",\n    \"experiment_id\": \"1b46effaaa894e35869040ee4c91d8e7\",\n    \"date\": \"2022-11-27_18-55-20\",\n    \"timestamp\": 1669564520,\n    \"time_total_s\": 479.79107093811035,\n    \"pid\": 24520,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-05,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 479.79107093811035,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"17_batch_size=4,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669564520.231782,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6973948030390291,\n      \"min\": 0.6959681714701856,\n      \"avg\": 0.6968035879977408,\n      \"last\": 0.696847899347289,\n      \"last-5-avg\": 0.696494377983941,\n      \"last-10-avg\": 0.6967657431578025\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.43589743589744,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.460861682891846,\n      \"min\": 31.64940881729126,\n      \"avg\": 31.986071395874017,\n      \"last\": 32.15101718902588,\n      \"last-5-avg\": 31.940715551376343,\n      \"last-10-avg\": 31.868582677841186\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 479.79107093811035,\n      \"min\": 33.460861682891846,\n      \"avg\": 256.5376741568248,\n      \"last\": 479.79107093811035,\n      \"last-5-avg\": 415.74670934677124,\n      \"last-10-avg\": 336.1377114057541\n    },\n    \"time_since_restore\": {\n      \"max\": 479.79107093811035,\n      \"min\": 33.460861682891846,\n      \"avg\": 256.5376741568248,\n      \"last\": 479.79107093811035,\n      \"last-5-avg\": 415.74670934677124,\n      \"last-10-avg\": 336.1377114057541\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe64930d20d20d2473fe64c4253253253473fe6455f0af0af0b473fe64902bc2bc2bc473fe64c93f73f73f7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64c6b7cb7cb7d473fe64e05e15e15e1473fe64fbfb9fb9fba473fe64c26b36b36b3473fe6504c08c08c09473fe64930d20d20d2473fe64c4253253253473fe6455f0af0af0b473fe64902bc2bc2bc473fe64c93f73f73f7652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fb660b000000047403ff24150000000474040014a7e00000047403fe23da0000000474040135488000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fca387400000047403fd64f4400000047403fda15c000000047403fc29aa400000047403fbe3c9000000047403fb660b000000047403ff24150000000474040014a7e00000047403fe23da0000000474040135488000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075fccc6a400000474077fbf07f400000474079fc19cf00000047407bfa3da900000047407dfca83a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740681ca53780000047406c176f200000004740700958ec00000047407205829640000047407401665f400000474075fccc6a400000474077fbf07f400000474079fc19cf00000047407bfa3da900000047407dfca83a000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075fccc6a400000474077fbf07f400000474079fc19cf00000047407bfa3da900000047407dfca83a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740681ca53780000047406c176f200000004740700958ec00000047407205829640000047407401665f400000474075fccc6a400000474077fbf07f400000474079fc19cf00000047407bfa3da900000047407dfca83a000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669564036.566616,\n  \"relative_logdir\": \"tune_hp_5e0ed_00017_17_batch_size=4,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-47-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00018\",\n  \"config\": {\n    \"learning_rate\": 5e-05,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"18_batch_size=8,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6937002198308961,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.665462255477905,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00018\",\n    \"experiment_id\": \"7920e6a82a964224898136dd6e294bd0\",\n    \"date\": \"2022-11-27_19-03-31\",\n    \"timestamp\": 1669565011,\n    \"time_total_s\": 486.93563866615295,\n    \"pid\": 24148,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-05,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 486.93563866615295,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"18_batch_size=8,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669565011.2602088,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6938413962339743,\n      \"min\": 0.6936490311581864,\n      \"avg\": 0.6937212300096823,\n      \"last\": 0.6937002198308961,\n      \"last-5-avg\": 0.6937195997971755,\n      \"last-10-avg\": 0.6937134375939003\n    },\n    \"accuracy\": {\n      \"max\": 45.72649572649573,\n      \"min\": 45.72649572649573,\n      \"avg\": 45.72649572649573,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.72649572649573\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.665029525756836,\n      \"min\": 31.977741956710815,\n      \"avg\": 32.462375911076855,\n      \"last\": 32.665462255477905,\n      \"last-5-avg\": 32.50645003318787,\n      \"last-10-avg\": 32.45466651916504\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 486.93563866615295,\n      \"min\": 33.665029525756836,\n      \"avg\": 259.9259770711263,\n      \"last\": 486.93563866615295,\n      \"last-5-avg\": 421.7789357185364,\n      \"last-10-avg\": 340.8145824432373\n    },\n    \"time_since_restore\": {\n      \"max\": 486.93563866615295,\n      \"min\": 33.665029525756836,\n      \"avg\": 259.9259770711263,\n      \"last\": 486.93563866615295,\n      \"last-5-avg\": 421.7789357185364,\n      \"last-10-avg\": 340.8145824432373\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6330e15e15e16473fe632dcb7cb7cb8473fe632e50f50f50f473fe6332690690690473fe632cacdacdace652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6325f73f73f74473fe63327ee7ee7ee473fe632b13b13b13b473fe6337c4ec4ec4f473fe6328b13b13b14473fe6330e15e15e16473fe632dcb7cb7cb8473fe632e50f50f50f473fe6332690690690473fe632cacdacdace652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040413fca000000474040292db6000000474040272b300000004740405d5a38000000474040552dde000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740406b023e0000004740403b423a00000047404013380c000000474040211c0a000000474040273fcc000000474040413fca000000474040292db6000000474040272b300000004740405d5a38000000474040552dde000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740764e9c40c0000047407853c1f780000047407a58a75d80000047407c6452a480000047407e6ef860400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406867330800000047406c7603968000004740703d68ccc00000474072418c4e0000004740744674478000004740764e9c40c0000047407853c1f780000047407a58a75d80000047407c6452a480000047407e6ef860400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740764e9c40c0000047407853c1f780000047407a58a75d80000047407c6452a480000047407e6ef860400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406867330800000047406c7603968000004740703d68ccc00000474072418c4e0000004740744674478000004740764e9c40c0000047407853c1f780000047407a58a75d80000047407c6452a480000047407e6ef860400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669564520.4192383,\n  \"relative_logdir\": \"tune_hp_5e0ed_00018_18_batch_size=8,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_18-55-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00019\",\n  \"config\": {\n    \"learning_rate\": 5e-05,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"19_batch_size=16,epochs=15,learning_rate=0.0001,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6907372759957598,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.930747270584106,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00019\",\n    \"experiment_id\": \"f7474f67c21a4a93bd79097108db9b3b\",\n    \"date\": \"2022-11-27_19-11-45\",\n    \"timestamp\": 1669565505,\n    \"time_total_s\": 489.82202672958374,\n    \"pid\": 21468,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-05,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 489.82202672958374,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015655517578125,\n    \"experiment_tag\": \"19_batch_size=16,epochs=15,learning_rate=0.0001,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669565505.9405296,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6907372759957598,\n      \"min\": 0.6904662694686499,\n      \"avg\": 0.6905922392494658,\n      \"last\": 0.6907372759957598,\n      \"last-5-avg\": 0.6905557746561165,\n      \"last-10-avg\": 0.6905874138204461\n    },\n    \"accuracy\": {\n      \"max\": 45.72649572649573,\n      \"min\": 45.72649572649573,\n      \"avg\": 45.72649572649573,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.72649572649573\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.211822271347046,\n      \"min\": 31.96316432952881,\n      \"avg\": 32.654801781972246,\n      \"last\": 32.930747270584106,\n      \"last-5-avg\": 32.643209552764894,\n      \"last-10-avg\": 32.649470043182376\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 489.82202672958374,\n      \"min\": 34.211822271347046,\n      \"avg\": 261.3971298694611,\n      \"last\": 489.82202672958374,\n      \"last-5-avg\": 424.4975634098053,\n      \"last-10-avg\": 342.7850593328476\n    },\n    \"time_since_restore\": {\n      \"max\": 489.82202672958374,\n      \"min\": 34.211822271347046,\n      \"avg\": 261.3971298694611,\n      \"last\": 489.82202672958374,\n      \"last-5-avg\": 424.4975634098053,\n      \"last-10-avg\": 342.7850593328476\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015655517578125,\n      \"min\": 0.015655517578125,\n      \"avg\": 0.015655517578125,\n      \"last\": 0.015655517578125,\n      \"last-5-avg\": 0.015655517578125,\n      \"last-10-avg\": 0.015655517578125\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe61889fb9fb9fc473fe61962df2df2df473fe6186b7cb7cb7d473fe6184cb7cb7cb8473fe61a850f50f50f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6196a1ea1ea1f473fe61a55be5be5be473fe61925be5be5be473fe6191acdacdace473fe619c13b13b13b473fe61889fb9fb9fc473fe61962df2df2df473fe6186b7cb7cb7d473fe6184cb7cb7cb8473fe61a850f50f50f652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040531b040000004740405904640000004740404f1730000000474040294e220000004740407722ba000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402326aa0000004740402d24a40000004740408915fc0000004740409312e00000004740403736ba000000474040531b040000004740405904640000004740404f1730000000474040294e220000004740407722ba000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740767415778000004740787f360400000047407a8918ea00000047407c8e42ae40000047407e9d2705800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406873431f80000047406c7e8c488000004740705068e3c0000047407262cb3fc0000047407469b2170000004740767415778000004740787f360400000047407a8918ea00000047407c8e42ae40000047407e9d2705800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740767415778000004740787f360400000047407a8918ea00000047407c8e42ae40000047407e9d2705800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406873431f80000047406c7e8c488000004740705068e3c0000047407262cb3fc0000047407469b2170000004740767415778000004740787f360400000047407a8918ea00000047407c8e42ae40000047407e9d2705800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669565012.1977832,\n  \"relative_logdir\": \"tune_hp_5e0ed_00019_19_batch_size=16,epochs=15,learning_rate=0.0001,model=custom_2022-11-27_19-03-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00020\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"20_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7194807916624933,\n    \"accuracy\": 41.452991452991455,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.775456428527832,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00020\",\n    \"experiment_id\": \"aa12cf89969947b19327d61209dee1c4\",\n    \"date\": \"2022-11-27_19-19-50\",\n    \"timestamp\": 1669565990,\n    \"time_total_s\": 480.42081332206726,\n    \"pid\": 25584,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 480.42081332206726,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"20_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669565990.672826,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7195254594851763,\n      \"min\": 0.7193833701630943,\n      \"avg\": 0.719452534645711,\n      \"last\": 0.7194807916624933,\n      \"last-5-avg\": 0.719452399881477,\n      \"last-10-avg\": 0.7194655328734307\n    },\n    \"accuracy\": {\n      \"max\": 41.452991452991455,\n      \"min\": 41.452991452991455,\n      \"avg\": 41.452991452991455,\n      \"last\": 41.452991452991455,\n      \"last-5-avg\": 41.452991452991455,\n      \"last-10-avg\": 41.452991452991455\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.710838317871094,\n      \"min\": 31.65069079399109,\n      \"avg\": 32.028054221471145,\n      \"last\": 31.775456428527832,\n      \"last-5-avg\": 31.884562683105468,\n      \"last-10-avg\": 31.925123858451844\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 480.42081332206726,\n      \"min\": 33.710838317871094,\n      \"avg\": 257.0940039952596,\n      \"last\": 480.42081332206726,\n      \"last-5-avg\": 416.70774350166323,\n      \"last-10-avg\": 336.9247192382812\n    },\n    \"time_since_restore\": {\n      \"max\": 480.42081332206726,\n      \"min\": 33.710838317871094,\n      \"avg\": 257.0940039952596,\n      \"last\": 480.42081332206726,\n      \"last-5-avg\": 416.70774350166323,\n      \"last-10-avg\": 336.9247192382812\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7059ee7ee7ee8473fe705ab13b13b14473fe705c578578578473fe705b92992992a473fe705fc94c94c95652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe705bdcfdcfdd0473fe7061a87a87a88473fe7065a41a41a42473fe705e069069069473fe705c59b59b59b473fe7059ee7ee7ee8473fe705ab13b13b14473fe705c578578578473fe705b92992992a473fe705fc94c94c95652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0474044b9fb9fb9fba0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ffe598400000047403fa693ac00000047404019271a00000047403fce7dcc00000047403fc68450000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040055996000000474040091a4400000047403fda3eac00000047403ff2551000000047403fea983c00000047403ffe598400000047403fa693ac00000047404019271a00000047403fce7dcc00000047403fc68450000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740760fdd670000004740780a46a1c0000047407a0d6b8500000047407c0a5361c0000047407e06bba6c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406826c38d80000047406c290a1e8000004740701228fa000000474072114e4b0000004740740ff7cec000004740760fdd670000004740780a46a1c0000047407a0d6b8500000047407c0a5361c0000047407e06bba6c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740760fdd670000004740780a46a1c0000047407a0d6b8500000047407c0a5361c0000047407e06bba6c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406826c38d80000047406c290a1e8000004740701228fa000000474072114e4b0000004740740ff7cec000004740760fdd670000004740780a46a1c0000047407a0d6b8500000047407c0a5361c0000047407e06bba6c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669565506.2842033,\n  \"relative_logdir\": \"tune_hp_5e0ed_00020_20_batch_size=2,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-11-46\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00021\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"21_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6917261629023104,\n    \"accuracy\": 46.15384615384615,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.72747278213501,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00021\",\n    \"experiment_id\": \"76d9dd2c94384d898800197dab9094f8\",\n    \"date\": \"2022-11-27_19-28-06\",\n    \"timestamp\": 1669566486,\n    \"time_total_s\": 491.9484598636627,\n    \"pid\": 26492,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 491.9484598636627,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"21_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669566486.8859162,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6917377048068576,\n      \"min\": 0.6916766696506076,\n      \"avg\": 0.6917145905671298,\n      \"last\": 0.6917261629023104,\n      \"last-5-avg\": 0.6917136559119592,\n      \"last-10-avg\": 0.6917100890069945\n    },\n    \"accuracy\": {\n      \"max\": 46.15384615384615,\n      \"min\": 46.15384615384615,\n      \"avg\": 46.15384615384616,\n      \"last\": 46.15384615384615,\n      \"last-5-avg\": 46.15384615384615,\n      \"last-10-avg\": 46.153846153846146\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.820616722106934,\n      \"min\": 32.16586256027222,\n      \"avg\": 32.796563990910855,\n      \"last\": 32.72747278213501,\n      \"last-5-avg\": 32.786849117279054,\n      \"last-10-avg\": 32.78248217105865\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 491.9484598636627,\n      \"min\": 33.820616722106934,\n      \"avg\": 262.6666986465454,\n      \"last\": 491.9484598636627,\n      \"last-5-avg\": 426.3062541484833,\n      \"last-10-avg\": 344.42570679187776\n    },\n    \"time_since_restore\": {\n      \"max\": 491.9484598636627,\n      \"min\": 33.820616722106934,\n      \"avg\": 262.6666986465454,\n      \"last\": 491.9484598636627,\n      \"last-5-avg\": 426.3062541484833,\n      \"last-10-avg\": 344.42570679187776\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62283b13b13b1473fe6229023023023473fe622ad89d89d8a473fe622371c71c71c473fe6229ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6223b9fb9fba0473fe6227a1ea1ea1f473fe622759b59b59b473fe6226b13b13b14473fe622b627627627473fe62283b13b13b1473fe6229023023023473fe622ad89d89d8a473fe622371c71c71c473fe6229ee7ee7ee8652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040632cd40000004740404b1924000000474040692228000000474040830f680000004740405d1dd4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740404b2d880000004740409b22ae000000474040553550000000474040733edc000000474040433a04000000474040632cd40000004740404b1924000000474040692228000000474040830f680000004740405d1dd4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768c9fd34000004740789602f7c0000047407aa3273cc0000047407cb38929c0000047407ebf2ce4400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406896c03a00000047406cbd88e5800000474070696b1cc0000047407277d2f8400000474074803a38c000004740768c9fd34000004740789602f7c0000047407aa3273cc0000047407cb38929c0000047407ebf2ce4400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768c9fd34000004740789602f7c0000047407aa3273cc0000047407cb38929c0000047407ebf2ce4400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406896c03a00000047406cbd88e5800000474070696b1cc0000047407277d2f8400000474074803a38c000004740768c9fd34000004740789602f7c0000047407aa3273cc0000047407cb38929c0000047407ebf2ce4400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669565991.0165014,\n  \"relative_logdir\": \"tune_hp_5e0ed_00021_21_batch_size=4,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-19-51\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00022\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"22_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6975190904405382,\n    \"accuracy\": 50.427350427350426,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.19614028930664,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00022\",\n    \"experiment_id\": \"56a11e6b0e7b4d49b7ea95281d50e10a\",\n    \"date\": \"2022-11-27_19-36-13\",\n    \"timestamp\": 1669566973,\n    \"time_total_s\": 483.1500012874603,\n    \"pid\": 22136,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 483.1500012874603,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"22_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669566973.9880815,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6975635626377203,\n      \"min\": 0.6975057226979834,\n      \"avg\": 0.6975268676410036,\n      \"last\": 0.6975190904405382,\n      \"last-5-avg\": 0.6975298107179821,\n      \"last-10-avg\": 0.6975218291975495\n    },\n    \"accuracy\": {\n      \"max\": 50.427350427350426,\n      \"min\": 50.427350427350426,\n      \"avg\": 50.42735042735043,\n      \"last\": 50.427350427350426,\n      \"last-5-avg\": 50.427350427350426,\n      \"last-10-avg\": 50.42735042735042\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.6795928478241,\n      \"min\": 31.775732040405273,\n      \"avg\": 32.210000085830686,\n      \"last\": 32.19614028930664,\n      \"last-5-avg\": 32.07130618095398,\n      \"last-10-avg\": 32.06055853366852\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 483.1500012874603,\n      \"min\": 33.6795928478241,\n      \"avg\": 258.57377250989276,\n      \"last\": 483.1500012874603,\n      \"last-5-avg\": 418.9761215209961,\n      \"last-10-avg\": 338.7553817272186\n    },\n    \"time_since_restore\": {\n      \"max\": 483.1500012874603,\n      \"min\": 33.6795928478241,\n      \"avg\": 258.57377250989276,\n      \"last\": 483.1500012874603,\n      \"last-5-avg\": 418.9761215209961,\n      \"last-10-avg\": 338.7553817272186\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe65206f96f96f9473fe65270d20d20d2473fe65234c94c94c9473fe652120d20d20d473fe652138e38e38e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe651f785785785473fe6520834834835473fe652350f50f50f473fe651fc2bc2bc2c473fe651f9d89d89d9473fe65206f96f96f9473fe65270d20d20d2473fe65234c94c94c9473fe652120d20d20d473fe652138e38e38e652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040111f060000004740400114b000000047403ffa6944000000474040051f56000000474040191b20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fc696600000004740400520740000004740401108be0000004740401b3e040000004740400b2e9e000000474040111f060000004740400114b000000047403ffa6944000000474040051f56000000474040191b20000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762ed5eec000004740782ef884c0000047407a2e9f1900000047407c2f4303c0000047407e326667c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684a3ea700000047406c4b86c400000047407027e479c000004740722b4c3a4000004740742cb20e0000004740762ed5eec000004740782ef884c0000047407a2e9f1900000047407c2f4303c0000047407e326667c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762ed5eec000004740782ef884c0000047407a2e9f1900000047407c2f4303c0000047407e326667c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740684a3ea700000047406c4b86c400000047407027e479c000004740722b4c3a4000004740742cb20e0000004740762ed5eec000004740782ef884c0000047407a2e9f1900000047407c2f4303c0000047407e326667c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669566486.901504,\n  \"relative_logdir\": \"tune_hp_5e0ed_00022_22_batch_size=8,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-28-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00023\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-05,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"23_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6882808065821981,\n    \"accuracy\": 44.871794871794876,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.46241879463196,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00023\",\n    \"experiment_id\": \"cd047c8198674b92be28666457486700\",\n    \"date\": \"2022-11-27_19-44-21\",\n    \"timestamp\": 1669567461,\n    \"time_total_s\": 482.92539501190186,\n    \"pid\": 22984,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 482.92539501190186,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"23_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669567461.5842786,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6882896749382346,\n      \"min\": 0.6882699819711539,\n      \"avg\": 0.6882825802534053,\n      \"last\": 0.6882808065821981,\n      \"last-5-avg\": 0.6882807022485977,\n      \"last-10-avg\": 0.6882826063368055\n    },\n    \"accuracy\": {\n      \"max\": 44.871794871794876,\n      \"min\": 44.871794871794876,\n      \"avg\": 44.87179487179488,\n      \"last\": 44.871794871794876,\n      \"last-5-avg\": 44.871794871794876,\n      \"last-10-avg\": 44.87179487179487\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.38533282279968,\n      \"min\": 31.868802547454834,\n      \"avg\": 32.19502633412679,\n      \"last\": 32.46241879463196,\n      \"last-5-avg\": 32.20332822799683,\n      \"last-10-avg\": 32.15007903575897\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 482.92539501190186,\n      \"min\": 33.38533282279968,\n      \"avg\": 257.83861406644183,\n      \"last\": 482.92539501190186,\n      \"last-5-avg\": 418.2623181819916,\n      \"last-10-avg\": 338.0868091583252\n    },\n    \"time_since_restore\": {\n      \"max\": 482.92539501190186,\n      \"min\": 33.38533282279968,\n      \"avg\": 257.83861406644183,\n      \"last\": 482.92539501190186,\n      \"last-5-avg\": 418.2623181819916,\n      \"last-10-avg\": 338.0868091583252\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60676f96f96f9473fe60669d89d89d9473fe6064ec4ec4ec5473fe6066532532532473fe6066578578578652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6067046046046473fe6066aaaaaaaab473fe60673b13b13b1473fe6067811811812473fe6065b7cb7cb7d473fe60676f96f96f9473fe60669d89d89d9473fe6064ec4ec4ec5473fe6066532532532473fe6066578578578652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fee47900000004740402144d800000047403fe281c80000004740403d473e0000004740403b308a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040411d4e000000474040012d8600000047403fea3ce40000004740400748e800000047403ffe8cd800000047403fee47900000004740402144d800000047403fe281c80000004740403d473e0000004740403b308a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740761d6eba80000047407821975580000047407a1fbf7200000047407c276859c0000047407e2ece6b000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740683dddb000000047406c3e29118000004740701db8570000004740721ea1740000004740741e8a418000004740761d6eba80000047407821975580000047407a1fbf7200000047407c276859c0000047407e2ece6b000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740761d6eba80000047407821975580000047407a1fbf7200000047407c276859c0000047407e2ece6b000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740683dddb000000047406c3e29118000004740701db8570000004740721ea1740000004740741e8a418000004740761d6eba80000047407821975580000047407a1fbf7200000047407c276859c0000047407e2ece6b000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669566974.8163552,\n  \"relative_logdir\": \"tune_hp_5e0ed_00023_23_batch_size=16,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-36-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00024\",\n  \"config\": {\n    \"learning_rate\": 5e-06,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"24_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6917727217715011,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.665506601333618,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00024\",\n    \"experiment_id\": \"a937b8a3fd124582a53c0bf6ae155b56\",\n    \"date\": \"2022-11-27_19-52-23\",\n    \"timestamp\": 1669567943,\n    \"time_total_s\": 477.23222827911377,\n    \"pid\": 27148,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-06,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 477.23222827911377,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"24_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669567943.5029066,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6918697520198985,\n      \"min\": 0.6917395306448652,\n      \"avg\": 0.6918049130344665,\n      \"last\": 0.6917727217715011,\n      \"last-5-avg\": 0.6918053390633347,\n      \"last-10-avg\": 0.6918136661888188\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.43589743589744,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.8069531917572,\n      \"min\": 31.399436712265015,\n      \"avg\": 31.815481885274252,\n      \"last\": 31.665506601333618,\n      \"last-5-avg\": 31.62115612030029,\n      \"last-10-avg\": 31.730709743499755\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 477.23222827911377,\n      \"min\": 33.8069531917572,\n      \"avg\": 255.36553494135535,\n      \"last\": 477.23222827911377,\n      \"last-5-avg\": 413.855375623703,\n      \"last-10-avg\": 334.60863268375397\n    },\n    \"time_since_restore\": {\n      \"max\": 477.23222827911377,\n      \"min\": 33.8069531917572,\n      \"avg\": 255.36553494135535,\n      \"last\": 477.23222827911377,\n      \"last-5-avg\": 413.855375623703,\n      \"last-10-avg\": 334.60863268375397\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe623b253253253473fe622c4ec4ec4ec473fe62377cb7cb7cb473fe623692992992a473fe623008c08c08c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe62373f73f73f7473fe62324a64a64a6473fe623cc08c08c09473fe623589d89d89e473fe6234a1ea1ea1f473fe623b253253253473fe622c4ec4ec4ec473fe62377cb7cb7cb473fe623692992992a473fe623008c08c08c652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f66417c00000047403f8e1c3400000047403fca400400000047403fb2181800000047403faa5ea4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403faa6d0400000047403fce6b4c00000047403ffa13e000000047403ff265f400000047403fce375c00000047403f66417c00000047403f8e1c3400000047403fca400400000047403fb2181800000047403faa5ea4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e86a05c00000474077e14bc9000000474079ddefc940000047407bd9114ac0000047407dd3b735000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067f2e84c80000047406becb5b600000047406febf832000000474071f52278400000474073f205ee000000474075e86a05c00000474077e14bc9000000474079ddefc940000047407bd9114ac0000047407dd3b735000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e86a05c00000474077e14bc9000000474079ddefc940000047407bd9114ac0000047407dd3b735000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067f2e84c80000047406becb5b600000047406febf832000000474071f52278400000474073f205ee000000474075e86a05c00000474077e14bc9000000474079ddefc940000047407bd9114ac0000047407dd3b735000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669567462.3496962,\n  \"relative_logdir\": \"tune_hp_5e0ed_00024_24_batch_size=2,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-44-22\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00025\",\n  \"config\": {\n    \"learning_rate\": 5e-06,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"25_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6962578928368723,\n    \"accuracy\": 51.28205128205128,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.86831831932068,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00025\",\n    \"experiment_id\": \"5dde40cc132146fb88f1cf7e48464e5a\",\n    \"date\": \"2022-11-27_20-00-29\",\n    \"timestamp\": 1669568429,\n    \"time_total_s\": 481.7171792984009,\n    \"pid\": 24588,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-06,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 481.7171792984009,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015649080276489258,\n    \"experiment_tag\": \"25_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669568429.76592,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6964146540715144,\n      \"min\": 0.6962140727246928,\n      \"avg\": 0.6963084555079796,\n      \"last\": 0.6962578928368723,\n      \"last-5-avg\": 0.696292740259415,\n      \"last-10-avg\": 0.6963077773395765\n    },\n    \"accuracy\": {\n      \"max\": 51.28205128205128,\n      \"min\": 51.28205128205128,\n      \"avg\": 51.28205128205127,\n      \"last\": 51.28205128205128,\n      \"last-5-avg\": 51.282051282051285,\n      \"last-10-avg\": 51.282051282051285\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.80665373802185,\n      \"min\": 31.85387873649597,\n      \"avg\": 32.11447861989339,\n      \"last\": 31.86831831932068,\n      \"last-5-avg\": 31.993948650360107,\n      \"last-10-avg\": 31.999888348579407\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 481.7171792984009,\n      \"min\": 33.80665373802185,\n      \"avg\": 257.74261260032654,\n      \"last\": 481.7171792984009,\n      \"last-5-avg\": 417.76139998435974,\n      \"last-10-avg\": 337.73437867164614\n    },\n    \"time_since_restore\": {\n      \"max\": 481.7171792984009,\n      \"min\": 33.80665373802185,\n      \"avg\": 257.74261260032654,\n      \"last\": 481.7171792984009,\n      \"last-5-avg\": 417.76139998435974,\n      \"last-10-avg\": 337.73437867164614\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015649080276489258,\n      \"min\": 0.015649080276489258,\n      \"avg\": 0.015649080276489258,\n      \"last\": 0.015649080276489258,\n      \"last-5-avg\": 0.015649080276489258,\n      \"last-10-avg\": 0.015649080276489258\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6490762762762473fe64762bc2bc2bc473fe6484f2df2df2e473fe647aea1ea1ea2473fe647bea1ea1ea2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64823b13b13b1473fe6489627627627473fe64867a87a87a8473fe647e3f73f73f7473fe6485c71c71c72473fe6490762762762473fe64762bc2bc2bc473fe6484f2df2df2e473fe647aea1ea1ea2473fe647bea1ea1ea2652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fda97cc0000004740400757e800000047404029404e00000047403fde2ec400000047403fde4a1c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400b09f400000047403fe26d1000000047403fe237f800000047404013419a000000474040031ccc00000047403fda97cc0000004740400757e800000047404029404e00000047403fde2ec400000047403fde4a1c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076199efc4000004740781a89f940000047407a1fb20300000047407c1d94ef40000047407e1b7991000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406839bec480000047406c360c668000004740701929b2c000004740721b91e60000004740741bf57f800000474076199efc4000004740781a89f940000047407a1fb20300000047407c1d94ef40000047407e1b7991000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076199efc4000004740781a89f940000047407a1fb20300000047407c1d94ef40000047407e1b7991000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406839bec480000047406c360c668000004740701929b2c000004740721b91e60000004740741bf57f800000474076199efc4000004740781a89f940000047407a1fb20300000047407c1d94ef40000047407e1b7991000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000473f90065000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669567944.0968297,\n  \"relative_logdir\": \"tune_hp_5e0ed_00025_25_batch_size=4,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_19-52-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00026\",\n  \"config\": {\n    \"learning_rate\": 5e-06,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"26_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6935307429387019,\n    \"accuracy\": 50.0,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.68036651611328,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00026\",\n    \"experiment_id\": \"4f8b38995e8d4b3e9a89f67af8a1b105\",\n    \"date\": \"2022-11-27_20-08-46\",\n    \"timestamp\": 1669568926,\n    \"time_total_s\": 493.0176434516907,\n    \"pid\": 23196,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-06,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 493.0176434516907,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"26_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669568926.8919728,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6935363508697249,\n      \"min\": 0.6935132670606303,\n      \"avg\": 0.6935240873244412,\n      \"last\": 0.6935307429387019,\n      \"last-5-avg\": 0.6935256827590812,\n      \"last-10-avg\": 0.693524182963575\n    },\n    \"accuracy\": {\n      \"max\": 50.0,\n      \"min\": 50.0,\n      \"avg\": 50.0,\n      \"last\": 50.0,\n      \"last-5-avg\": 50.0,\n      \"last-10-avg\": 50.0\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.322545289993286,\n      \"min\": 32.166738748550415,\n      \"avg\": 32.86784289677938,\n      \"last\": 32.68036651611328,\n      \"last-5-avg\": 33.07171053886414,\n      \"last-10-avg\": 33.028164291381835\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 493.0176434516907,\n      \"min\": 33.214282751083374,\n      \"avg\": 262.3388412475586,\n      \"last\": 493.0176434516907,\n      \"last-5-avg\": 427.1563996315002,\n      \"last-10-avg\": 344.46232216358186\n    },\n    \"time_since_restore\": {\n      \"max\": 493.0176434516907,\n      \"min\": 33.214282751083374,\n      \"avg\": 262.3388412475586,\n      \"last\": 493.0176434516907,\n      \"last-5-avg\": 427.1563996315002,\n      \"last-10-avg\": 344.46232216358186\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6315690690690473fe6315348348348473fe6314be5be5be6473fe63172bc2bc2bc473fe6316762762762652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6314c08c08c09473fe6315ee7ee7ee8473fe63145e15e15e1473fe6317325325325473fe6314c71c71c72473fe6315690690690473fe6315348348348473fe6314be5be5be6473fe63172bc2bc2bc473fe6316762762762652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740409f488a000000474040a9492a0000004740408927480000004740408515d2000000474040571640000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040853d4c0000004740407f3ee2000000474040854b460000004740408132ae0000004740406b2db00000004740409f488a000000474040a9492a0000004740408927480000004740408515d2000000474040571640000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768e74b4000000474078a39dd940000047407ab4c2c240000047407cc5657c80000047407ed04844800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406878dca400000047406c98ac5c8000004740705cff970000004740726d25ecc000004740747a8ba2c000004740768e74b4000000474078a39dd940000047407ab4c2c240000047407cc5657c80000047407ed04844800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768e74b4000000474078a39dd940000047407ab4c2c240000047407cc5657c80000047407ed04844800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406878dca400000047406c98ac5c8000004740705cff970000004740726d25ecc000004740747a8ba2c000004740768e74b4000000474078a39dd940000047407ab4c2c240000047407cc5657c80000047407ed04844800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669568429.9064837,\n  \"relative_logdir\": \"tune_hp_5e0ed_00026_26_batch_size=8,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-00-29\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00027\",\n  \"config\": {\n    \"learning_rate\": 5e-06,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 5e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"27_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6884997115175948,\n    \"accuracy\": 41.88034188034188,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.010589361190796,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00027\",\n    \"experiment_id\": \"1f214641ae3843c4b2ec04eeda51d530\",\n    \"date\": \"2022-11-27_20-17-03\",\n    \"timestamp\": 1669569423,\n    \"time_total_s\": 492.3197093009949,\n    \"pid\": 24112,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 5e-06,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 492.3197093009949,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"27_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669569423.8362715,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6885093623756343,\n      \"min\": 0.6884615645449386,\n      \"avg\": 0.6884892520741521,\n      \"last\": 0.6884997115175948,\n      \"last-5-avg\": 0.6884931254590678,\n      \"last-10-avg\": 0.6884897085336539\n    },\n    \"accuracy\": {\n      \"max\": 41.88034188034188,\n      \"min\": 41.88034188034188,\n      \"avg\": 41.880341880341874,\n      \"last\": 41.88034188034188,\n      \"last-5-avg\": 41.88034188034188,\n      \"last-10-avg\": 41.880341880341874\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.30508613586426,\n      \"min\": 31.93070387840271,\n      \"avg\": 32.82131395339967,\n      \"last\": 32.010589361190796,\n      \"last-5-avg\": 32.0625759601593,\n      \"last-10-avg\": 32.31534171104431\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 492.3197093009949,\n      \"min\": 34.30508613586426,\n      \"avg\": 265.7949032306671,\n      \"last\": 492.3197093009949,\n      \"last-5-avg\": 428.1667529582977,\n      \"last-10-avg\": 347.7109619140625\n    },\n    \"time_since_restore\": {\n      \"max\": 492.3197093009949,\n      \"min\": 34.30508613586426,\n      \"avg\": 265.7949032306671,\n      \"last\": 492.3197093009949,\n      \"last-5-avg\": 428.1667529582977,\n      \"last-10-avg\": 347.7109619140625\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60833d43d43d4473fe6081c71c71c72473fe608113b13b13b473fe6081b9fb9fba0473fe608308c08c08c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe60829d89d89d9473fe607ffb9fb9fba473fe60844c94c94c9473fe608171c71c71c473fe607e08c08c08c473fe60833d43d43d4473fe6081c71c71c72473fe608113b13b13b473fe6081b9fb9fba0473fe608308c08c08c652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400370dc00000047403fee429c0000004740401f06c60000004740400d1884000000474040015afe000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740406b1628000000474040471dda0000004740408d3f38000000474040311a8a00000047403ff611ec0000004740400370dc00000047403fee429c0000004740401f06c60000004740400d1884000000474040015afe000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076c08a14c00000474078bf6e3e80000047407ac34f1740000047407cc4f227c0000047407ec51d87800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740694017ce00000047406d51df44800000474070ba9789400000474072c0bada800000474074c01bf9400000474076c08a14c00000474078bf6e3e80000047407ac34f1740000047407cc4f227c0000047407ec51d87800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076c08a14c00000474078bf6e3e80000047407ac34f1740000047407cc4f227c0000047407ec51d87800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740694017ce00000047406d51df44800000474070ba9789400000474072c0bada800000474074c01bf9400000474076c08a14c00000474078bf6e3e80000047407ac34f1740000047407cc4f227c0000047407ec51d87800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669568927.6424725,\n  \"relative_logdir\": \"tune_hp_5e0ed_00027_27_batch_size=16,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-08-47\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00028\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"28_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6837177113590077,\n    \"accuracy\": 41.88034188034188,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.12023735046387,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00028\",\n    \"experiment_id\": \"1f0ca1d8214f463490e5f8ee4dd5c99c\",\n    \"date\": \"2022-11-27_20-25-06\",\n    \"timestamp\": 1669569906,\n    \"time_total_s\": 477.89328265190125,\n    \"pid\": 22664,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 477.89328265190125,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"28_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669569906.6190283,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6837217542860243,\n      \"min\": 0.683689932537894,\n      \"avg\": 0.683706769372663,\n      \"last\": 0.6837177113590077,\n      \"last-5-avg\": 0.683709716796875,\n      \"last-10-avg\": 0.683708236563919\n    },\n    \"accuracy\": {\n      \"max\": 41.88034188034188,\n      \"min\": 41.88034188034188,\n      \"avg\": 41.880341880341874,\n      \"last\": 41.88034188034188,\n      \"last-5-avg\": 41.88034188034188,\n      \"last-10-avg\": 41.880341880341874\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.35297870635986,\n      \"min\": 31.541406631469727,\n      \"avg\": 31.859552176793414,\n      \"last\": 32.12023735046387,\n      \"last-5-avg\": 31.83462357521057,\n      \"last-10-avg\": 31.742444229125976\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 477.89328265190125,\n      \"min\": 33.35297870635986,\n      \"avg\": 255.4395033677419,\n      \"last\": 477.89328265190125,\n      \"last-5-avg\": 413.93956832885743,\n      \"last-10-avg\": 334.6780092716217\n    },\n    \"time_since_restore\": {\n      \"max\": 477.89328265190125,\n      \"min\": 33.35297870635986,\n      \"avg\": 255.4395033677419,\n      \"last\": 477.89328265190125,\n      \"last-5-avg\": 413.93956832885743,\n      \"last-10-avg\": 334.6780092716217\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5e0eb59b59b5a473fe5e0f6f96f96f9473fe5e10b7cb7cb7d473fe5e0ce38e38e39473fe5e103f73f73f7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5e0f046046046473fe5e0eaf0af0af1473fe5e0ee7ee7ee7f473fe5e0f857857858473fe5e0dee7ee7ee8473fe5e0eb59b59b5a473fe5e0f6f96f96f9473fe5e10b7cb7cb7d473fe5e0ce38e38e39473fe5e103f73f73f7652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b474044f0af0af0af0b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fa6b31c00000047403f8e3f9800000047403fce629c000000474040051a220000004740400f63f0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403faa5a0800000047403faa7db800000047403f8a99a000000047403fbe857800000047403fa25ff400000047403fa6b31c00000047403f8e3f9800000047403fce629c000000474040051a220000004740400f63f0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e5f0fd400000474077ded4f6c00000474079dbbb2080000047407bdc5e64c0000047407dde4ae2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068044bfe80000047406bf99bb580000047406feaeee9800000474071f15fcc400000474073eb85cb800000474075e5f0fd400000474077ded4f6c00000474079dbbb2080000047407bdc5e64c0000047407dde4ae2c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e5f0fd400000474077ded4f6c00000474079dbbb2080000047407bdc5e64c0000047407dde4ae2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068044bfe80000047406bf99bb580000047406feaeee9800000474071f15fcc400000474073eb85cb800000474075e5f0fd400000474077ded4f6c00000474079dbbb2080000047407bdc5e64c0000047407dde4ae2c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669569424.7422812,\n  \"relative_logdir\": \"tune_hp_5e0ed_00028_28_batch_size=2,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-17-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00029\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"29_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6936069064670138,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.244224071502686,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00029\",\n    \"experiment_id\": \"3afb999adead4b5997588d22c6b6d7d4\",\n    \"date\": \"2022-11-27_20-33-14\",\n    \"timestamp\": 1669570394,\n    \"time_total_s\": 483.23038244247437,\n    \"pid\": 23200,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 483.23038244247437,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"29_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669570394.4577296,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6937259771885016,\n      \"min\": 0.6935643253163395,\n      \"avg\": 0.6936439362006991,\n      \"last\": 0.6936069064670138,\n      \"last-5-avg\": 0.6936660897018563,\n      \"last-10-avg\": 0.6936460641714243\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324785,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.773285150527954,\n      \"min\": 31.63321805000305,\n      \"avg\": 32.21535882949829,\n      \"last\": 32.244224071502686,\n      \"last-5-avg\": 32.16213955879211,\n      \"last-10-avg\": 32.15930533409119\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 483.23038244247437,\n      \"min\": 33.773285150527954,\n      \"avg\": 258.29841723442075,\n      \"last\": 483.23038244247437,\n      \"last-5-avg\": 418.8812218666077,\n      \"last-10-avg\": 338.57211859226226\n    },\n    \"time_since_restore\": {\n      \"max\": 483.23038244247437,\n      \"min\": 33.773285150527954,\n      \"avg\": 258.29841723442075,\n      \"last\": 483.23038244247437,\n      \"last-5-avg\": 418.8812218666077,\n      \"last-10-avg\": 338.57211859226226\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe632b08c08c08c473fe632364a64a64a473fe63300d20d20d2473fe632a15e15e15e473fe632071c71c71c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6325348348348473fe631eb36b36b37473fe63221ea1ea1ea473fe632138e38e38e473fe6327834834835473fe632b08c08c08c473fe632364a64a64a473fe63300d20d20d2473fe632a15e15e15e473fe632071c71c71c652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740401d47f8000000474040271af400000047403fa21a940000004740403312000000004740401f42bc000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402919300000004740401171a0000000474040273a94000000474040051d6c00000047403ffa82d40000004740401d47f8000000474040271af400000047403fa21a940000004740403312000000004740401f42bc000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762a60064000004740782f4364c0000047407a29650e00000047407c2fc74e00000047407e33afa5800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740683eab4c00000047406c4307b4000000474070266b2c800000474072270eda00000047407426b7074000004740762a60064000004740782f4364c0000047407a29650e00000047407c2fc74e00000047407e33afa5800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762a60064000004740782f4364c0000047407a29650e00000047407c2fc74e00000047407e33afa5800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740683eab4c00000047406c4307b4000000474070266b2c800000474072270eda00000047407426b7074000004740762a60064000004740782f4364c0000047407a29650e00000047407c2fc74e00000047407e33afa5800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669569907.33793,\n  \"relative_logdir\": \"tune_hp_5e0ed_00029_29_batch_size=4,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-25-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00030\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"30_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6922282031458667,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.837291955947876,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00030\",\n    \"experiment_id\": \"dacde363be2244f095934b14ff0ccd9d\",\n    \"date\": \"2022-11-27_20-41-28\",\n    \"timestamp\": 1669570888,\n    \"time_total_s\": 489.0693836212158,\n    \"pid\": 25480,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 489.0693836212158,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.01561427116394043,\n    \"experiment_tag\": \"30_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669570888.2760215,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6922360281658988,\n      \"min\": 0.6922282031458667,\n      \"avg\": 0.6922313592372796,\n      \"last\": 0.6922282031458667,\n      \"last-5-avg\": 0.6922310853615785,\n      \"last-10-avg\": 0.6922311375283787\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324785,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.02323126792908,\n      \"min\": 31.805856466293335,\n      \"avg\": 32.604625574747715,\n      \"last\": 31.837291955947876,\n      \"last-5-avg\": 32.15912752151489,\n      \"last-10-avg\": 32.44479920864105\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 489.0693836212158,\n      \"min\": 34.02323126792908,\n      \"avg\": 262.5035876115163,\n      \"last\": 489.0693836212158,\n      \"last-5-avg\": 424.8759822845459,\n      \"last-10-avg\": 344.09748747348783\n    },\n    \"time_since_restore\": {\n      \"max\": 489.0693836212158,\n      \"min\": 34.02323126792908,\n      \"avg\": 262.5035876115163,\n      \"last\": 489.0693836212158,\n      \"last-5-avg\": 424.8759822845459,\n      \"last-10-avg\": 344.09748747348783\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.01561427116394043,\n      \"min\": 0.01561427116394043,\n      \"avg\": 0.01561427116394043,\n      \"last\": 0.01561427116394043,\n      \"last-5-avg\": 0.01561427116394043,\n      \"last-10-avg\": 0.01561427116394043\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe626cc2bc2bc2c473fe626c000000000473fe626bf73f73f74473fe626c1a41a41a4473fe626bbc2bc2bc3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe626bbe5be5be6473fe626bee7ee7ee8473fe626c43d43d43d473fe626c857857858473fe626c2bc2bc2bc473fe626cc2bc2bc2c473fe626c000000000473fe626bf73f73f74473fe626c1a41a41a4473fe626bbc2bc2bc3652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740401943040000004740401f06c60000004740401715460000004740402b4c0200000047403fd658c4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740407716860000004740408b2bb400000047404083019800000047404067163a00000047403fce4c9c0000004740401943040000004740401f06c60000004740401715460000004740402b4c0200000047403fd658c4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768789a40000004740788b6a7cc0000047407a8e4d2580000047407c93b6a5c0000047407e911c32000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068b1a81200000047406cd472ff0000004740707a99b2800000474072877c79c000004740748461438000004740768789a40000004740788b6a7cc0000047407a8e4d2580000047407c93b6a5c0000047407e911c32000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740768789a40000004740788b6a7cc0000047407a8e4d2580000047407c93b6a5c0000047407e911c32000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068b1a81200000047406cd472ff0000004740707a99b2800000474072877c79c000004740748461438000004740768789a40000004740788b6a7cc0000047407a8e4d2580000047407c93b6a5c0000047407e911c32000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000473f8ffa6000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669570395.1922255,\n  \"relative_logdir\": \"tune_hp_5e0ed_00030_30_batch_size=8,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-33-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00031\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-06,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"31_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6919502193092281,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 34.05669832229614,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00031\",\n    \"experiment_id\": \"8c2e963d659947498e4284a3d2c956b6\",\n    \"date\": \"2022-11-27_20-49-49\",\n    \"timestamp\": 1669571389,\n    \"time_total_s\": 496.5152153968811,\n    \"pid\": 28360,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 496.5152153968811,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"31_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669571389.6182249,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6919502193092281,\n      \"min\": 0.6918087168636485,\n      \"avg\": 0.6918797854344728,\n      \"last\": 0.6919502193092281,\n      \"last-5-avg\": 0.6918784377921341,\n      \"last-10-avg\": 0.6918819851345486\n    },\n    \"accuracy\": {\n      \"max\": 45.72649572649573,\n      \"min\": 45.72649572649573,\n      \"avg\": 45.72649572649573,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.72649572649573\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.05669832229614,\n      \"min\": 31.6824209690094,\n      \"avg\": 33.101014359792075,\n      \"last\": 34.05669832229614,\n      \"last-5-avg\": 33.41844339370728,\n      \"last-10-avg\": 33.29667382240295\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 496.5152153968811,\n      \"min\": 33.39888143539429,\n      \"avg\": 263.3386964162191,\n      \"last\": 496.5152153968811,\n      \"last-5-avg\": 428.9528257846832,\n      \"last-10-avg\": 346.07031297683716\n    },\n    \"time_since_restore\": {\n      \"max\": 496.5152153968811,\n      \"min\": 33.39888143539429,\n      \"avg\": 263.3386964162191,\n      \"last\": 496.5152153968811,\n      \"last-5-avg\": 428.9528257846832,\n      \"last-10-avg\": 346.07031297683716\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62390af0af0af473fe623e9fb9fb9fc473fe6241bc2bc2bc3473fe6234c08c08c09473fe62474c94c94c9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6240af0af0af1473fe6244ee7ee7ee8473fe6243bc2bc2bc3473fe6234e38e38e39473fe623bdcfdcfdd0473fe62390af0af0af473fe623e9fb9fb9fc473fe6241bc2bc2bc3473fe6234c08c08c09473fe62474c94c94c9652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040632a0e0000004740406f15e0000000474040bb135c000000474040f738960000004740410741e4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040d11142000000474040591b7c000000474040972a1c000000474040ab4eaa000000474040834acc000000474040632a0e0000004740406f15e0000000474040bb135c000000474040f738960000004740410741e4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076a329dbc00000474078b10c97c0000047407ac86f0340000047407ce7561600000047407f083e52800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a5d17080000047406cbc184f80000047407070f16b400000474072865b4080000047407496c49a000000474076a329dbc00000474078b10c97c0000047407ac86f0340000047407ce7561600000047407f083e52800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076a329dbc00000474078b10c97c0000047407ac86f0340000047407ce7561600000047407f083e52800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a5d17080000047406cbc184f80000047407070f16b400000474072865b4080000047407496c49a000000474076a329dbc00000474078b10c97c0000047407ac86f0340000047407ce7561600000047407f083e52800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669570889.2132988,\n  \"relative_logdir\": \"tune_hp_5e0ed_00031_31_batch_size=16,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-41-29\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00032\",\n  \"config\": {\n    \"learning_rate\": 1e-09,\n    \"batch_size\": 2,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-09,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"32_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6885676587748731,\n    \"accuracy\": 44.871794871794876,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.946353435516357,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00032\",\n    \"experiment_id\": \"06f71219bbd14b96a2931a7a470140e7\",\n    \"date\": \"2022-11-27_20-57-55\",\n    \"timestamp\": 1669571875,\n    \"time_total_s\": 481.3890018463135,\n    \"pid\": 17312,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-09,\n      \"batch_size\": 2,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 481.3890018463135,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015655517578125,\n    \"experiment_tag\": \"32_batch_size=2,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669571875.381206,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6885947203024839,\n      \"min\": 0.6885350545247396,\n      \"avg\": 0.6885562125094595,\n      \"last\": 0.6885676587748731,\n      \"last-5-avg\": 0.6885496351453994,\n      \"last-10-avg\": 0.6885537563226161\n    },\n    \"accuracy\": {\n      \"max\": 44.871794871794876,\n      \"min\": 44.871794871794876,\n      \"avg\": 44.87179487179488,\n      \"last\": 44.871794871794876,\n      \"last-5-avg\": 44.871794871794876,\n      \"last-10-avg\": 44.87179487179487\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.1488618850708,\n      \"min\": 31.493103742599487,\n      \"avg\": 32.092600123087564,\n      \"last\": 31.946353435516357,\n      \"last-5-avg\": 31.94409589767456,\n      \"last-10-avg\": 31.904722476005553\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 481.3890018463135,\n      \"min\": 34.1488618850708,\n      \"avg\": 257.9287896792094,\n      \"last\": 481.3890018463135,\n      \"last-5-avg\": 417.47269167900083,\n      \"last-10-avg\": 337.8375844478607\n    },\n    \"time_since_restore\": {\n      \"max\": 481.3890018463135,\n      \"min\": 34.1488618850708,\n      \"avg\": 257.9287896792094,\n      \"last\": 481.3890018463135,\n      \"last-5-avg\": 417.47269167900083,\n      \"last-10-avg\": 337.8375844478607\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015655517578125,\n      \"min\": 0.015655517578125,\n      \"avg\": 0.015655517578125,\n      \"last\": 0.015655517578125,\n      \"last-5-avg\": 0.015655517578125,\n      \"last-10-avg\": 0.015655517578125\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe608913b13b13b473fe6089578578578473fe6089dcfdcfdd0473fe6087aaaaaaaab473fe608bf0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe608d0d20d20d2473fe608b627627627473fe6089811811812473fe6088df2df2df3473fe608a7a87a87a8473fe608913b13b13b473fe6089578578578473fe6089dcfdcfdd0473fe6087aaaaaaaab473fe608bf0af0af0b652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa4740466f96f96f96fa652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fda86a4000000474040011eb800000047403ff2a8f000000047403ff6c01c00000047403ff24438000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404035056e00000047403fba655000000047403fd23a9c00000047403f7e3c0c00000047403fdebec000000047403fda86a4000000474040011eb800000047403ff2a8f000000047403ff6c01c00000047403ff24438000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076185aaec00000474078187e85c0000047407a17a914c0000047407c17151680000047407e16395a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406858313200000047406c4f7ddc00000047407024e297c000004740721cc6588000004740741ab244800000474076185aaec00000474078187e85c0000047407a17a914c0000047407c17151680000047407e16395a000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474076185aaec00000474078187e85c0000047407a17a914c0000047407c17151680000047407e16395a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406858313200000047406c4f7ddc00000047407024e297c000004740721cc6588000004740741ab244800000474076185aaec00000474078187e85c0000047407a17a914c0000047407c17151680000047407e16395a000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000473f90080000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669571390.102488,\n  \"relative_logdir\": \"tune_hp_5e0ed_00032_32_batch_size=2,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-49-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00033\",\n  \"config\": {\n    \"learning_rate\": 1e-09,\n    \"batch_size\": 4,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-09,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"33_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6940716474484174,\n    \"accuracy\": 50.85470085470085,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.899887323379517,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00033\",\n    \"experiment_id\": \"134e90aad87f4f39a3aceb7173b9b47b\",\n    \"date\": \"2022-11-27_21-05-58\",\n    \"timestamp\": 1669572358,\n    \"time_total_s\": 477.4190719127655,\n    \"pid\": 11928,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-09,\n      \"batch_size\": 4,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 477.4190719127655,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"33_batch_size=4,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669572358.174,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6940750382904314,\n      \"min\": 0.6940660395173945,\n      \"avg\": 0.6940709736272481,\n      \"last\": 0.6940716474484174,\n      \"last-5-avg\": 0.6940714648646168,\n      \"last-10-avg\": 0.6940708453838642\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 50.85470085470085,\n      \"avg\": 50.85470085470084,\n      \"last\": 50.85470085470085,\n      \"last-5-avg\": 50.85470085470085,\n      \"last-10-avg\": 50.85470085470086\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.74322056770325,\n      \"min\": 31.3833646774292,\n      \"avg\": 31.827938127517697,\n      \"last\": 31.899887323379517,\n      \"last-5-avg\": 31.749922943115234,\n      \"last-10-avg\": 31.72497901916504\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 477.4190719127655,\n      \"min\": 33.74322056770325,\n      \"avg\": 255.30288529396057,\n      \"last\": 477.4190719127655,\n      \"last-5-avg\": 413.7409465312958,\n      \"last-10-avg\": 334.48619668483735\n    },\n    \"time_since_restore\": {\n      \"max\": 477.4190719127655,\n      \"min\": 33.74322056770325,\n      \"avg\": 255.30288529396057,\n      \"last\": 477.4190719127655,\n      \"last-5-avg\": 413.7409465312958,\n      \"last-10-avg\": 334.48619668483735\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe635cdacdacdad473fe635d857857858473fe635dcb7cb7cb8473fe635d253253253473fe635d5be5be5be652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe635d92992992a473fe635cea1ea1ea2473fe635d9b59b59b6473fe635c9fb9fb9fc473fe635d253253253473fe635cdacdacdad473fe635d857857858473fe635dcb7cb7cb8473fe635d253253253473fe635d5be5be5be652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f82379400000047403fc6628000000047403faea76800000047403fe2464000000047403fe65f04000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fae92d400000047403fd2352400000047403f661c5c00000047403fd2635000000047403fc6c3dc00000047403f82379400000047403fc6628000000047403faea76800000047403fe2464000000047403fe65f04000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e2d992000000474077df3fba000000474079da2a3080000047407bd84e9480000047407dd6b484c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067fb3d1c00000047406bf583c080000047406fe2474c000000474071ee49db000000474073eab618c00000474075e2d992000000474077df3fba000000474079da2a3080000047407bd84e9480000047407dd6b484c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474075e2d992000000474077df3fba000000474079da2a3080000047407bd84e9480000047407dd6b484c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474067fb3d1c00000047406bf583c080000047406fe2474c000000474071ee49db000000474073eab618c00000474075e2d992000000474077df3fba000000474079da2a3080000047407bd84e9480000047407dd6b484c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669571876.8499286,\n  \"relative_logdir\": \"tune_hp_5e0ed_00033_33_batch_size=4,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_20-57-56\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00034\",\n  \"config\": {\n    \"learning_rate\": 1e-09,\n    \"batch_size\": 8,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-09,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"34_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6961233677008213,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.36832857131958,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00034\",\n    \"experiment_id\": \"25b53f0c6aeb4059bff303f9a558a1b3\",\n    \"date\": \"2022-11-27_21-14-06\",\n    \"timestamp\": 1669572846,\n    \"time_total_s\": 483.6862406730652,\n    \"pid\": 3684,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-09,\n      \"batch_size\": 8,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 483.6862406730652,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"34_batch_size=8,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669572846.2654817,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6961703178210136,\n      \"min\": 0.6960901765741854,\n      \"avg\": 0.696130492816284,\n      \"last\": 0.6961233677008213,\n      \"last-5-avg\": 0.6961318708892561,\n      \"last-10-avg\": 0.6961353269397702\n    },\n    \"accuracy\": {\n      \"max\": 45.72649572649573,\n      \"min\": 45.72649572649573,\n      \"avg\": 45.72649572649573,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.72649572649573\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.24314785003662,\n      \"min\": 31.821335554122925,\n      \"avg\": 32.245749378204344,\n      \"last\": 32.36832857131958,\n      \"last-5-avg\": 32.20911769866943,\n      \"last-10-avg\": 32.22198648452759\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 483.6862406730652,\n      \"min\": 33.24314785003662,\n      \"avg\": 258.2335530281067,\n      \"last\": 483.6862406730652,\n      \"last-5-avg\": 419.28052072525026,\n      \"last-10-avg\": 338.6994304180145\n    },\n    \"time_since_restore\": {\n      \"max\": 483.6862406730652,\n      \"min\": 33.24314785003662,\n      \"avg\": 258.2335530281067,\n      \"last\": 483.6862406730652,\n      \"last-5-avg\": 419.28052072525026,\n      \"last-10-avg\": 338.6994304180145\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe646f069069069473fe6465ee7ee7ee8473fe64694ec4ec4ec473fe64706f96f96f9473fe646a483483483652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6468f0af0af0b473fe646af96f96f97473fe646db36b36b37473fe646efdcfdcfdd473fe646ce7ee7ee7f473fe646f069069069473fe6465ee7ee7ee8473fe64694ec4ec4ec473fe64706f96f96f9473fe646a483483483652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040292926000000474040132d1c0000004740401b281a00000047403ffe64300000004740402f2564000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401557e60000004740401b50320000004740401b2bba0000004740402d4b820000004740401d2f5c000000474040292926000000474040132d1c0000004740401b281a00000047403ffe64300000004740402f2564000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762f654140000047407831cae4c0000047407a352fe800000047407c35162b00000047407e3afad7800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406834428680000047406c3b169300000047407020f0c0c00000474072269a310000004740742a401c8000004740762f654140000047407831cae4c0000047407a352fe800000047407c35162b00000047407e3afad7800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740762f654140000047407831cae4c0000047407a352fe800000047407c35162b00000047407e3afad7800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406834428680000047406c3b169300000047407020f0c0c00000474072269a310000004740742a401c8000004740762f654140000047407831cae4c0000047407a352fe800000047407c35162b00000047407e3afad7800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669572358.627333,\n  \"relative_logdir\": \"tune_hp_5e0ed_00034_34_batch_size=8,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_21-05-58\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"5e0ed_00035\",\n  \"config\": {\n    \"learning_rate\": 1e-09,\n    \"batch_size\": 16,\n    \"model\": \"custom\",\n    \"epochs\": 15\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-27_16-28-23\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15,\n    \"learning_rate\": 1e-09,\n    \"model\": \"custom\"\n  },\n  \"experiment_tag\": \"35_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6970949091463008,\n    \"accuracy\": 50.85470085470085,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.430463552474976,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 15,\n    \"trial_id\": \"5e0ed_00035\",\n    \"experiment_id\": \"313b6f544c93434f8cbc921e29c4f441\",\n    \"date\": \"2022-11-27_21-22-18\",\n    \"timestamp\": 1669573338,\n    \"time_total_s\": 488.4179263114929,\n    \"pid\": 25872,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-09,\n      \"batch_size\": 16,\n      \"model\": \"custom\",\n      \"epochs\": 15\n    },\n    \"time_since_restore\": 488.4179263114929,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 0.015597820281982422,\n    \"experiment_tag\": \"35_batch_size=16,epochs=15,learning_rate=0.0000,model=custom\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1669573338.8230326,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.697111080854367,\n      \"min\": 0.6970892360067775,\n      \"avg\": 0.6970990998792514,\n      \"last\": 0.6970949091463008,\n      \"last-5-avg\": 0.697098143487914,\n      \"last-10-avg\": 0.6970974979237615\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 50.85470085470085,\n      \"avg\": 50.85470085470084,\n      \"last\": 50.85470085470085,\n      \"last-5-avg\": 50.85470085470085,\n      \"last-10-avg\": 50.85470085470086\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.11901354789734,\n      \"min\": 32.0252251625061,\n      \"avg\": 32.561195087432864,\n      \"last\": 32.430463552474976,\n      \"last-5-avg\": 32.29619054794311,\n      \"last-10-avg\": 32.40285620689392\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 488.4179263114929,\n      \"min\": 34.11901354789734,\n      \"avg\": 261.8255017280579,\n      \"last\": 488.4179263114929,\n      \"last-5-avg\": 423.9378457546234,\n      \"last-10-avg\": 343.08863339424136\n    },\n    \"time_since_restore\": {\n      \"max\": 488.4179263114929,\n      \"min\": 34.11901354789734,\n      \"avg\": 261.8255017280579,\n      \"last\": 488.4179263114929,\n      \"last-5-avg\": 423.9378457546234,\n      \"last-10-avg\": 343.08863339424136\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015597820281982422,\n      \"min\": 0.015597820281982422,\n      \"avg\": 0.015597820281982422,\n      \"last\": 0.015597820281982422,\n      \"last-5-avg\": 0.015597820281982422,\n      \"last-10-avg\": 0.015597820281982422\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe64ea1ea1ea1ea473fe64eb1a41a41a4473fe64e9e5be5be5c473fe64e97ee7ee7ee473fe64e99fb9fb9fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64ea992992993473fe64ea2bc2bc2bc473fe64e9ee7ee7ee8473fe64e9cfdcfdcfe473fe64e8e15e15e16473fe64ea1ea1ea1ea473fe64eb1a41a41a4473fe64e9e5be5be5c473fe64e97ee7ee7ee473fe64e99fb9fb9fc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740404916040000004740402f05fe000000474040033a940000004740400b1fd800000047404037196e000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040732a2200000047404029332e0000004740407330a80000004740402b4ddc0000004740400b3c3c0000004740404916040000004740402f05fe000000474040033a940000004740400b1fd800000047404037196e000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740767820988000004740787e015840000047407a7e68aac0000047407c7fcca5c0000047407e86afd3800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a9403480000047406cb38d00000000474070682c950000004740726d96508000004740746efdd80000004740767820988000004740787e015840000047407a7e68aac0000047407c7fcca5c0000047407e86afd3800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740767820988000004740787e015840000047407a7e68aac0000047407c7fcca5c0000047407e86afd3800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474068a9403480000047406cb38d00000000474070682c950000004740726d96508000004740746efdd80000004740767820988000004740787e015840000047407a7e68aac0000047407c7fcca5c0000047407e86afd3800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000473f8ff1c000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1669572846.3904243,\n  \"relative_logdir\": \"tune_hp_5e0ed_00035_35_batch_size=16,epochs=15,learning_rate=0.0000,model=custom_2022-11-27_21-14-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-27_16-28-23\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 17,
    "_metric": null,
    "_total_time": 18635.132032632828,
    "_iteration": 3887,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "C:\\Users\\MohammedSB\\ray_results\\tune_hp_2022-11-27_16-28-23",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1669555703.7792659,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-11-27_16-28-23",
    "checkpoint_file": "C:\\Users\\MohammedSB\\ray_results\\tune_hp_2022-11-27_16-28-23\\experiment_state-2022-11-27_16-28-23.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1669555703.7792659,
    "timestamp": 1669573331.7778115
  }
}