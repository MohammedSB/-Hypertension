{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00008\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.0001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"8_batch_size=2,learning_rate=0.0001,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6935242220886753,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.695772409439087,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00008\",\n    \"experiment_id\": \"565eb3dd31974aa0ac21a241c5c160f2\",\n    \"date\": \"2022-11-16_18-32-04\",\n    \"timestamp\": 1668612724,\n    \"time_total_s\": 969.2301132678986,\n    \"pid\": 26056,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 969.2301132678986,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015595436096191406,\n    \"experiment_tag\": \"8_batch_size=2,learning_rate=0.0001,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668612724.2259083,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6950774885650374,\n      \"min\": 0.6924341967982105,\n      \"avg\": 0.6938016842573117,\n      \"last\": 0.6935242220886753,\n      \"last-5-avg\": 0.6933591793744991,\n      \"last-10-avg\": 0.6936304076105102\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.435897435897424,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.45886206626892,\n      \"min\": 31.5707745552063,\n      \"avg\": 32.30767044226328,\n      \"last\": 31.695772409439087,\n      \"last-5-avg\": 31.882571268081666,\n      \"last-10-avg\": 31.82488172054291\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 969.2301132678986,\n      \"min\": 42.45886206626892,\n      \"avg\": 506.3147582530975,\n      \"last\": 969.2301132678986,\n      \"last-5-avg\": 905.5382389068603,\n      \"last-10-avg\": 825.8478792667389\n    },\n    \"time_since_restore\": {\n      \"max\": 969.2301132678986,\n      \"min\": 42.45886206626892,\n      \"avg\": 506.3147582530975,\n      \"last\": 969.2301132678986,\n      \"last-5-avg\": 905.5382389068603,\n      \"last-10-avg\": 825.8478792667389\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015595436096191406,\n      \"min\": 0.015595436096191406,\n      \"avg\": 0.015595436096191406,\n      \"last\": 0.015595436096191406,\n      \"last-5-avg\": 0.015595436096191406,\n      \"last-10-avg\": 0.015595436096191406\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62c7bc2bc2bc3473fe6326a1ea1ea1f473fe632e460460460473fe62cd9fb9fb9fc473fe63159b59b59b6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe639f181181181473fe6371834834835473fe6309c4ec4ec4f473fe62ff762762762473fe634989d89d89e473fe62c7bc2bc2bc3473fe6326a1ea1ea1f473fe632e460460460473fe62cd9fb9fb9fc473fe63159b59b59b6652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fe26e1800000047403fee1a7000000047403ff6187400000047403ff0f1d400000047403fb21e24000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f921e4800000047403fc6932400000047403fc66ba000000047403fe2859c00000047403fd45ee000000047403fe26e1800000047403fee1a7000000047403ff6187400000047403ff0f1d400000047403fb21e24000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4d9d2ec0000047408b4d0e0240000047408c4cbec5e0000047408d4c465480000047408e49d745a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085546aa4000000474086529f3d20000047408750d29a2000004740884fe6c70000004740894e89be00000047408a4d9d2ec0000047408b4d0e0240000047408c4cbec5e0000047408d4c465480000047408e49d745a00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4d9d2ec0000047408b4d0e0240000047408c4cbec5e0000047408d4c465480000047408e49d745a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085546aa4000000474086529f3d20000047408750d29a2000004740884fe6c70000004740894e89be00000047408a4d9d2ec0000047408b4d0e0240000047408c4cbec5e0000047408d4c465480000047408e49d745a00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000473f8ff08000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668611751.0279968,\n  \"relative_logdir\": \"tune_hp_757a3_00008_8_batch_size=2,learning_rate=0.0001,model=vgg16_2022-11-16_18-15-51\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00000\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.01,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"0_batch_size=2,learning_rate=0.0100,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6948942526792868,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.1028037071228,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00000\",\n    \"experiment_id\": \"1aa86382710f438dac07b31f293430c6\",\n    \"date\": \"2022-11-16_16-22-35\",\n    \"timestamp\": 1668604955,\n    \"time_total_s\": 972.5517611503601,\n    \"pid\": 12404,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 972.5517611503601,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"0_batch_size=2,learning_rate=0.0100,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668604955.2840898,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6948942526792868,\n      \"min\": 0.6948941222622863,\n      \"avg\": 0.6948942092069533,\n      \"last\": 0.6948942526792868,\n      \"last-5-avg\": 0.6948942005124866,\n      \"last-10-avg\": 0.6948942005124868\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324783,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 43.06701588630676,\n      \"min\": 31.66310477256775,\n      \"avg\": 32.41839203834533,\n      \"last\": 32.1028037071228,\n      \"last-5-avg\": 31.883955717086792,\n      \"last-10-avg\": 31.891424322128294\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 972.5517611503601,\n      \"min\": 43.06701588630676,\n      \"avg\": 509.29374587535847,\n      \"last\": 972.5517611503601,\n      \"last-5-avg\": 908.6139460086822,\n      \"last-10-avg\": 828.9941588640213\n    },\n    \"time_since_restore\": {\n      \"max\": 972.5517611503601,\n      \"min\": 43.06701588630676,\n      \"avg\": 509.29374587535847,\n      \"last\": 972.5517611503601,\n      \"last-5-avg\": 908.6139460086822,\n      \"last-10-avg\": 828.9941588640213\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92df2df2df652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe63c92bc2bc2bc473fe63c92df2df2df473fe63c92bc2bc2bc473fe63c92df2df2df473fe63c9299299299473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92bc2bc2bc473fe63c92df2df2df652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fc125a000000047403fc1d7a800000047403fe52db800000047403fe8fa440000004740400d28ac000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404008a1f400000047403fcfa5ec00000047403fd499a000000047403fd3626000000047403ff5af6800000047403fc125a000000047403fc1d7a800000047403fe52db800000047403fe8fa440000004740400d28ac000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a671779e0000047408b65263720000047408c644fa4e0000047408d63977700000047408e646a01c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740856da3c24000004740866c20f1a000004740876ac5bea000004740886960d1a00000474089690e4ce0000047408a671779e0000047408b65263720000047408c644fa4e0000047408d63977700000047408e646a01c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a671779e0000047408b65263720000047408c644fa4e0000047408d63977700000047408e646a01c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740856da3c24000004740866c20f1a000004740876ac5bea000004740886960d1a00000474089690e4ce0000047408a671779e0000047408b65263720000047408c644fa4e0000047408d63977700000047408e646a01c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668603978.5301917,\n  \"relative_logdir\": \"tune_hp_757a3_00000_0_batch_size=2,learning_rate=0.0100,model=vgg16_2022-11-16_16-06-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00003\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.01,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"3_batch_size=16,learning_rate=0.0100,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 805857.9145299145,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.75725483894348,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00003\",\n    \"experiment_id\": \"ed32c71c8db44b6797163d9f621ea481\",\n    \"date\": \"2022-11-16_17-11-04\",\n    \"timestamp\": 1668607864,\n    \"time_total_s\": 961.4000325202942,\n    \"pid\": 26592,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 961.4000325202942,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015620946884155273,\n    \"experiment_tag\": \"3_batch_size=16,learning_rate=0.0100,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668607865.0108683,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 821256.0683760684,\n      \"min\": 756404.717948718,\n      \"avg\": 790067.357264957,\n      \"last\": 805857.9145299145,\n      \"last-5-avg\": 795838.5777777778,\n      \"last-10-avg\": 790888.211965812\n    },\n    \"accuracy\": {\n      \"max\": 48.29059829059829,\n      \"min\": 48.29059829059829,\n      \"avg\": 48.2905982905983,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 48.29059829059829,\n      \"last-10-avg\": 48.29059829059828\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.52747964859009,\n      \"min\": 31.73307991027832,\n      \"avg\": 32.04666775067648,\n      \"last\": 31.75725483894348,\n      \"last-5-avg\": 31.921469020843507,\n      \"last-10-avg\": 31.867581820487977\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.4000325202942,\n      \"min\": 34.52747964859009,\n      \"avg\": 498.36026462713863,\n      \"last\": 961.4000325202942,\n      \"last-5-avg\": 897.7161147117615,\n      \"last-10-avg\": 817.9413796663284\n    },\n    \"time_since_restore\": {\n      \"max\": 961.4000325202942,\n      \"min\": 34.52747964859009,\n      \"avg\": 498.36026462713863,\n      \"last\": 961.4000325202942,\n      \"last-5-avg\": 897.7161147117615,\n      \"last-10-avg\": 817.9413796663284\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015620946884155273,\n      \"min\": 0.015620946884155273,\n      \"avg\": 0.015620946884155273,\n      \"last\": 0.015620946884155273,\n      \"last-5-avg\": 0.015620946884155273,\n      \"last-10-avg\": 0.015620946884155273\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474127d449d89d89d947412847c64a64a64a474127ab8dacdacdad47412910102302302347412897c3d43d43d4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284741274490f50f50f5474127f8b18118118147412801db13b13b14474128a491181181184741280903d43d43d4474127d449d89d89d947412847c64a64a64a474127ab8dacdacdad47412910102302302347412897c3d43d43d4652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404010cfb200000047403ffaef6c00000047403fce252800000047403feeeb8c00000047403fc1db74000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fc5e0c400000047403fee842c00000047403fbbc35400000047403fca31e000000047403fd72d5000000047404010cfb200000047403ffaef6c00000047403fce252800000047403feeeb8c00000047403fc1db74000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0f6467a0000047408b0f3be300000047408c0dad0c40000047408d0d2468a0000047408e0b3344400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408513fa37000000474086136e58600000474087114c730000004740880f9e020000004740890e576c80000047408a0f6467a0000047408b0f3be300000047408c0dad0c40000047408d0d2468a0000047408e0b3344400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0f6467a0000047408b0f3be300000047408c0dad0c40000047408d0d2468a0000047408e0b3344400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408513fa37000000474086136e58600000474087114c730000004740880f9e020000004740890e576c80000047408a0f6467a0000047408b0f3be300000047408c0dad0c40000047408d0d2468a0000047408e0b3344400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000473f8ffde000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668606899.6884716,\n  \"relative_logdir\": \"tune_hp_757a3_00003_3_batch_size=16,learning_rate=0.0100,model=vgg16_2022-11-16_16-54-59\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00006\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"6_batch_size=8,learning_rate=0.0010,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6974973108014489,\n    \"accuracy\": 40.17094017094017,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.962899923324585,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00006\",\n    \"experiment_id\": \"907fa40dd4de4970a07e02f1cfc7b7bb\",\n    \"date\": \"2022-11-16_17-59-48\",\n    \"timestamp\": 1668610788,\n    \"time_total_s\": 971.8291664123535,\n    \"pid\": 25316,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 971.8291664123535,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"6_batch_size=8,learning_rate=0.0010,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668610788.380826,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6980727758163061,\n      \"min\": 0.6972931429871128,\n      \"avg\": 0.6977258883310519,\n      \"last\": 0.6974973108014489,\n      \"last-5-avg\": 0.6977102426382211,\n      \"last-10-avg\": 0.6976717565813635\n    },\n    \"accuracy\": {\n      \"max\": 40.17094017094017,\n      \"min\": 40.17094017094017,\n      \"avg\": 40.170940170940185,\n      \"last\": 40.17094017094017,\n      \"last-5-avg\": 40.17094017094017,\n      \"last-10-avg\": 40.17094017094018\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.92965745925903,\n      \"min\": 31.914510011672974,\n      \"avg\": 32.394305547078446,\n      \"last\": 31.962899923324585,\n      \"last-5-avg\": 32.03343830108643,\n      \"last-10-avg\": 32.25322782993317\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 971.8291664123535,\n      \"min\": 34.92965745925903,\n      \"avg\": 503.2365332841872,\n      \"last\": 971.8291664123535,\n      \"last-5-avg\": 907.846674823761,\n      \"last-10-avg\": 827.5683261632919\n    },\n    \"time_since_restore\": {\n      \"max\": 971.8291664123535,\n      \"min\": 34.92965745925903,\n      \"avg\": 503.2365332841872,\n      \"last\": 971.8291664123535,\n      \"last-5-avg\": 907.846674823761,\n      \"last-10-avg\": 827.5683261632919\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6543762762762473fe65310d20d20d2473fe65639d89d89d9473fe652ce38e38e39473fe651e5e15e15e1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6538ee7ee7ee8473fe650a71c71c71c473fe6529cdacdacdb473fe653b299299299473fe6548992992993473fe6543762762762473fe65310d20d20d2473fe65639d89d89d9473fe652ce38e38e39473fe651e5e15e15e1652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e47404415e15e15e15e652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404011bb7e0000004740400333e40000004740400b0e3800000047403ff4514000000047403ff6809c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740407d1a600000004740407668700000004740402f0c1a000000474040171d9600000047403fea1d5400000047404011bb7e0000004740400333e40000004740400b0e3800000047403ff4514000000047403ff6809c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5e677160000047408b5e9aafa0000047408c5f4b9320000047408d5eee1d20000047408e5ea222000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855231ace00000474086599833e000004740875c88f58000004740885dfacee000004740895d4bb980000047408a5e677160000047408b5e9aafa0000047408c5f4b9320000047408d5eee1d20000047408e5ea222000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5e677160000047408b5e9aafa0000047408c5f4b9320000047408d5eee1d20000047408e5ea222000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855231ace00000474086599833e000004740875c88f58000004740885dfacee000004740895d4bb980000047408a5e677160000047408b5e9aafa0000047408c5f4b9320000047408d5eee1d20000047408e5ea222000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668609812.5994465,\n  \"relative_logdir\": \"tune_hp_757a3_00006_6_batch_size=8,learning_rate=0.0010,model=vgg16_2022-11-16_17-43-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00015\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-05,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"15_batch_size=16,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6220474895249065,\n    \"accuracy\": 65.8119658119658,\n    \"f1_score\": 0.5789473684210525,\n    \"time_this_iter_s\": 31.68696928024292,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00015\",\n    \"experiment_id\": \"2fb0af47c7474a5d80017846632f2ef1\",\n    \"date\": \"2022-11-16_20-25-37\",\n    \"timestamp\": 1668619537,\n    \"time_total_s\": 967.7696883678436,\n    \"pid\": 20876,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 967.7696883678436,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"15_batch_size=16,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668619537.6384869,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6366683438292935,\n      \"min\": 0.6156325381026309,\n      \"avg\": 0.6252397042733652,\n      \"last\": 0.6220474895249065,\n      \"last-5-avg\": 0.626743883964343,\n      \"last-10-avg\": 0.6271785442645733\n    },\n    \"accuracy\": {\n      \"max\": 67.94871794871796,\n      \"min\": 61.111111111111114,\n      \"avg\": 64.71509971509971,\n      \"last\": 65.8119658119658,\n      \"last-5-avg\": 65.12820512820512,\n      \"last-10-avg\": 64.95726495726497\n    },\n    \"f1_score\": {\n      \"max\": 0.6192893401015229,\n      \"min\": 0.5136612021857924,\n      \"avg\": 0.5674757006438109,\n      \"last\": 0.5789473684210525,\n      \"last-5-avg\": 0.5680038235318152,\n      \"last-10-avg\": 0.567581352136038\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.03925442695618,\n      \"min\": 31.569124937057495,\n      \"avg\": 32.25898961226144,\n      \"last\": 31.68696928024292,\n      \"last-5-avg\": 31.70036678314209,\n      \"last-10-avg\": 31.825317764282225\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 967.7696883678436,\n      \"min\": 35.03925442695618,\n      \"avg\": 503.82405936717976,\n      \"last\": 967.7696883678436,\n      \"last-5-avg\": 904.4515144348145,\n      \"last-10-avg\": 824.9516865253448\n    },\n    \"time_since_restore\": {\n      \"max\": 967.7696883678436,\n      \"min\": 35.03925442695618,\n      \"avg\": 503.82405936717976,\n      \"last\": 967.7696883678436,\n      \"last-5-avg\": 904.4515144348145,\n      \"last-10-avg\": 824.9516865253448\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3fba276276276473fe3fec4a64a64a6473fe4317230230230473fe433c483483483473fe3e7d023023023652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3e30b59b59b5a473fe3f177cb7cb7cb473fe43420af0af0af473fe42b059b59b59b473fe4376000000000473fe3fba276276276473fe3fec4a64a64a6473fe4317230230230473fe433c483483483473fe3e7d023023023652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474050589d89d89d8a474050589d89d89d8a474050c6046046046047404efb9fb9fb9fba47405073f73f73f73f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405073f73f73f73f4740503d43d43d43d4474050aaaaaaaaaaaa47405006906906906947404f325325325325474050589d89d89d8a474050589d89d89d8a474050c6046046046047404efb9fb9fb9fba47405073f73f73f73f652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824520cf59723e23f94869452946807680d4308922449922449e23f94869452946807680d43087854b3fe0c7ee33f94869452946807680d4308af95139ee96fe03f94869452946807680d43086b28afa1bc86e23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086b28afa1bc86e23f94869452946807680d4308129986ed6679e23f94869452946807680d4308cf2d71eaf7dce23f94869452946807680d43088c31c618638ce13f94869452946807680d4308555555555555e13f94869452946807680d430824520cf59723e23f94869452946807680d4308922449922449e23f94869452946807680d43087854b3fe0c7ee33f94869452946807680d4308af95139ee96fe03f94869452946807680d43086b28afa1bc86e23f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fdeaea000000047403fb6224000000047403f91b22c00000047403faa17ec00000047403fafdd38000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fea16280000004740401f7f8800000047403fcebd3800000047403fea167c00000047403fde6f2400000047403fdeaea000000047403fb6224000000047403f91b22c00000047403faa17ec00000047403fafdd38000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a491a05e0000047408b46cb17e0000047408c4358a940000047408d40a968a0000047408e3e2852600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854b7281a000004740864d6a7a2000004740874be063e000004740884b3117c000004740894a2490e0000047408a491a05e0000047408b46cb17e0000047408c4358a940000047408d40a968a0000047408e3e2852600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a491a05e0000047408b46cb17e0000047408c4358a940000047408d40a968a0000047408e3e2852600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854b7281a000004740864d6a7a2000004740874be063e000004740884b3117c000004740894a2490e0000047408a491a05e0000047408b46cb17e0000047408c4358a940000047408d40a968a0000047408e3e2852600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668618565.8851788,\n  \"relative_logdir\": \"tune_hp_757a3_00015_15_batch_size=16,learning_rate=0.0000,model=vgg16_2022-11-16_20-09-25\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00002\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.01,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"2_batch_size=8,learning_rate=0.0100,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 1.1436954074435763,\n    \"accuracy\": 45.2991452991453,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.98025155067444,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00002\",\n    \"experiment_id\": \"b7b866fb8ef64fb18a0b25213eb4dd51\",\n    \"date\": \"2022-11-16_16-54-59\",\n    \"timestamp\": 1668606899,\n    \"time_total_s\": 966.9879817962646,\n    \"pid\": 24940,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 966.9879817962646,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015628814697265625,\n    \"experiment_tag\": \"2_batch_size=8,learning_rate=0.0100,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668606899.122911,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 177.7711672008547,\n      \"min\": 1.1436954074435763,\n      \"avg\": 48.51973989546468,\n      \"last\": 1.1436954074435763,\n      \"last-5-avg\": 60.37737564999834,\n      \"last-10-avg\": 64.73460629455045\n    },\n    \"accuracy\": {\n      \"max\": 45.2991452991453,\n      \"min\": 45.2991452991453,\n      \"avg\": 45.29914529914528,\n      \"last\": 45.2991452991453,\n      \"last-5-avg\": 45.2991452991453,\n      \"last-10-avg\": 45.29914529914531\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.57602643966675,\n      \"min\": 31.896807193756104,\n      \"avg\": 32.23293272654215,\n      \"last\": 31.98025155067444,\n      \"last-5-avg\": 32.07309718132019,\n      \"last-10-avg\": 32.10227091312409\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.9879817962646,\n      \"min\": 34.57602643966675,\n      \"avg\": 500.80110208193463,\n      \"last\": 966.9879817962646,\n      \"last-5-avg\": 902.8350531101227,\n      \"last-10-avg\": 822.6079576015472\n    },\n    \"time_since_restore\": {\n      \"max\": 966.9879817962646,\n      \"min\": 34.57602643966675,\n      \"avg\": 500.80110208193463,\n      \"last\": 966.9879817962646,\n      \"last-5-avg\": 902.8350531101227,\n      \"last-10-avg\": 822.6079576015472\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015628814697265625,\n      \"min\": 0.015628814697265625,\n      \"avg\": 0.015628814697265625,\n      \"last\": 0.015628814697265625,\n      \"last-5-avg\": 0.015628814697265625,\n      \"last-10-avg\": 0.015628814697265625\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474042aab5325325324740596ef2df2df2df474012a8894c94c94d474063a05d20d20d21473ff24c938e38e38e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404e97c06906906947406031871c71c71c47404892f18118118147405180e069069069474041c83762762762474042aab5325325324740596ef2df2df2df474012a8894c94c94d474063a05d20d20d21473ff24c938e38e38e652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400b738800000047403feb2e700000004740401a68be00000047404015dbde00000047403ffaf1c4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401c43e00000004740400b74f2000000474040015af80000004740401fb6020000004740400b56180000004740400b738800000047403feb2e700000004740401a68be00000047404015dbde00000047403ffaf1c4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a35b217a0000047408b350b8b20000047408c36b21700000047408d380fd4e0000047408e37e763000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085317d1ee0000047408632346e000000474087324a1d80000047408834457da0000047408934fadf20000047408a35b217a0000047408b350b8b20000047408c36b21700000047408d380fd4e0000047408e37e763000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a35b217a0000047408b350b8b20000047408c36b21700000047408d380fd4e0000047408e37e763000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085317d1ee0000047408632346e000000474087324a1d80000047408834457da0000047408934fadf20000047408a35b217a0000047408b350b8b20000047408c36b21700000047408d380fd4e0000047408e37e763000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000473f90010000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668605928.2454956,\n  \"relative_logdir\": \"tune_hp_757a3_00002_2_batch_size=8,learning_rate=0.0100,model=vgg16_2022-11-16_16-38-48\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00009\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.0001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"9_batch_size=4,learning_rate=0.0001,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6283176780765892,\n    \"accuracy\": 64.1025641025641,\n    \"f1_score\": 0.5882352941176471,\n    \"time_this_iter_s\": 31.601993560791016,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00009\",\n    \"experiment_id\": \"a93bcaf02a7144e8bc789cadfd72e5db\",\n    \"date\": \"2022-11-16_18-48-16\",\n    \"timestamp\": 1668613696,\n    \"time_total_s\": 966.7421050071716,\n    \"pid\": 19744,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 966.7421050071716,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"9_batch_size=4,learning_rate=0.0001,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668613696.7635372,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6526043231670673,\n      \"min\": 0.6220464461889023,\n      \"avg\": 0.6408066361038774,\n      \"last\": 0.6283176780765892,\n      \"last-5-avg\": 0.6419810368464544,\n      \"last-10-avg\": 0.6407238300030048\n    },\n    \"accuracy\": {\n      \"max\": 67.94871794871796,\n      \"min\": 60.68376068376068,\n      \"avg\": 63.96011396011398,\n      \"last\": 64.1025641025641,\n      \"last-5-avg\": 63.760683760683754,\n      \"last-10-avg\": 63.931623931623925\n    },\n    \"f1_score\": {\n      \"max\": 0.631578947368421,\n      \"min\": 0.5533980582524272,\n      \"avg\": 0.5895720138414238,\n      \"last\": 0.5882352941176471,\n      \"last-5-avg\": 0.5928927995200224,\n      \"last-10-avg\": 0.591842224838528\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.27304196357727,\n      \"min\": 31.601993560791016,\n      \"avg\": 32.224736833572365,\n      \"last\": 31.601993560791016,\n      \"last-5-avg\": 31.860658884048462,\n      \"last-10-avg\": 31.846874785423278\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.7421050071716,\n      \"min\": 35.27304196357727,\n      \"avg\": 502.0559735774993,\n      \"last\": 966.7421050071716,\n      \"last-5-avg\": 903.1839082241058,\n      \"last-10-avg\": 823.4654046058655\n    },\n    \"time_since_restore\": {\n      \"max\": 966.7421050071716,\n      \"min\": 35.27304196357727,\n      \"avg\": 502.0559735774993,\n      \"last\": 966.7421050071716,\n      \"last-5-avg\": 903.1839082241058,\n      \"last-10-avg\": 823.4654046058655\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe4cd46d66d66d6473fe494f6d66d66d6473fe4a7de7ee7ee7f473fe492413b13b13b473fe41b2dacdacdad652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3e7cdf2df2df3473fe4c6a578578578473fe49e6483483483473fe4d2936b36b36b473fe4312230230230473fe4cd46d66d66d6473fe494f6d66d66d6473fe4a7de7ee7ee7f473fe492413b13b13b473fe41b2dacdacdad652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404f32532532532547404f9fb9fb9fb9fb474050589d89d89d8a47404fd66d66d66d66474050069069069069652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474050fcb7cb7cb7cc47404f32532532532547404fd66d66d66d6647404efb9fb9fb9fba47405021ea1ea1ea1f47404f32532532532547404f9fb9fb9fb9fb474050589d89d89d8a47404fd66d66d66d66474050069069069069652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcb223e8154e23f94869452946807680d43084fecc44eecc4e23f94869452946807680d4308987a327ebbd4e33f94869452946807680d43082a8f0ebce71be33f94869452946807680d4308d3d2d2d2d2d2e23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085cf8d598480fe43f94869452946807680d4308cdcb223e8154e23f94869452946807680d430869bbb74a53fce23f94869452946807680d43081b92b721791be23f94869452946807680d43080cd3b3303d0be33f94869452946807680d4308cdcb223e8154e23f94869452946807680d43084fecc44eecc4e23f94869452946807680d4308987a327ebbd4e33f94869452946807680d43082a8f0ebce71be33f94869452946807680d4308d3d2d2d2d2d2e23f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff216b800000047403fe61a300000004740400b09f400000047403fc543a400000047403f9a1c40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fddc43800000047403fb624cc00000047403ff2171c00000047403fb61a3400000047403fee40d400000047403ff216b800000047403fe61a300000004740400b09f400000047403fc543a400000047403f9a1c40000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3b1364e0000047408b3a443660000047408c3af4d5a0000047408d391ef2c0000047408e35efd4c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085411df7a000004740863ecf1e0000004740873e5fd6e000004740883c10a88000004740893b82af20000047408a3b1364e0000047408b3a443660000047408c3af4d5a0000047408d391ef2c0000047408e35efd4c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3b1364e0000047408b3a443660000047408c3af4d5a0000047408d391ef2c0000047408e35efd4c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085411df7a000004740863ecf1e0000004740873e5fd6e000004740883c10a88000004740893b82af20000047408a3b1364e0000047408b3a443660000047408c3af4d5a0000047408d391ef2c0000047408e35efd4c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668612726.1320193,\n  \"relative_logdir\": \"tune_hp_757a3_00009_9_batch_size=4,learning_rate=0.0001,model=vgg16_2022-11-16_18-32-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00007\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"7_batch_size=16,learning_rate=0.0010,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7200516268738315,\n    \"accuracy\": 55.55555555555556,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.92611312866211,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00007\",\n    \"experiment_id\": \"359ab534948e42c5883cc1c3aaf93a10\",\n    \"date\": \"2022-11-16_18-15-50\",\n    \"timestamp\": 1668611750,\n    \"time_total_s\": 958.1013426780701,\n    \"pid\": 17800,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 958.1013426780701,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"7_batch_size=16,learning_rate=0.0010,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668611750.6218383,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7204417693309295,\n      \"min\": 0.7196130997095352,\n      \"avg\": 0.7200325446930365,\n      \"last\": 0.7200516268738315,\n      \"last-5-avg\": 0.7200194529997997,\n      \"last-10-avg\": 0.7200866568801749\n    },\n    \"accuracy\": {\n      \"max\": 55.55555555555556,\n      \"min\": 55.55555555555556,\n      \"avg\": 55.55555555555558,\n      \"last\": 55.55555555555556,\n      \"last-5-avg\": 55.55555555555556,\n      \"last-10-avg\": 55.55555555555556\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.43029284477234,\n      \"min\": 31.650417804718018,\n      \"avg\": 31.936711422602325,\n      \"last\": 31.92611312866211,\n      \"last-5-avg\": 32.01099128723145,\n      \"last-10-avg\": 31.907447934150696\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 958.1013426780701,\n      \"min\": 34.43029284477234,\n      \"avg\": 495.9701050917308,\n      \"last\": 958.1013426780701,\n      \"last-5-avg\": 894.0103450298309,\n      \"last-10-avg\": 814.213209605217\n    },\n    \"time_since_restore\": {\n      \"max\": 958.1013426780701,\n      \"min\": 34.43029284477234,\n      \"avg\": 495.9701050917308,\n      \"last\": 958.1013426780701,\n      \"last-5-avg\": 894.0103450298309,\n      \"last-10-avg\": 814.213209605217\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe70a5f73f73f74473fe70c8253253253473fe70b61a41a41a4473fe707120d20d20d473fe70aa9b59b59b6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe70a3e7ee7ee7f473fe70aa811811812473fe70b150f50f50f473fe70ddbe5be5be6473fe70ba906906907473fe70a5f73f73f74473fe70c8253253253473fe70b61a41a41a4473fe707120d20d20d473fe70aa9b59b59b6652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c72652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c7247404bc71c71c71c72652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fc935b00000004740400d3c82000000474040091eb60000004740401587e000000047403fed15c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fca630c00000047403fee01c800000047403fa98eec00000047403fa681c800000047403ffc89ec00000047403fc935b00000004740400d3c82000000474040091eb60000004740401587e000000047403fed15c0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089eea8ad40000047408aef7c7560000047408bf00e60c0000047408cf166dec0000047408df0cf8cc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084f68a1c800000474085f5fa2ac00000474086f346a2200000474087f07ab0600000474088f05effc00000474089eea8ad40000047408aef7c7560000047408bf00e60c0000047408cf166dec0000047408df0cf8cc00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089eea8ad40000047408aef7c7560000047408bf00e60c0000047408cf166dec0000047408df0cf8cc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084f68a1c800000474085f5fa2ac00000474086f346a2200000474087f07ab0600000474088f05effc00000474089eea8ad40000047408aef7c7560000047408bf00e60c0000047408cf166dec0000047408df0cf8cc00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668610788.6307685,\n  \"relative_logdir\": \"tune_hp_757a3_00007_7_batch_size=16,learning_rate=0.0010,model=vgg16_2022-11-16_17-59-48\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00012\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-05,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"12_batch_size=2,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6222667857113048,\n    \"accuracy\": 61.53846153846154,\n    \"f1_score\": 0.40789473684210525,\n    \"time_this_iter_s\": 32.14872431755066,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00012\",\n    \"experiment_id\": \"28929df140c949f5beb207a3aed34b30\",\n    \"date\": \"2022-11-16_19-36-50\",\n    \"timestamp\": 1668616610,\n    \"time_total_s\": 970.6893191337585,\n    \"pid\": 3040,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 970.6893191337585,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"12_batch_size=2,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668616610.6656983,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6292112301557492,\n      \"min\": 0.6019157996544471,\n      \"avg\": 0.6189850766434628,\n      \"last\": 0.6222667857113048,\n      \"last-5-avg\": 0.6196675618489583,\n      \"last-10-avg\": 0.6186530153975528\n    },\n    \"accuracy\": {\n      \"max\": 64.1025641025641,\n      \"min\": 59.401709401709404,\n      \"avg\": 61.980056980056965,\n      \"last\": 61.53846153846154,\n      \"last-5-avg\": 62.136752136752136,\n      \"last-10-avg\": 62.3931623931624\n    },\n    \"f1_score\": {\n      \"max\": 0.46540880503144655,\n      \"min\": 0.3472222222222222,\n      \"avg\": 0.4180228078757386,\n      \"last\": 0.40789473684210525,\n      \"last-5-avg\": 0.4222931007760729,\n      \"last-10-avg\": 0.42981223591072293\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.57331871986389,\n      \"min\": 31.738512754440308,\n      \"avg\": 32.35631063779195,\n      \"last\": 32.14872431755066,\n      \"last-5-avg\": 32.093433427810666,\n      \"last-10-avg\": 32.12402718067169\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.6893191337585,\n      \"min\": 42.57331871986389,\n      \"avg\": 505.84806834061925,\n      \"last\": 970.6893191337585,\n      \"last-5-avg\": 906.4995842933655,\n      \"last-10-avg\": 826.2252480745316\n    },\n    \"time_since_restore\": {\n      \"max\": 970.6893191337585,\n      \"min\": 42.57331871986389,\n      \"avg\": 505.84806834061925,\n      \"last\": 970.6893191337585,\n      \"last-5-avg\": 906.4995842933655,\n      \"last-10-avg\": 826.2252480745316\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3bc7d66d66d67473fe3da894c94c94d473fe3d5db7cb7cb7d473fe3cf171c71c71c473fe3e99c08c08c09652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3980118118118473fe3b0db9fb9fba0473fe3ceebc2bc2bc3473fe39c97ee7ee7ee473fe41e1857857858473fe3bc7d66d66d67473fe3da894c94c94d473fe3d5db7cb7cb7d473fe3cf171c71c71c473fe3e99c08c08c09652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404e8e38e38e38e447404f32532532532547404f32532532532547404f9fb9fb9fb9fb47404ec4ec4ec4ec4f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404fd66d66d66d6647404f9fb9fb9fb9fb47404f9fb9fb9fb9fb47404ec4ec4ec4ec4f47404ec4ec4ec4ec4f47404e8e38e38e38e447404f32532532532547404f32532532532547404f9fb9fb9fb9fb47404ec4ec4ec4ec4f652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b44ef9944efd93f94869452946807680d4308dbb66ddbb66ddb3f94869452946807680d430828afa1bc86f2da3f94869452946807680d43087ccbb77ccbb7dc3f94869452946807680d4308afa1bc86f21ada3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a5a380342c9dd3f94869452946807680d4308fa0971567e42dc3f94869452946807680d43087ccbb77ccbb7dc3f94869452946807680d43083bb1133bb113db3f94869452946807680d4308afa1bc86f21ada3f94869452946807680d43089b44ef9944efd93f94869452946807680d4308dbb66ddbb66ddb3f94869452946807680d430828afa1bc86f2da3f94869452946807680d43087ccbb77ccbb7dc3f94869452946807680d4308afa1bc86f21ada3f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040171dbc000000474040030a6a00000047404001919c0000004740400d08fa000000474040130966000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404023096400000047404007094c00000047404017396a0000004740400e881c0000004740401320e2000000474040171dbc000000474040030a6a00000047404001919c0000004740400d08fa000000474040130966000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5338d360000047408b53697a00000047408c538293c0000047408d54532360000047408e5583b9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854dc83c6000004740864e38d12000004740874fac67c000004740885094e980000047408951c6f7a0000047408a5338d360000047408b53697a00000047408c538293c0000047408d54532360000047408e5583b9c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5338d360000047408b53697a00000047408c538293c0000047408d54532360000047408e5583b9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854dc83c6000004740864e38d12000004740874fac67c000004740885094e980000047408951c6f7a0000047408a5338d360000047408b53697a00000047408c538293c0000047408d54532360000047408e5583b9c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668615636.0866635,\n  \"relative_logdir\": \"tune_hp_757a3_00012_12_batch_size=2,learning_rate=0.0000,model=vgg16_2022-11-16_19-20-36\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00011\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.0001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"11_batch_size=16,learning_rate=0.0001,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6974686842698318,\n    \"accuracy\": 46.15384615384615,\n    \"f1_score\": 0.03076923076923077,\n    \"time_this_iter_s\": 32.467212438583374,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00011\",\n    \"experiment_id\": \"027b8111cd814bc3902df8180109bc84\",\n    \"date\": \"2022-11-16_19-20-35\",\n    \"timestamp\": 1668615635,\n    \"time_total_s\": 963.3774907588959,\n    \"pid\": 26960,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 963.3774907588959,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"11_batch_size=16,learning_rate=0.0001,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668615635.9929357,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7040228558401777,\n      \"min\": 0.6947032569820045,\n      \"avg\": 0.6987607167996573,\n      \"last\": 0.6974686842698318,\n      \"last-5-avg\": 0.6988574818668203,\n      \"last-10-avg\": 0.698909459562383\n    },\n    \"accuracy\": {\n      \"max\": 46.58119658119658,\n      \"min\": 45.2991452991453,\n      \"avg\": 45.99715099715101,\n      \"last\": 46.15384615384615,\n      \"last-5-avg\": 45.98290598290599,\n      \"last-10-avg\": 45.982905982905976\n    },\n    \"f1_score\": {\n      \"max\": 0.04580152671755725,\n      \"min\": 0.0,\n      \"avg\": 0.025132908789929916,\n      \"last\": 0.03076923076923077,\n      \"last-5-avg\": 0.024663088849135362,\n      \"last-10-avg\": 0.024639782963944156\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.5236599445343,\n      \"min\": 31.618008136749268,\n      \"avg\": 32.11258302529651,\n      \"last\": 32.467212438583374,\n      \"last-5-avg\": 32.20517826080322,\n      \"last-10-avg\": 32.08077211380005\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 963.3774907588959,\n      \"min\": 34.5236599445343,\n      \"avg\": 498.524717648824,\n      \"last\": 963.3774907588959,\n      \"last-5-avg\": 898.8678660869598,\n      \"last-10-avg\": 818.702547955513\n    },\n    \"time_since_restore\": {\n      \"max\": 963.3774907588959,\n      \"min\": 34.5236599445343,\n      \"avg\": 498.524717648824,\n      \"last\": 963.3774907588959,\n      \"last-5-avg\": 898.8678660869598,\n      \"last-10-avg\": 818.702547955513\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe651d6f96f96f9473fe6562302302302473fe650350f50f50f473fe6875af0af0af1473fe651a9d89d89d9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe66b464a64a64a473fe646b857857858473fe63b5a1ea1ea1f473fe67ff1c71c71c7473fe6682b59b59b5a473fe651d6f96f96f9473fe6562302302302473fe650350f50f50f473fe6875af0af0af1473fe651a9d89d89d9652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd047404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404713b13b13b13b474046dcfdcfdcfdd04740474a64a64a64a6474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd047404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f007fc017fc08f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d430820f8811ff8819f3f94869452946807680d430820f8811ff8819f3f94869452946807680d430820f8811ff8819f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430820f8811ff8819f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d4308d5b1b7364c73a73f94869452946807680d4308f007fc017fc08f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d4308f007fc017fc08f3f94869452946807680d430820f8811ff8819f3f94869452946807680d430820f8811ff8819f3f94869452946807680d430820f8811ff8819f3f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740401b17cc00000047404011089c0000004740400c3d520000004740400f25100000004740403bcd9e000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400a980600000047403ff34e7800000047403ff615d800000047403ff35c1400000047403fd635900000004740401b17cc00000047404011089c0000004740400c3d520000004740400f25100000004740403bcd9e000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a14819020000047408b159219e0000047408c1655ef00000047408d17484000000047408e1b0519e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085153863c0000047408614d2d7800000474087148386400000474088141e66e0000047408912d01360000047408a14819020000047408b159219e0000047408c1655ef00000047408d17484000000047408e1b0519e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a14819020000047408b159219e0000047408c1655ef00000047408d17484000000047408e1b0519e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085153863c0000047408614d2d7800000474087148386400000474088141e66e0000047408912d01360000047408a14819020000047408b159219e0000047408c1655ef00000047408d17484000000047408e1b0519e00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668614668.6945148,\n  \"relative_logdir\": \"tune_hp_757a3_00011_11_batch_size=16,learning_rate=0.0001,model=vgg16_2022-11-16_19-04-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00001\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.01,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"1_batch_size=4,learning_rate=0.0100,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.8851377047025241,\n    \"accuracy\": 53.84615384615385,\n    \"f1_score\": 0.7000000000000001,\n    \"time_this_iter_s\": 31.774298191070557,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00001\",\n    \"experiment_id\": \"087390eee60b4c94acbe223ed9d98040\",\n    \"date\": \"2022-11-16_16-38-46\",\n    \"timestamp\": 1668605926,\n    \"time_total_s\": 966.4626138210297,\n    \"pid\": 5312,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 966.4626138210297,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"1_batch_size=4,learning_rate=0.0100,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668605926.3862417,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.8851379655365251,\n      \"min\": 0.8851375742855235,\n      \"avg\": 0.8851378090361245,\n      \"last\": 0.8851377047025241,\n      \"last-5-avg\": 0.8851378090361244,\n      \"last-10-avg\": 0.8851377894735745\n    },\n    \"accuracy\": {\n      \"max\": 53.84615384615385,\n      \"min\": 53.84615384615385,\n      \"avg\": 53.846153846153825,\n      \"last\": 53.84615384615385,\n      \"last-5-avg\": 53.84615384615385,\n      \"last-10-avg\": 53.846153846153854\n    },\n    \"f1_score\": {\n      \"max\": 0.7000000000000001,\n      \"min\": 0.7000000000000001,\n      \"avg\": 0.6999999999999995,\n      \"last\": 0.7000000000000001,\n      \"last-5-avg\": 0.7000000000000001,\n      \"last-10-avg\": 0.7000000000000001\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.94173073768616,\n      \"min\": 31.66109013557434,\n      \"avg\": 32.21542046070098,\n      \"last\": 31.774298191070557,\n      \"last-5-avg\": 31.819373846054077,\n      \"last-10-avg\": 32.056104278564455\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.4626138210297,\n      \"min\": 34.94173073768616,\n      \"avg\": 500.5258679707845,\n      \"last\": 966.4626138210297,\n      \"last-5-avg\": 902.9240612506867,\n      \"last-10-avg\": 822.8759621620178\n    },\n    \"time_since_restore\": {\n      \"max\": 966.4626138210297,\n      \"min\": 34.94173073768616,\n      \"avg\": 500.5258679707845,\n      \"last\": 966.4626138210297,\n      \"last-5-avg\": 902.9240612506867,\n      \"last-10-avg\": 822.8759621620178\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec530c71c71c72473fec530c94c94c95473fec530c94c94c95473fec530cb7cb7cb8473fec530c4ec4ec4f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fec530c94c94c95473fec530cb7cb7cb8473fec530c71c71c72473fec530c08c08c09473fec530c71c71c72473fec530c71c71c72473fec530c94c94c95473fec530c94c94c95473fec530cb7cb7cb8473fec530c4ec4ec4f652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec5652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec547404aec4ec4ec4ec5652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f94869452946807680d4308676666666666e63f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404002298c00000047403fad47c400000047403ff7bbf400000047403fa93d3400000047403fc63868000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402e8902000000474040191e7200000047404038ce520000004740401e4da40000004740401ca6a000000047404002298c00000047403fad47c400000047403ff7bbf400000047403fa93d3400000047403fc63868000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3b0fa440000047408b3879e260000047408c3837c200000047408d3581aba0000047408e33b36ee00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085321efb00000047408633b0e2200000474087373dc74000004740883922a18000004740893aed0b80000047408a3b0fa440000047408b3879e260000047408c3837c200000047408d3581aba0000047408e33b36ee00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3b0fa440000047408b3879e260000047408c3837c200000047408d3581aba0000047408e33b36ee00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085321efb00000047408633b0e2200000474087373dc74000004740883922a18000004740893aed0b80000047408a3b0fa440000047408b3879e260000047408c3837c200000047408d3581aba0000047408e33b36ee00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668604956.0654666,\n  \"relative_logdir\": \"tune_hp_757a3_00001_1_batch_size=4,learning_rate=0.0100,model=vgg16_2022-11-16_16-22-36\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00016\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-06,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"16_batch_size=2,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6578153952574118,\n    \"accuracy\": 55.98290598290598,\n    \"f1_score\": 0.2797202797202798,\n    \"time_this_iter_s\": 31.925955533981323,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00016\",\n    \"experiment_id\": \"1908ab8ca3b54175a1a5ebced998d136\",\n    \"date\": \"2022-11-16_20-41-52\",\n    \"timestamp\": 1668620512,\n    \"time_total_s\": 968.8034369945526,\n    \"pid\": 26184,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 968.8034369945526,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015620708465576172,\n    \"experiment_tag\": \"16_batch_size=2,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668620512.2998993,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6697348570212339,\n      \"min\": 0.6468221550313835,\n      \"avg\": 0.6586234742080384,\n      \"last\": 0.6578153952574118,\n      \"last-5-avg\": 0.6580983740651709,\n      \"last-10-avg\": 0.6569349957327557\n    },\n    \"accuracy\": {\n      \"max\": 58.119658119658126,\n      \"min\": 51.28205128205128,\n      \"avg\": 55.59829059829058,\n      \"last\": 55.98290598290598,\n      \"last-5-avg\": 55.64102564102565,\n      \"last-10-avg\": 55.85470085470085\n    },\n    \"f1_score\": {\n      \"max\": 0.3,\n      \"min\": 0.12307692307692307,\n      \"avg\": 0.2417558958186456,\n      \"last\": 0.2797202797202798,\n      \"last-5-avg\": 0.24398849470444844,\n      \"last-10-avg\": 0.24940536954935705\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.85013961791992,\n      \"min\": 31.680875539779663,\n      \"avg\": 32.2934478998184,\n      \"last\": 31.925955533981323,\n      \"last-5-avg\": 31.978348779678345,\n      \"last-10-avg\": 31.904025554656982\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 968.8034369945526,\n      \"min\": 42.85013961791992,\n      \"avg\": 506.3256477197011,\n      \"last\": 968.8034369945526,\n      \"last-5-avg\": 904.8639439582824,\n      \"last-10-avg\": 825.0309148073196\n    },\n    \"time_since_restore\": {\n      \"max\": 968.8034369945526,\n      \"min\": 42.85013961791992,\n      \"avg\": 506.3256477197011,\n      \"last\": 968.8034369945526,\n      \"last-5-avg\": 904.8639439582824,\n      \"last-10-avg\": 825.0309148073196\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015620708465576172,\n      \"min\": 0.015620708465576172,\n      \"avg\": 0.015620708465576172,\n      \"last\": 0.015620708465576172,\n      \"last-5-avg\": 0.015620708465576172,\n      \"last-10-avg\": 0.015620708465576172\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe4d5a627627627473fe50b7992992993473fe51f792992992a473fe53e49d89d89d9473fe50cd2df2df2df652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5127834834835473fe5206302302302473fe508515e15e15e473fe4fe76d66d66d6473fe4b2c460460460473fe4d5a627627627473fe50b7992992993473fe51f792992992a473fe53e49d89d89d9473fe50cd2df2df2df652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b90690690690747404bfdcfdcfdcfdd47404b59b59b59b59c47404c34834834834847404bfdcfdcfdcfdd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b23023023023047404bfdcfdcfdcfdd47404b90690690690747404c6b36b36b36b347404d0f50f50f50f647404b90690690690747404bfdcfdcfdcfdd47404b59b59b59b59c47404c34834834834847404bfdcfdcfdcfdd652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081cc7711cc771cc3f94869452946807680d4308f30e385234c4cf3f94869452946807680d43087aa072760bbfca3f94869452946807680d43080b59c84216b2d03f94869452946807680d4308fc4c5be3efe6d13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430821feb8757907cc3f94869452946807680d4308f30e385234c4cf3f94869452946807680d43088a86f8e3d6e5cd3f94869452946807680d43083e5a4d42147fd13f94869452946807680d4308333333333333d33f94869452946807680d43081cc7711cc771cc3f94869452946807680d4308f30e385234c4cf3f94869452946807680d43087aa072760bbfca3f94869452946807680d43080b59c84216b2d03f94869452946807680d4308fc4c5be3efe6d13f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff9764400000047403fee5f040000004740400f1cc000000047403ff12f2000000047403fed0b6c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fc249b400000047403fecd9dc00000047403fae4ddc00000047403fda16e800000047403fee7c8800000047403ff9764400000047403fee5f040000004740400f1cc000000047403ff12f2000000047403fed0b6c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4716d7e0000047408b4689d000000047408c477b9c00000047408d47051500000047408e466d70600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854c2d4c8000004740864b941b60000047408749068a40000047408847d741800000474089474b25c0000047408a4716d7e0000047408b4689d000000047408c477b9c00000047408d47051500000047408e466d70600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4716d7e0000047408b4689d000000047408c477b9c00000047408d47051500000047408e466d70600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854c2d4c8000004740864b941b60000047408749068a40000047408847d741800000474089474b25c0000047408a4716d7e0000047408b4689d000000047408c477b9c00000047408d47051500000047408e466d70600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000473f8ffdc000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668619539.5602045,\n  \"relative_logdir\": \"tune_hp_757a3_00016_16_batch_size=2,learning_rate=0.0000,model=vgg16_2022-11-16_20-25-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00004\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"4_batch_size=2,learning_rate=0.0010,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6956952738965678,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.09688377380371,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00004\",\n    \"experiment_id\": \"7c022075c7be42cd804cbb6ba3e7aba3\",\n    \"date\": \"2022-11-16_17-27-19\",\n    \"timestamp\": 1668608839,\n    \"time_total_s\": 970.1380972862244,\n    \"pid\": 20404,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 970.1380972862244,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015622615814208984,\n    \"experiment_tag\": \"4_batch_size=2,learning_rate=0.0010,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668608839.511553,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6956954043135684,\n      \"min\": 0.695695078271067,\n      \"avg\": 0.6956952565076346,\n      \"last\": 0.6956952738965678,\n      \"last-5-avg\": 0.6956952217297676,\n      \"last-10-avg\": 0.6956952282506176\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324783,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.529945611953735,\n      \"min\": 31.456678867340088,\n      \"avg\": 32.33793657620746,\n      \"last\": 32.09688377380371,\n      \"last-5-avg\": 31.952567481994627,\n      \"last-10-avg\": 31.850417828559877\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.1380972862244,\n      \"min\": 42.529945611953735,\n      \"avg\": 506.7979771375656,\n      \"last\": 970.1380972862244,\n      \"last-5-avg\": 905.9329334259033,\n      \"last-10-avg\": 826.4378537416458\n    },\n    \"time_since_restore\": {\n      \"max\": 970.1380972862244,\n      \"min\": 42.529945611953735,\n      \"avg\": 506.7979771375656,\n      \"last\": 970.1380972862244,\n      \"last-5-avg\": 905.9329334259033,\n      \"last-10-avg\": 826.4378537416458\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015622615814208984,\n      \"min\": 0.015622615814208984,\n      \"avg\": 0.015622615814208984,\n      \"last\": 0.015622615814208984,\n      \"last-5-avg\": 0.015622615814208984,\n      \"last-10-avg\": 0.015622615814208984\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6432253253253473fe64322bc2bc2bc473fe6432299299299473fe64322bc2bc2bc473fe64322bc2bc2bc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6432276276276473fe6432299299299473fe6432299299299473fe6432302302302473fe6432299299299473fe6432253253253473fe64322bc2bc2bc473fe6432299299299473fe64322bc2bc2bc473fe64322bc2bc2bc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fa0d47000000047403fc23c2800000047403ff517980000004740402929e00000004740400c66b0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404003093800000047403f74e8e800000047403fd2174400000047403fb25a1c00000047403fbe5bcc00000047403fa0d47000000047403fc23c2800000047403ff517980000004740402929e00000004740400c66b0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a50072bc0000047408b4e190d00000047408c4dc1c9c0000047408d505467c0000047408e511ad2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855d42d7a0000047408658ea1ee00000474087577ad9000000474088550da9e0000047408953008840000047408a50072bc0000047408b4e190d00000047408c4dc1c9c0000047408d505467c0000047408e511ad2c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a50072bc0000047408b4e190d00000047408c4dc1c9c0000047408d505467c0000047408e511ad2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855d42d7a0000047408658ea1ee00000474087577ad9000000474088550da9e0000047408953008840000047408a50072bc0000047408b4e190d00000047408c4dc1c9c0000047408d505467c0000047408e511ad2c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000473f8ffec000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668607865.2451892,\n  \"relative_logdir\": \"tune_hp_757a3_00004_4_batch_size=2,learning_rate=0.0010,model=vgg16_2022-11-16_17-11-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00013\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-05,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"13_batch_size=4,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6352483635274773,\n    \"accuracy\": 63.24786324786324,\n    \"f1_score\": 0.5000000000000001,\n    \"time_this_iter_s\": 32.10185432434082,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00013\",\n    \"experiment_id\": \"f9fa099fc5a54c03b912add097e49215\",\n    \"date\": \"2022-11-16_19-53-06\",\n    \"timestamp\": 1668617586,\n    \"time_total_s\": 971.8144669532776,\n    \"pid\": 12188,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 971.8144669532776,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015592575073242188,\n    \"experiment_tag\": \"13_batch_size=4,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668617586.6354127,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.649746821476863,\n      \"min\": 0.6352483635274773,\n      \"avg\": 0.6427502993504883,\n      \"last\": 0.6352483635274773,\n      \"last-5-avg\": 0.642057852459769,\n      \"last-10-avg\": 0.6422853257921006\n    },\n    \"accuracy\": {\n      \"max\": 64.95726495726495,\n      \"min\": 58.54700854700855,\n      \"avg\": 60.59829059829058,\n      \"last\": 63.24786324786324,\n      \"last-5-avg\": 60.256410256410255,\n      \"last-10-avg\": 60.042735042735046\n    },\n    \"f1_score\": {\n      \"max\": 0.5232558139534884,\n      \"min\": 0.4049079754601227,\n      \"avg\": 0.45117811924633905,\n      \"last\": 0.5000000000000001,\n      \"last-5-avg\": 0.4504998264642466,\n      \"last-10-avg\": 0.4427004150951734\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.20463681221008,\n      \"min\": 31.83691167831421,\n      \"avg\": 32.39381556510924,\n      \"last\": 32.10185432434082,\n      \"last-5-avg\": 32.01902670860291,\n      \"last-10-avg\": 32.06666224002838\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 971.8144669532776,\n      \"min\": 35.20463681221008,\n      \"avg\": 504.3365222136178,\n      \"last\": 971.8144669532776,\n      \"last-5-avg\": 907.6685510635376,\n      \"last-10-avg\": 827.6887951135635\n    },\n    \"time_since_restore\": {\n      \"max\": 971.8144669532776,\n      \"min\": 35.20463681221008,\n      \"avg\": 504.3365222136178,\n      \"last\": 971.8144669532776,\n      \"last-5-avg\": 907.6685510635376,\n      \"last-10-avg\": 827.6887951135635\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015592575073242188,\n      \"min\": 0.015592575073242188,\n      \"avg\": 0.015592575073242188,\n      \"last\": 0.015592575073242188,\n      \"last-5-avg\": 0.015592575073242188,\n      \"last-10-avg\": 0.015592575073242188\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe47494a64a64a6473fe4a4bd89d89d8a473fe4a0ddf2df2df3473fe4ac8c08c08c09473fe453f460460460652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe45f2811811812473fe4946c2bc2bc2c473fe4c92a1ea1ea1f473fe4739483483483473fe49d0023023023473fe47494a64a64a6473fe4a4bd89d89d8a473fe4a0ddf2df2df3473fe4ac8c08c08c09473fe453f460460460652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404d7cb7cb7cb7cc47404d46046046046147404db36b36b36b3747404e8e38e38e38e447404f9fb9fb9fb9fb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404e8e38e38e38e447404e20d20d20d20d47404e57857857857847404d46046046046147404d46046046046147404d7cb7cb7cb7cc47404d46046046046147404db36b36b36b3747404e8e38e38e38e447404f9fb9fb9fb9fb652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430889da95a85d89da3f94869452946807680d4308cfc83b7f8bd3da3f94869452946807680d43088e20d27a01dbdc3f94869452946807680d430810df417c07f1dd3f94869452946807680d4308010000000000e03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089dd8899dd889dd3f94869452946807680d4308d58346def95bdc3f94869452946807680d4308bed1d4f9b587dc3f94869452946807680d43083a691f2403ead93f94869452946807680d4308cfc83b7f8bd3da3f94869452946807680d430889da95a85d89da3f94869452946807680d4308cfc83b7f8bd3da3f94869452946807680d43088e20d27a01dbdc3f94869452946807680d430810df417c07f1dd3f94869452946807680d4308010000000000e03f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fd63fd800000047404009e2ba00000047403ffe12fc0000004740400b17a20000004740400d0990000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404033069e00000047404023093800000047403fe99be800000047403ffe631800000047403ffe2e6c00000047403fd63fd800000047404009e2ba00000047403ffe12fc0000004740400b17a20000004740400d0990000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5c7330a0000047408b5d115c40000047408c5d01f420000047408d5db36e40000047408e5e8407400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855c5f330000004740865e8fc68000004740875ddca5c000004740885dcfbe8000004740895dc131e0000047408a5c7330a0000047408b5d115c40000047408c5d01f420000047408d5db36e40000047408e5e8407400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5c7330a0000047408b5d115c40000047408c5d01f420000047408d5db36e40000047408e5e8407400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855c5f330000004740865e8fc68000004740875ddca5c000004740885dcfbe8000004740895dc131e0000047408a5c7330a0000047408b5d115c40000047408c5d01f420000047408d5db36e40000047408e5e8407400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000473f8fef0000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668616610.94688,\n  \"relative_logdir\": \"tune_hp_757a3_00013_13_batch_size=4,learning_rate=0.0000,model=vgg16_2022-11-16_19-36-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00010\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.0001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"10_batch_size=8,learning_rate=0.0001,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6788266825879741,\n    \"accuracy\": 51.70940170940172,\n    \"f1_score\": 0.09600000000000002,\n    \"time_this_iter_s\": 32.10322618484497,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00010\",\n    \"experiment_id\": \"4e8eb252097644e2a6bfab133fd546db\",\n    \"date\": \"2022-11-16_19-04-28\",\n    \"timestamp\": 1668614668,\n    \"time_total_s\": 966.1667017936707,\n    \"pid\": 25596,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 966.1667017936707,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"10_batch_size=8,learning_rate=0.0001,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668614668.30398,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6890470716688368,\n      \"min\": 0.6587522457807492,\n      \"avg\": 0.6734393584422576,\n      \"last\": 0.6788266825879741,\n      \"last-5-avg\": 0.6758809016301082,\n      \"last-10-avg\": 0.6758961538983206\n    },\n    \"accuracy\": {\n      \"max\": 53.41880341880342,\n      \"min\": 51.28205128205128,\n      \"avg\": 52.521367521367495,\n      \"last\": 51.70940170940172,\n      \"last-5-avg\": 52.56410256410256,\n      \"last-10-avg\": 52.64957264957265\n    },\n    \"f1_score\": {\n      \"max\": 0.15503875968992248,\n      \"min\": 0.08064516129032258,\n      \"avg\": 0.11499331184823278,\n      \"last\": 0.09600000000000002,\n      \"last-5-avg\": 0.1146025908051816,\n      \"last-10-avg\": 0.11889616537080876\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.27752184867859,\n      \"min\": 31.665144205093384,\n      \"avg\": 32.20555672645568,\n      \"last\": 32.10322618484497,\n      \"last-5-avg\": 31.99270887374878,\n      \"last-10-avg\": 32.06030688285828\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.1667017936707,\n      \"min\": 35.27752184867859,\n      \"avg\": 500.54111227194466,\n      \"last\": 966.1667017936707,\n      \"last-5-avg\": 902.0935762405395,\n      \"last-10-avg\": 822.0660492420196\n    },\n    \"time_since_restore\": {\n      \"max\": 966.1667017936707,\n      \"min\": 35.27752184867859,\n      \"avg\": 500.54111227194466,\n      \"last\": 966.1667017936707,\n      \"last-5-avg\": 902.0935762405395,\n      \"last-10-avg\": 822.0660492420196\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5f441c71c71c7473fe55bd811811812473fe56fa5be5be5be473fe5ab6299299299473fe5b8f2bc2bc2bc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe57fa8c08c08c1473fe5bef7ee7ee7ee473fe5db6ee7ee7ee8473fe5a249d89d89d9473fe568fb59b59b5a473fe5f441c71c71c7473fe55bd811811812473fe56fa5be5be5be473fe5ab6299299299473fe5b8f2bc2bc2bc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ab59b59b59b5a47404ab59b59b59b5a47404a11811811811947404a118118118119474049dacdacdacdae652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a7ee7ee7ee7ef47404ab59b59b59b5a474049dacdacdacdae47404a48348348348447404a7ee7ee7ee7ef47404ab59b59b59b5a47404ab59b59b59b5a47404a11811811811947404a118118118119474049dacdacdacdae652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308894422914824c23f94869452946807680d4308894422914824c23f94869452946807680d4308c618638c31c6b83f94869452946807680d4308c618638c31c6b83f94869452946807680d4308fb7e6abc7493b83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000c23f94869452946807680d4308f6843d614fd8c33f94869452946807680d4308d114024d21d0b43f94869452946807680d430879e9263108acbc3f94869452946807680d4308100441100441c03f94869452946807680d4308894422914824c23f94869452946807680d4308894422914824c23f94869452946807680d4308c618638c31c6b83f94869452946807680d4308c618638c31c6b83f94869452946807680d4308fb7e6abc7493b83f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fd66f500000004740400b1c1e00000047403ff1156000000047403ffe80e40000004740400d3684000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401370b00000004740400b09940000004740403308b400000047404009210800000047403fee6fe000000047403fd66f500000004740400b1c1e00000047403ff1156000000047403ffe80e40000004740400d3684000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a30538b80000047408b31054d60000047408c308df860000047408d3081ff80000047408e315567c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852db95d0000004740862e69f6400000474087319a81800000474088322c9200000047408931a01100000047408a30538b80000047408b31054d60000047408c308df860000047408d3081ff80000047408e315567c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a30538b80000047408b31054d60000047408c308df860000047408d3081ff80000047408e315567c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852db95d0000004740862e69f6400000474087319a81800000474088322c9200000047408931a01100000047408a30538b80000047408b31054d60000047408c308df860000047408d3081ff80000047408e315567c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668613698.2478483,\n  \"relative_logdir\": \"tune_hp_757a3_00010_10_batch_size=8,learning_rate=0.0001,model=vgg16_2022-11-16_18-48-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00005\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.001,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"5_batch_size=4,learning_rate=0.0010,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6995309030907786,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.685084581375122,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00005\",\n    \"experiment_id\": \"37c1ebdc804e4664aca78449f2dd1eb7\",\n    \"date\": \"2022-11-16_17-43-32\",\n    \"timestamp\": 1668609812,\n    \"time_total_s\": 968.0109581947327,\n    \"pid\": 19168,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 968.0109581947327,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"5_batch_size=4,learning_rate=0.0010,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668609812.4432333,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6995313595502805,\n      \"min\": 0.6995309030907786,\n      \"avg\": 0.6995310639384125,\n      \"last\": 0.6995309030907786,\n      \"last-5-avg\": 0.6995310856745792,\n      \"last-10-avg\": 0.6995310856745793\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324783,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.101818323135376,\n      \"min\": 31.68084716796875,\n      \"avg\": 32.26703193982442,\n      \"last\": 31.685084581375122,\n      \"last-5-avg\": 31.805227184295653,\n      \"last-10-avg\": 31.857642388343812\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 968.0109581947327,\n      \"min\": 35.101818323135376,\n      \"avg\": 503.38048379421235,\n      \"last\": 968.0109581947327,\n      \"last-5-avg\": 904.5008460044861,\n      \"last-10-avg\": 824.8942397117614\n    },\n    \"time_since_restore\": {\n      \"max\": 968.0109581947327,\n      \"min\": 35.101818323135376,\n      \"avg\": 503.38048379421235,\n      \"last\": 968.0109581947327,\n      \"last-5-avg\": 904.5008460044861,\n      \"last-10-avg\": 824.8942397117614\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6628f0af0af0b473fe6628f96f96f97473fe6628ee7ee7ee8473fe6628ee7ee7ee8473fe6628ea1ea1ea2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6628f0af0af0b473fe6628ec4ec4ec5473fe6628f2df2df2e473fe6628ee7ee7ee8473fe6628f2df2df2e473fe6628f0af0af0b473fe6628f96f96f97473fe6628ee7ee7ee8473fe6628ee7ee7ee8473fe6628ea1ea1ea2652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040035d1200000047403fba042000000047403fae4c0000000047403fe844e000000047403faf61b4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401f278600000047403fbfa3bc00000047403fd64f4800000047403fd251e400000047403fe64bb8000000474040035d1200000047403fba042000000047403fae4c0000000047403fe844e000000047403faf61b4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4816bba0000047408b45e6dca0000047408c43593ca0000047408d429b63a0000047408e401671400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854d6c658000004740864b69836000004740874a1bfda0000047408848ae8cc0000047408947e0ea80000047408a4816bba0000047408b45e6dca0000047408c43593ca0000047408d429b63a0000047408e401671400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4816bba0000047408b45e6dca0000047408c43593ca0000047408d429b63a0000047408e401671400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854d6c658000004740864b69836000004740874a1bfda0000047408848ae8cc0000047408947e0ea80000047408a4816bba0000047408b45e6dca0000047408c43593ca0000047408d429b63a0000047408e401671400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668608840.5585139,\n  \"relative_logdir\": \"tune_hp_757a3_00005_5_batch_size=4,learning_rate=0.0010,model=vgg16_2022-11-16_17-27-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00014\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-05,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"14_batch_size=8,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6150302071856637,\n    \"accuracy\": 63.67521367521367,\n    \"f1_score\": 0.5502645502645503,\n    \"time_this_iter_s\": 32.00256133079529,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00014\",\n    \"experiment_id\": \"20c3b6018ab3481bbd72af409bba6145\",\n    \"date\": \"2022-11-16_20-09-25\",\n    \"timestamp\": 1668618565,\n    \"time_total_s\": 974.3446359634399,\n    \"pid\": 23088,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 974.3446359634399,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"14_batch_size=8,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668618565.0103552,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6198965219350961,\n      \"min\": 0.6003406883304955,\n      \"avg\": 0.6106517693935296,\n      \"last\": 0.6150302071856637,\n      \"last-5-avg\": 0.6085863031892694,\n      \"last-10-avg\": 0.6095820043840978\n    },\n    \"accuracy\": {\n      \"max\": 69.23076923076923,\n      \"min\": 63.67521367521367,\n      \"avg\": 66.18233618233617,\n      \"last\": 63.67521367521367,\n      \"last-5-avg\": 65.98290598290598,\n      \"last-10-avg\": 66.15384615384615\n    },\n    \"f1_score\": {\n      \"max\": 0.6256410256410257,\n      \"min\": 0.5454545454545455,\n      \"avg\": 0.5826166844442099,\n      \"last\": 0.5502645502645503,\n      \"last-5-avg\": 0.5817084305145158,\n      \"last-10-avg\": 0.5821168608103415\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.07282781600952,\n      \"min\": 31.8760724067688,\n      \"avg\": 32.47815453211466,\n      \"last\": 32.00256133079529,\n      \"last-5-avg\": 32.19376363754272,\n      \"last-10-avg\": 32.156797647476196\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 974.3446359634399,\n      \"min\": 35.07282781600952,\n      \"avg\": 505.659370748202,\n      \"last\": 974.3446359634399,\n      \"last-5-avg\": 910.194620513916,\n      \"last-10-avg\": 829.5838877916336\n    },\n    \"time_since_restore\": {\n      \"max\": 974.3446359634399,\n      \"min\": 35.07282781600952,\n      \"avg\": 505.659370748202,\n      \"last\": 974.3446359634399,\n      \"last-5-avg\": 910.194620513916,\n      \"last-10-avg\": 829.5838877916336\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe373bbe5be5be6473fe358173f73f73f473fe3634276276276473fe382487a87a87b473fe3ae53d43d43d4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe37a089d89d89e473fe354a9fb9fb9fc473fe3bbfbc2bc2bc3473fe3862992992993473fe3a06b59b59b5a473fe373bbe5be5be6473fe358173f73f73f473fe3634276276276473fe382487a87a87b473fe3ae53d43d43d4652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404fd66d66d66d664740508f50f50f50f54740514ec4ec4ec4ec474050c6046046046047404fd66d66d66d66652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474050aaaaaaaaaaaa4740508f50f50f50f5474050589d89d89d8a4740508f50f50f50f5474050c6046046046047404fd66d66d66d664740508f50f50f50f54740514ec4ec4ec4ec474050c6046046046047404fd66d66d66d66652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430875d145175d74e13f94869452946807680d43082d5ef944cce6e23f94869452946807680d4308cf467d67a3bee33f94869452946807680d4308d3355dd3355de33f94869452946807680d4308bd19f166c49be13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cf2d71eaf7dce23f94869452946807680d4308fd29f5a7d49fe23f94869452946807680d4308d31fb1803bfde13f94869452946807680d4308d25dc694afc3e23f94869452946807680d4308692fa1bd84f6e23f94869452946807680d430875d145175d74e13f94869452946807680d43082d5ef944cce6e23f94869452946807680d4308cf467d67a3bee33f94869452946807680d4308d3355dd3355de33f94869452946807680d4308bd19f166c49be13f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740402c37e20000004740403d53540000004740401509cc00000047403ffa32980000004740400053ee000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404011086e00000047403ffe4b9c00000047403fe046480000004740400f37340000004740403d28a40000004740402c37e20000004740403d53540000004740401509cc00000047403ffa32980000004740400053ee000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a6dc52ae0000047408b719a6020000047408c72eafce0000047408d72bc91a0000047408e72c1d0800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408567472020000047408667397d000000474087663baf400000474088672f228000004740896b01acc0000047408a6dc52ae0000047408b719a6020000047408c72eafce0000047408d72bc91a0000047408e72c1d0800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a6dc52ae0000047408b719a6020000047408c72eafce0000047408d72bc91a0000047408e72c1d0800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408567472020000047408667397d000000474087663baf400000474088672f228000004740896b01acc0000047408a6dc52ae0000047408b719a6020000047408c72eafce0000047408d72bc91a0000047408e72c1d0800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668617586.8072205,\n  \"relative_logdir\": \"tune_hp_757a3_00014_14_batch_size=8,learning_rate=0.0000,model=vgg16_2022-11-16_19-53-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00017\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-06,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"17_batch_size=4,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6650870559561965,\n    \"accuracy\": 55.12820512820513,\n    \"f1_score\": 0.1984732824427481,\n    \"time_this_iter_s\": 32.13391423225403,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00017\",\n    \"experiment_id\": \"3817a3575ed0414aa974dca9f83cc415\",\n    \"date\": \"2022-11-16_20-58-00\",\n    \"timestamp\": 1668621480,\n    \"time_total_s\": 963.7067260742188,\n    \"pid\": 25820,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 963.7067260742188,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"17_batch_size=4,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668621480.9116983,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6773746849125267,\n      \"min\": 0.6618459326589209,\n      \"avg\": 0.6699388835504859,\n      \"last\": 0.6650870559561965,\n      \"last-5-avg\": 0.6684092986278045,\n      \"last-10-avg\": 0.6707281194181525\n    },\n    \"accuracy\": {\n      \"max\": 55.98290598290598,\n      \"min\": 49.14529914529914,\n      \"avg\": 53.26210826210823,\n      \"last\": 55.12820512820513,\n      \"last-5-avg\": 53.162393162393165,\n      \"last-10-avg\": 52.99145299145299\n    },\n    \"f1_score\": {\n      \"max\": 0.22556390977443605,\n      \"min\": 0.06299212598425197,\n      \"avg\": 0.15632773395354577,\n      \"last\": 0.1984732824427481,\n      \"last-5-avg\": 0.16127354811865874,\n      \"last-10-avg\": 0.15200696636702168\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.86855602264404,\n      \"min\": 31.774978160858154,\n      \"avg\": 32.12355753580727,\n      \"last\": 32.13391423225403,\n      \"last-5-avg\": 32.0727499961853,\n      \"last-10-avg\": 32.06517791748047\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 963.7067260742188,\n      \"min\": 34.86855602264404,\n      \"avg\": 498.9553125778833,\n      \"last\": 963.7067260742188,\n      \"last-5-avg\": 899.5196411132813,\n      \"last-10-avg\": 819.4082274198532\n    },\n    \"time_since_restore\": {\n      \"max\": 963.7067260742188,\n      \"min\": 34.86855602264404,\n      \"avg\": 498.9553125778833,\n      \"last\": 963.7067260742188,\n      \"last-5-avg\": 899.5196411132813,\n      \"last-10-avg\": 819.4082274198532\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe55b094c94c94d473fe57d9ea1ea1ea2473fe531e66d66d66d473fe59f187a87a87b473fe54864a64a64a6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5a1bdacdacdad473fe52dd785785785473fe596de38e38e39473fe59c7f96f96f97473fe5ad0dacdacdad473fe55b094c94c94d473fe57d9ea1ea1ea2473fe531e66d66d66d473fe59f187a87a87b473fe54864a64a64a6652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bfdcfdcfdcfdd47404a7ee7ee7ee7ef47404a48348348348447404892992992992947404b906906906907652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef47404a7ee7ee7ee7ef474049a41a41a41a4147404aec4ec4ec4ec547404bfdcfdcfdcfdd47404a7ee7ee7ee7ef47404a48348348348447404892992992992947404b906906906907652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f3cdd13747dfcc3f94869452946807680d4308565555555555c53f94869452946807680d43088769ee82bf8ac33f94869452946807680d4308080402814020b03f94869452946807680d4308fc559c909267c93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000c23f94869452946807680d4308143bb1133bb1c33f94869452946807680d4308000000000000c23f94869452946807680d4308000000000000bc3f94869452946807680d4308965aa9955aa9c53f94869452946807680d4308f3cdd13747dfcc3f94869452946807680d4308565555555555c53f94869452946807680d43088769ee82bf8ac33f94869452946807680d4308080402814020b03f94869452946807680d4308fc559c909267c93f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400f519800000047403fee17ac0000004740400909ba0000004740400e041a00000047404011241a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fee90d80000004740402ef04a00000047404008315c00000047403ff7301800000047403ff5b80c0000004740400f519800000047403fee17ac0000004740400909ba0000004740400e041a00000047404011241a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a1bb383c0000047408b1b244120000047408c1bb4dcc0000047408d1c951e60000047408e1da760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408517e50ec000004740861ad4136000004740871b57292000004740881b10a9e000004740891abe6a40000047408a1bb383c0000047408b1b244120000047408c1bb4dcc0000047408d1c951e60000047408e1da760000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a1bb383c0000047408b1b244120000047408c1bb4dcc0000047408d1c951e60000047408e1da760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408517e50ec000004740861ad4136000004740871b57292000004740881b10a9e000004740891abe6a40000047408a1bb383c0000047408b1b244120000047408c1bb4dcc0000047408d1c951e60000047408e1da760000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668620513.3153965,\n  \"relative_logdir\": \"tune_hp_757a3_00017_17_batch_size=4,learning_rate=0.0000,model=vgg16_2022-11-16_20-41-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00018\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-06,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"18_batch_size=8,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.700241219284188,\n    \"accuracy\": 54.27350427350427,\n    \"f1_score\": 0.30967741935483867,\n    \"time_this_iter_s\": 32.3904013633728,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00018\",\n    \"experiment_id\": \"128fb558c8034fe5a8396b3e73a9eb6a\",\n    \"date\": \"2022-11-16_21-14-19\",\n    \"timestamp\": 1668622459,\n    \"time_total_s\": 973.4930171966553,\n    \"pid\": 9636,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 973.4930171966553,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"18_batch_size=8,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668622459.3098164,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7095469939403045,\n      \"min\": 0.6929481049888154,\n      \"avg\": 0.6989217622327666,\n      \"last\": 0.700241219284188,\n      \"last-5-avg\": 0.6980792053744326,\n      \"last-10-avg\": 0.6994831639477329\n    },\n    \"accuracy\": {\n      \"max\": 59.82905982905983,\n      \"min\": 51.28205128205128,\n      \"avg\": 54.43019943019943,\n      \"last\": 54.27350427350427,\n      \"last-5-avg\": 55.47008547008547,\n      \"last-10-avg\": 54.7008547008547\n    },\n    \"f1_score\": {\n      \"max\": 0.4024390243902439,\n      \"min\": 0.2448979591836735,\n      \"avg\": 0.3026287453872729,\n      \"last\": 0.30967741935483867,\n      \"last-5-avg\": 0.322517883927052,\n      \"last-10-avg\": 0.30703539983015116\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.58541417121887,\n      \"min\": 32.04149556159973,\n      \"avg\": 32.449767239888516,\n      \"last\": 32.3904013633728,\n      \"last-5-avg\": 32.32642436027527,\n      \"last-10-avg\": 32.31947741508484\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 973.4930171966553,\n      \"min\": 35.58541417121887,\n      \"avg\": 504.75744515260055,\n      \"last\": 973.4930171966553,\n      \"last-5-avg\": 908.7315083503723,\n      \"last-10-avg\": 827.9306109905243\n    },\n    \"time_since_restore\": {\n      \"max\": 973.4930171966553,\n      \"min\": 35.58541417121887,\n      \"avg\": 504.75744515260055,\n      \"last\": 973.4930171966553,\n      \"last-5-avg\": 908.7315083503723,\n      \"last-10-avg\": 827.9306109905243\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe66f8c2bc2bc2c473fe6579023023023473fe652987a87a87b473fe62f3df2df2df3473fe6686046046046652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6476a64a64a65473fe65af785785785473fe643a89d89d89e473fe6abc7a87a87a8473fe69283f73f73f7473fe66f8c2bc2bc2c473fe6579023023023473fe652987a87a87b473fe62f3df2df2df3473fe6686046046046652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b59b59b59b59c47404dea1ea1ea1ea247404c34834834834847404a11811811811947404b230230230230652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404b23023023023047404b90690690690747404b90690690690747404a11811811811947404a7ee7ee7ee7ef47404b59b59b59b59c47404dea1ea1ea1ea247404c34834834834847404a11811811811947404b230230230230652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308354883344883d43f94869452946807680d4308bd86f21aca6bd83f94869452946807680d43080971567e429cd53f94869452946807680d4308790de53594d7d03f94869452946807680d4308d1131c3dc1d1d33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d1131c3dc1d1d33f94869452946807680d43087003866a3ae6d23f94869452946807680d4308967b1a61b9a7d13f94869452946807680d4308d2200dd2200dd23f94869452946807680d4308f42ddff22ddfd23f94869452946807680d4308354883344883d43f94869452946807680d4308bd86f21aca6bd83f94869452946807680d43080971567e429cd53f94869452946807680d4308790de53594d7d03f94869452946807680d4308d1131c3dc1d1d33f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740401daabe0000004740402da5da000000474040090b3c0000004740404a94de00000047404031f8ac000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040273a4e0000004740401139a20000004740402b40740000004740402508200000004740403f487a0000004740401daabe0000004740402da5da000000474040090b3c0000004740404a94de00000047404031f8ac000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a60bdc900000047408b639826a0000047408c6428da60000047408d68d22840000047408e6bf1b3000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408554d67220000047408655ea0c400000474087589e138000004740885aee958000004740895ee31d20000047408a60bdc900000047408b639826a0000047408c6428da60000047408d68d22840000047408e6bf1b3000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a60bdc900000047408b639826a0000047408c6428da60000047408d68d22840000047408e6bf1b3000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408554d67220000047408655ea0c400000474087589e138000004740885aee958000004740895ee31d20000047408a60bdc900000047408b639826a0000047408c6428da60000047408d68d22840000047408e6bf1b3000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668621481.8648849,\n  \"relative_logdir\": \"tune_hp_757a3_00018_18_batch_size=8,learning_rate=0.0000,model=vgg16_2022-11-16_20-58-01\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00019\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-06,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"19_batch_size=16,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6809264615050747,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.039345026016235,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00019\",\n    \"experiment_id\": \"139d6462c296456494fa5b7c28b1b430\",\n    \"date\": \"2022-11-16_21-30-28\",\n    \"timestamp\": 1668623428,\n    \"time_total_s\": 964.6697134971619,\n    \"pid\": 17980,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 964.6697134971619,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"19_batch_size=16,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668623428.072293,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6840697720519497,\n      \"min\": 0.666013407910991,\n      \"avg\": 0.6747532162571223,\n      \"last\": 0.6809264615050747,\n      \"last-5-avg\": 0.6759682027702658,\n      \"last-10-avg\": 0.6764008024818876\n    },\n    \"accuracy\": {\n      \"max\": 49.14529914529914,\n      \"min\": 48.29059829059829,\n      \"avg\": 48.37606837606837,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 48.376068376068375,\n      \"last-10-avg\": 48.37606837606837\n    },\n    \"f1_score\": {\n      \"max\": 0.032520325203252036,\n      \"min\": 0.0,\n      \"avg\": 0.003269803189835177,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.003278688524590164,\n      \"last-10-avg\": 0.003278688524590164\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.78950071334839,\n      \"min\": 31.587037801742554,\n      \"avg\": 32.15565711657205,\n      \"last\": 32.039345026016235,\n      \"last-5-avg\": 31.987528800964355,\n      \"last-10-avg\": 32.07504980564117\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 964.6697134971619,\n      \"min\": 34.78950071334839,\n      \"avg\": 499.5245107889173,\n      \"last\": 964.6697134971619,\n      \"last-5-avg\": 900.5855923175811,\n      \"last-10-avg\": 820.3786113977433\n    },\n    \"time_since_restore\": {\n      \"max\": 964.6697134971619,\n      \"min\": 34.78950071334839,\n      \"avg\": 499.5245107889173,\n      \"last\": 964.6697134971619,\n      \"last-5-avg\": 900.5855923175811,\n      \"last-10-avg\": 820.3786113977433\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5cd0d89d89d8a473fe5918c08c08c09473fe5aeed20d20d21473fe54ffb59b59b5a473fe5ca264a64a64a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5a03aaaaaaaab473fe5c0564a64a64a473fe5d6ee15e15e16473fe595d023023023473fe57dc96f96f970473fe5cd0d89d89d8a473fe5918c08c08c09473fe5aeed20d20d21473fe54ffb59b59b5a473fe5ca264a64a64a652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740485be5be5be5be474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740482532532532534740482532532532534740482532532532534740482532532532534740485be5be5be5be4740485be5be5be5be474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083bdabc4f71c9903f94869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d43083bdabc4f71c9903f94869452946807680d43083bdabc4f71c9903f94869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f96481c0000004740401b53bc0000004740401f2d5e00000047403fdaac9c000000474040050942000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401e86c600000047403fb23ca40000004740401908c400000047404001f87e00000047404055654000000047403f96481c0000004740401b53bc0000004740401f2d5e00000047403fdaac9c000000474040050942000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a228d8820000047408b2442c3e0000047408c263599c0000047408d250afea0000047408e255b92c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852142fa0000004740861ed4df20000047408720656b6000004740882084f340000047408925db4740000047408a228d8820000047408b2442c3e0000047408c263599c0000047408d250afea0000047408e255b92c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a228d8820000047408b2442c3e0000047408c263599c0000047408d250afea0000047408e255b92c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852142fa0000004740861ed4df20000047408720656b6000004740882084f340000047408925db4740000047408a228d8820000047408b2442c3e0000047408c263599c0000047408d250afea0000047408e255b92c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668622459.4660027,\n  \"relative_logdir\": \"tune_hp_757a3_00019_19_batch_size=16,learning_rate=0.0000,model=vgg16_2022-11-16_21-14-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00020\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-07,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"20_batch_size=2,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6931559244791666,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.805705547332764,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00020\",\n    \"experiment_id\": \"f52267e0ca114d47b0f3e006efc952a9\",\n    \"date\": \"2022-11-16_21-46-42\",\n    \"timestamp\": 1668624402,\n    \"time_total_s\": 970.7972667217255,\n    \"pid\": 21216,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 970.7972667217255,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"20_batch_size=2,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668624402.977946,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6999601706480368,\n      \"min\": 0.6876961471688035,\n      \"avg\": 0.6944103903919883,\n      \"last\": 0.6931559244791666,\n      \"last-5-avg\": 0.6951534173427484,\n      \"last-10-avg\": 0.6930021563146869\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.45014245014246,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.01612903225806452,\n      \"min\": 0.0,\n      \"avg\": 0.0005376344086021503,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.63067436218262,\n      \"min\": 31.680075883865356,\n      \"avg\": 32.359908890724164,\n      \"last\": 31.805705547332764,\n      \"last-5-avg\": 31.972148752212526,\n      \"last-10-avg\": 32.06418607234955\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.7972667217255,\n      \"min\": 42.63067436218262,\n      \"avg\": 506.4671128670373,\n      \"last\": 970.7972667217255,\n      \"last-5-avg\": 907.0745566368103,\n      \"last-10-avg\": 826.841492819786\n    },\n    \"time_since_restore\": {\n      \"max\": 970.7972667217255,\n      \"min\": 42.63067436218262,\n      \"avg\": 506.4671128670373,\n      \"last\": 970.7972667217255,\n      \"last-5-avg\": 907.0745566368103,\n      \"last-10-avg\": 826.841492819786\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6518d66d66d67473fe60a392992992a473fe6574c2bc2bc2c473fe65813d43d43d4473fe62e5555555555652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe62123b13b13b1473fe602136b36b36b473fe60ac8c08c08c1473fe6235a41a41a42473fe637e690690690473fe6518d66d66d67473fe60a392992992a473fe6574c2bc2bc2c473fe65813d43d43d4473fe62e5555555555652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404025082800000047403ffe3a5000000047403feb98a000000047403fda33bc00000047403fce42b8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404005553c000000474040251ea000000047404020d3ce00000047403fef36740000004740402118c000000047404025082800000047403ffe3a5000000047403feb98a000000047403fda33bc00000047403fce42b8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a59ce8240000047408b59c054c0000047408c591d19c0000047408d57eeb7a0000047408e5660cd600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408551939940000047408653e58340000047408755f2c0200000474088556c73c00000474089577dffc0000047408a59ce8240000047408b59c054c0000047408c591d19c0000047408d57eeb7a0000047408e5660cd600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a59ce8240000047408b59c054c0000047408c591d19c0000047408d57eeb7a0000047408e5660cd600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408551939940000047408653e58340000047408755f2c0200000474088556c73c00000474089577dffc0000047408a59ce8240000047408b59c054c0000047408c591d19c0000047408d57eeb7a0000047408e5660cd600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668623428.306613,\n  \"relative_logdir\": \"tune_hp_757a3_00020_20_batch_size=2,learning_rate=0.0000,model=vgg16_2022-11-16_21-30-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00021\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-07,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"21_batch_size=4,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6752703414004073,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.07575757575757576,\n    \"time_this_iter_s\": 32.07061290740967,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00021\",\n    \"experiment_id\": \"15ce1a9dcdea42c7b7ed157300a5c69e\",\n    \"date\": \"2022-11-16_22-02-52\",\n    \"timestamp\": 1668625372,\n    \"time_total_s\": 965.4393203258514,\n    \"pid\": 26088,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 965.4393203258514,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"21_batch_size=4,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668625372.4319506,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6857904287484976,\n      \"min\": 0.6671548174996661,\n      \"avg\": 0.6752637423001797,\n      \"last\": 0.6752703414004073,\n      \"last-5-avg\": 0.6735057341746795,\n      \"last-10-avg\": 0.674341055063101\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 46.15384615384615,\n      \"avg\": 48.36182336182335,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 48.63247863247863,\n      \"last-10-avg\": 48.63247863247862\n    },\n    \"f1_score\": {\n      \"max\": 0.16058394160583941,\n      \"min\": 0.030769230769230767,\n      \"avg\": 0.09113897256335464,\n      \"last\": 0.07575757575757576,\n      \"last-5-avg\": 0.10082955703393659,\n      \"last-10-avg\": 0.09574624056826628\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.96804404258728,\n      \"min\": 31.772473096847534,\n      \"avg\": 32.18131067752837,\n      \"last\": 32.07061290740967,\n      \"last-5-avg\": 32.05358352661133,\n      \"last-10-avg\": 32.17360200881958\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 965.4393203258514,\n      \"min\": 34.96804404258728,\n      \"avg\": 499.57943194707235,\n      \"last\": 965.4393203258514,\n      \"last-5-avg\": 901.4070703983307,\n      \"last-10-avg\": 821.0625413417816\n    },\n    \"time_since_restore\": {\n      \"max\": 965.4393203258514,\n      \"min\": 34.96804404258728,\n      \"avg\": 499.57943194707235,\n      \"last\": 965.4393203258514,\n      \"last-5-avg\": 901.4070703983307,\n      \"last-10-avg\": 821.0625413417816\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5b2fdcfdcfdd0473fe559550f50f50f473fe58097a87a87a8473fe59a1069069069473fe59bd08c08c08c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5adcf2df2df2e473fe56dda64a64a65473fe5a3d6d66d66d6473fe5b45d66d66d67473fe5935b9fb9fba0473fe5b2fdcfdcfdd0473fe559550f50f50f473fe58097a87a87a8473fe59a1069069069473fe59bd08c08c08c652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740489299299299294740489299299299294740496d66d66d66d647404713b13b13b13b474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048c94c94c94c95474048c94c94c94c954740482532532532534740485be5be5be5be4740478118118118114740489299299299294740489299299299294740496d66d66d66d647404713b13b13b13b474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873e501c93a57be3f94869452946807680d430873e501c93a57be3f94869452946807680d43087fdcbabc038ec43f94869452946807680d43081ff8811ff8819f3f94869452946807680d430865934d36d964b33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308279b6cb2c926bb3f94869452946807680d430866b7f0ab3191be3f94869452946807680d43088669ee82bf8ab33f94869452946807680d430846175d74d145b73f94869452946807680d4308071f7cf0c107af3f94869452946807680d430873e501c93a57be3f94869452946807680d430873e501c93a57be3f94869452946807680d43087fdcbabc038ec43f94869452946807680d43081ff8811ff8819f3f94869452946807680d430865934d36d964b33f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040165922000000474040007ad400000047404017465600000047403fd64df80000004740400909d8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040591dfc00000047403ff23c400000004740402108580000004740403b9ca40000004740400d09b0000000474040165922000000474040007ad400000047404017465600000047403fd64df80000004740400909d8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2ac49a80000047408b2acc47c0000047408c2c40ad20000047408d2af31ce0000047408e2b83ba600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408523323ba0000047408622c41da0000047408724d4a3200000474088288e6d600000474089295f0860000047408a2ac49a80000047408b2acc47c0000047408c2c40ad20000047408d2af31ce0000047408e2b83ba600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2ac49a80000047408b2acc47c0000047408c2c40ad20000047408d2af31ce0000047408e2b83ba600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408523323ba0000047408622c41da0000047408724d4a3200000474088288e6d600000474089295f0860000047408a2ac49a80000047408b2acc47c0000047408c2c40ad20000047408d2af31ce0000047408e2b83ba600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668624403.071673,\n  \"relative_logdir\": \"tune_hp_757a3_00021_21_batch_size=4,learning_rate=0.0000,model=vgg16_2022-11-16_21-46-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00022\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-07,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"22_batch_size=8,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7172168829502203,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.164369106292725,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00022\",\n    \"experiment_id\": \"f424d4f9f37246a9b46ab407a5b0b6b9\",\n    \"date\": \"2022-11-16_22-19-02\",\n    \"timestamp\": 1668626342,\n    \"time_total_s\": 965.9311668872833,\n    \"pid\": 20244,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 965.9311668872833,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"22_batch_size=8,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668626342.84644,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7202811607947717,\n      \"min\": 0.7017953334710537,\n      \"avg\": 0.709718251024556,\n      \"last\": 0.7172168829502203,\n      \"last-5-avg\": 0.7075082632211538,\n      \"last-10-avg\": 0.7088094466771835\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.008547008547005,\n      \"avg\": 47.42165242165242,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.9041793346405,\n      \"min\": 31.801735401153564,\n      \"avg\": 32.197705562909434,\n      \"last\": 32.164369106292725,\n      \"last-5-avg\": 32.173792552948,\n      \"last-10-avg\": 32.2021767616272\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 965.9311668872833,\n      \"min\": 34.9041793346405,\n      \"avg\": 499.6209109783172,\n      \"last\": 965.9311668872833,\n      \"last-5-avg\": 901.4199910163879,\n      \"last-10-avg\": 820.9670011043548\n    },\n    \"time_since_restore\": {\n      \"max\": 965.9311668872833,\n      \"min\": 34.9041793346405,\n      \"avg\": 499.6209109783172,\n      \"last\": 965.9311668872833,\n      \"last-5-avg\": 901.4199910163879,\n      \"last-10-avg\": 820.9670011043548\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6869dcfdcfdd0473fe6b33d66d66d67473fe688d118118118473fe67d6cb7cb7cb8473fe6f370d20d20d2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6f12069069069473fe6d2f627627627473fe6a53992992993473fe69a29fb9fb9fc473fe69aa785785785473fe6869dcfdcfdd0473fe6b33d66d66d67473fe688d118118118473fe67d6cb7cb7cb8473fe6f370d20d20d2652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fcd3e88000000474040194372000000474040352cd2000000474040252098000000474040150a0c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400d0ece0000004740401b0998000000474040316d600000004740400731c200000047404032d79400000047403fcd3e88000000474040194372000000474040352cd2000000474040252098000000474040150a0c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a26e95920000047408b287d9040000047408c2bd05d60000047408d2e2266e0000047408e2f7307a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408520176000000047408621c7f980000047408724decf8000004740882551eba00000474089287f64e0000047408a26e95920000047408b287d9040000047408c2bd05d60000047408d2e2266e0000047408e2f7307a00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a26e95920000047408b287d9040000047408c2bd05d60000047408d2e2266e0000047408e2f7307a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408520176000000047408621c7f980000047408724decf8000004740882551eba00000474089287f64e0000047408a26e95920000047408b287d9040000047408c2bd05d60000047408d2e2266e0000047408e2f7307a00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668625373.0099382,\n  \"relative_logdir\": \"tune_hp_757a3_00022_22_batch_size=8,learning_rate=0.0000,model=vgg16_2022-11-16_22-02-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00023\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-07,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"23_batch_size=16,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.696145995050414,\n    \"accuracy\": 52.991452991452995,\n    \"f1_score\": 0.08333333333333334,\n    \"time_this_iter_s\": 32.00812792778015,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00023\",\n    \"experiment_id\": \"b69756d95fdd46b088f0af53df2d81f3\",\n    \"date\": \"2022-11-16_22-35-10\",\n    \"timestamp\": 1668627310,\n    \"time_total_s\": 962.5410103797913,\n    \"pid\": 13512,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 962.5410103797913,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"23_batch_size=16,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668627310.2612805,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7056827382144765,\n      \"min\": 0.6870684501452323,\n      \"avg\": 0.6938999382518976,\n      \"last\": 0.696145995050414,\n      \"last-5-avg\": 0.6958436754014757,\n      \"last-10-avg\": 0.6937815674349792\n    },\n    \"accuracy\": {\n      \"max\": 55.12820512820513,\n      \"min\": 50.0,\n      \"avg\": 52.89173789173788,\n      \"last\": 52.991452991452995,\n      \"last-5-avg\": 52.73504273504274,\n      \"last-10-avg\": 52.60683760683761\n    },\n    \"f1_score\": {\n      \"max\": 0.18604651162790697,\n      \"min\": 0.033613445378151266,\n      \"avg\": 0.09515944057700916,\n      \"last\": 0.08333333333333334,\n      \"last-5-avg\": 0.08859295172325939,\n      \"last-10-avg\": 0.08551108092869378\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.80983376502991,\n      \"min\": 31.398895025253296,\n      \"avg\": 32.084700345993035,\n      \"last\": 32.00812792778015,\n      \"last-5-avg\": 31.842725610733034,\n      \"last-10-avg\": 31.78849744796753\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 962.5410103797913,\n      \"min\": 34.80983376502991,\n      \"avg\": 499.7242435773212,\n      \"last\": 962.5410103797913,\n      \"last-5-avg\": 898.5403687953949,\n      \"last-10-avg\": 819.1754960536957\n    },\n    \"time_since_restore\": {\n      \"max\": 962.5410103797913,\n      \"min\": 34.80983376502991,\n      \"avg\": 499.7242435773212,\n      \"last\": 962.5410103797913,\n      \"last-5-avg\": 898.5403687953949,\n      \"last-10-avg\": 819.1754960536957\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe65b2bc2bc2bc3473fe6286811811812473fe63cad20d20d21473fe64eacdacdacdb473fe646d3f73f73f7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe60a471c71c71c473fe61ec5be5be5be473fe62a9f96f96f97473fe621b41a41a41a473fe63773b13b13b1473fe65b2bc2bc2bc3473fe6286811811812473fe63cad20d20d21473fe64eacdacdacdb473fe646d3f73f73f7652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a7ee7ee7ee7ef47404a7ee7ee7ee7ef4740496d66d66d66d647404aec4ec4ec4ec547404a7ee7ee7ee7ef652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a11811811811947404ab59b59b59b5a47404a7ee7ee7ee7ef47404a483483483484474049a41a41a41a4147404a7ee7ee7ee7ef47404a7ee7ee7ee7ef4740496d66d66d66d647404aec4ec4ec4ec547404a7ee7ee7ee7ef652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430859479bf7292eb93f94869452946807680d4308e79c73ce39e7bc3f94869452946807680d430812c83511c835a13f94869452946807680d4308e67d8a4b8660bd3f94869452946807680d4308565555555555b53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ca10aca3cdfbb43f94869452946807680d4308d8ead9217063b93f94869452946807680d430859479bf7292eb93f94869452946807680d4308b543e0c63228b53f94869452946807680d4308999999999999a93f94869452946807680d430859479bf7292eb93f94869452946807680d4308e79c73ce39e7bc3f94869452946807680d430812c83511c835a13f94869452946807680d4308e67d8a4b8660bd3f94869452946807680d4308565555555555b53f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f661dfc00000047403fc28ec000000047403feddbf80000004740400f097a000000474040010a56000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9e4efc00000047403fd2178400000047403fb20ec800000047403fc661cc00000047403fc3064800000047403f661dfc00000047403fc28ec000000047403feddbf80000004740400f097a000000474040010a56000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a15cf6a80000047408b13e3e080000047408c1352c040000047408d144357e0000047408e1453fd400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085223207a0000047408620c2c3c000004740871e533a0000004740881c86486000004740891a9e7aa0000047408a15cf6a80000047408b13e3e080000047408c1352c040000047408d144357e0000047408e1453fd400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a15cf6a80000047408b13e3e080000047408c1352c040000047408d144357e0000047408e1453fd400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085223207a0000047408620c2c3c000004740871e533a0000004740881c86486000004740891a9e7aa0000047408a15cf6a80000047408b13e3e080000047408c1352c040000047408d144357e0000047408e1453fd400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668626343.7836926,\n  \"relative_logdir\": \"tune_hp_757a3_00023_23_batch_size=16,learning_rate=0.0000,model=vgg16_2022-11-16_22-19-03\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00024\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-08,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"24_batch_size=2,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7341123401609242,\n    \"accuracy\": 44.01709401709402,\n    \"f1_score\": 0.3068783068783069,\n    \"time_this_iter_s\": 32.49522423744202,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00024\",\n    \"experiment_id\": \"53d1d4349a574a8db24652ecb47c54bb\",\n    \"date\": \"2022-11-16_22-51-30\",\n    \"timestamp\": 1668628290,\n    \"time_total_s\": 975.8009188175201,\n    \"pid\": 11436,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 975.8009188175201,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"24_batch_size=2,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668628290.1237762,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7416238377236912,\n      \"min\": 0.7132369473449185,\n      \"avg\": 0.7267740298540162,\n      \"last\": 0.7341123401609242,\n      \"last-5-avg\": 0.7274973812266292,\n      \"last-10-avg\": 0.7297303224221254\n    },\n    \"accuracy\": {\n      \"max\": 50.427350427350426,\n      \"min\": 42.30769230769231,\n      \"avg\": 46.48148148148145,\n      \"last\": 44.01709401709402,\n      \"last-5-avg\": 46.324786324786324,\n      \"last-10-avg\": 45.81196581196581\n    },\n    \"f1_score\": {\n      \"max\": 0.43137254901960786,\n      \"min\": 0.2681564245810056,\n      \"avg\": 0.3498839077721361,\n      \"last\": 0.3068783068783069,\n      \"last-5-avg\": 0.3504939745728531,\n      \"last-10-avg\": 0.3425916445893314\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.5890679359436,\n      \"min\": 31.558807849884033,\n      \"avg\": 32.526697293917344,\n      \"last\": 32.49522423744202,\n      \"last-5-avg\": 32.40270314216614,\n      \"last-10-avg\": 32.44092643260956\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 975.8009188175201,\n      \"min\": 42.5890679359436,\n      \"avg\": 507.19146590232845,\n      \"last\": 975.8009188175201,\n      \"last-5-avg\": 910.9089853286744,\n      \"last-10-avg\": 829.833183813095\n    },\n    \"time_since_restore\": {\n      \"max\": 975.8009188175201,\n      \"min\": 42.5890679359436,\n      \"avg\": 507.19146590232845,\n      \"last\": 975.8009188175201,\n      \"last-5-avg\": 910.9089853286744,\n      \"last-10-avg\": 829.833183813095\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe741b811811812473fe7307ee7ee7ee8473fe7418627627627473fe734b4a64a64a6473fe77dd92992992a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe770c046046046473fe75cd08c08c08c473fe76126d66d66d6473fe7b04b7cb7cb7d473fe73e33f73f73f7473fe741b811811812473fe7307ee7ee7ee8473fe7418627627627473fe734b4a64a64a6473fe77dd92992992a652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046a64a64a64a65474047ee7ee7ee7ee84740474a64a64a64a6474047ee7ee7ee7ee8474046023023023023652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046a64a64a64a654740474a64a64a64a6474046023023023023474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474047ee7ee7ee7ee84740474a64a64a64a6474047ee7ee7ee7ee8474046023023023023652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430852dfd9a8ef6cd43f94869452946807680d4308f6285c8fc2f5d83f94869452946807680d4308f8c046ef8accd73f94869452946807680d4308565555555555d73f94869452946807680d43083f3af9e8e4a3d33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308264efd9e5be2d43f94869452946807680d4308976ff9966ff9d63f94869452946807680d4308d56972907929d13f94869452946807680d43080ad7a3703d0ad73f94869452946807680d43080ad7a3703d0ad73f94869452946807680d430852dfd9a8ef6cd43f94869452946807680d4308f6285c8fc2f5d83f94869452946807680d4308f8c046ef8accd73f94869452946807680d4308565555555555d73f94869452946807680d43083f3af9e8e4a3d33f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040249d40000000474040395ae400000047404029303e0000004740403b2efe0000004740403f6382000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740403b188400000047404033484200000047404039fe820000004740403d311a0000004740404d1782000000474040249d40000000474040395ae400000047404029303e0000004740403b2efe0000004740403f6382000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a70966e00000047408b742c1c40000047408c76bf2020000047408d7a721000000047408e7e6848200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855ed3a400000047408662082820000047408765a810400000474088697b21e000004740896e4c9a00000047408a70966e00000047408b742c1c40000047408c76bf2020000047408d7a721000000047408e7e6848200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a70966e00000047408b742c1c40000047408c76bf2020000047408d7a721000000047408e7e6848200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855ed3a400000047408662082820000047408765a810400000474088697b21e000004740896e4c9a00000047408a70966e00000047408b742c1c40000047408c76bf2020000047408d7a721000000047408e7e6848200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668627310.3706288,\n  \"relative_logdir\": \"tune_hp_757a3_00024_24_batch_size=2,learning_rate=0.0000,model=vgg16_2022-11-16_22-35-10\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00025\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-08,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"25_batch_size=4,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7087315616444645,\n    \"accuracy\": 47.008547008547005,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.816832780838013,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00025\",\n    \"experiment_id\": \"61c507e803cd4a1a9a4008518c874fd6\",\n    \"date\": \"2022-11-16_23-07-38\",\n    \"timestamp\": 1668629258,\n    \"time_total_s\": 964.0498247146606,\n    \"pid\": 26876,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 964.0498247146606,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"25_batch_size=4,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668629258.907278,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7105968507946047,\n      \"min\": 0.6915705102121729,\n      \"avg\": 0.7009027682138644,\n      \"last\": 0.7087315616444645,\n      \"last-5-avg\": 0.7030103112897302,\n      \"last-10-avg\": 0.700903581146501\n    },\n    \"accuracy\": {\n      \"max\": 47.008547008547005,\n      \"min\": 47.008547008547005,\n      \"avg\": 47.008547008547026,\n      \"last\": 47.008547008547005,\n      \"last-5-avg\": 47.008547008547005,\n      \"last-10-avg\": 47.008547008547005\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.08727169036865,\n      \"min\": 31.727646112442017,\n      \"avg\": 32.13499415715534,\n      \"last\": 31.816832780838013,\n      \"last-5-avg\": 31.846282386779784,\n      \"last-10-avg\": 31.92368538379669\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 964.0498247146606,\n      \"min\": 35.08727169036865,\n      \"avg\": 500.3647995471954,\n      \"last\": 964.0498247146606,\n      \"last-5-avg\": 900.4483991146087,\n      \"last-10-avg\": 820.5937866210937\n    },\n    \"time_since_restore\": {\n      \"max\": 964.0498247146606,\n      \"min\": 35.08727169036865,\n      \"avg\": 500.3647995471954,\n      \"last\": 964.0498247146606,\n      \"last-5-avg\": 900.4483991146087,\n      \"last-10-avg\": 820.5937866210937\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe67ab483483483473fe66d65e15e15e1473fe68b9460460460473fe659b0d20d20d2473fe6adedcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe658e71c71c71c473fe6289ec4ec4ec5473fe669f73f73f73f473fe67b5dcfdcfdd0473fe667dd20d20d21473fe67ab483483483473fe66d65e15e15e1473fe68b9460460460473fe659b0d20d20d2473fe6adedcfdcfdd0652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff37a8800000047403fea325800000047403fd22df800000047403fba470400000047403fd11bf4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ffa1500000000474040041b1200000047403fd676c000000047403ff241b80000004740401b308400000047403ff37a8800000047403fea325800000047403fd22df800000047403fba470400000047403fd11bf4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2627f040000047408b25798300000047408c240af2c0000047408d21dd2ae0000047408e20660a800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408526519ee0000047408626935000000047408725470600000047408824d913c00000474089268c1c00000047408a2627f040000047408b25798300000047408c240af2c0000047408d21dd2ae0000047408e20660a800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2627f040000047408b25798300000047408c240af2c0000047408d21dd2ae0000047408e20660a800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408526519ee0000047408626935000000047408725470600000047408824d913c00000474089268c1c00000047408a2627f040000047408b25798300000047408c240af2c0000047408d21dd2ae0000047408e20660a800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668628290.9829483,\n  \"relative_logdir\": \"tune_hp_757a3_00025_25_batch_size=4,learning_rate=0.0000,model=vgg16_2022-11-16_22-51-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00026\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-08,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"26_batch_size=8,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6855888040656717,\n    \"accuracy\": 55.12820512820513,\n    \"f1_score\": 0.15999999999999998,\n    \"time_this_iter_s\": 32.18218994140625,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00026\",\n    \"experiment_id\": \"da14ecfd3ae5425e8dab57e35a7f158d\",\n    \"date\": \"2022-11-16_23-23-53\",\n    \"timestamp\": 1668630233,\n    \"time_total_s\": 970.3126344680786,\n    \"pid\": 26072,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 970.3126344680786,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"26_batch_size=8,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668630233.7038605,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6967045710637019,\n      \"min\": 0.6736024383805755,\n      \"avg\": 0.6855933273619735,\n      \"last\": 0.6855888040656717,\n      \"last-5-avg\": 0.6855210524338942,\n      \"last-10-avg\": 0.684434326693543\n    },\n    \"accuracy\": {\n      \"max\": 56.837606837606835,\n      \"min\": 50.0,\n      \"avg\": 53.98860398860399,\n      \"last\": 55.12820512820513,\n      \"last-5-avg\": 53.67521367521368,\n      \"last-10-avg\": 54.01709401709402\n    },\n    \"f1_score\": {\n      \"max\": 0.2627737226277372,\n      \"min\": 0.033057851239669415,\n      \"avg\": 0.16460830453485115,\n      \"last\": 0.15999999999999998,\n      \"last-5-avg\": 0.13539032086889763,\n      \"last-10-avg\": 0.16139264439214335\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.961323261260986,\n      \"min\": 31.984029054641724,\n      \"avg\": 32.34375448226929,\n      \"last\": 32.18218994140625,\n      \"last-5-avg\": 32.28428082466125,\n      \"last-10-avg\": 32.2471286535263\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.3126344680786,\n      \"min\": 34.961323261260986,\n      \"avg\": 502.28067153294876,\n      \"last\": 970.3126344680786,\n      \"last-5-avg\": 905.7227249622345,\n      \"last-10-avg\": 825.1233330011368\n    },\n    \"time_since_restore\": {\n      \"max\": 970.3126344680786,\n      \"min\": 34.961323261260986,\n      \"avg\": 502.28067153294876,\n      \"last\": 970.3126344680786,\n      \"last-5-avg\": 905.7227249622345,\n      \"last-10-avg\": 825.1233330011368\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5d4e992992993473fe62d8b13b13b14473fe5ec8811811812473fe5cf9c94c94c95473fe5f057ee7ee7ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5ee26b36b36b3473fe5bc5af0af0af1473fe5f1008c08c08c473fe5a942df2df2df473fe61125e15e15e1473fe5d4e992992993473fe62d8b13b13b14473fe5ec8811811812473fe5cf9c94c94c95473fe5f057ee7ee7ee652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bc71c71c71c7247404900000000000047404b59b59b59b59c47404a7ee7ee7ee7ef47404b906906906907652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049dacdacdacdae47404aec4ec4ec4ec547404c6b36b36b36b347404aec4ec4ec4ec547404bc71c71c71c7247404bc71c71c71c7247404900000000000047404b59b59b59b59c47404a7ee7ee7ee7ef47404b906906906907652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308279b6cb2c926cb3f94869452946807680d43088f9ce66bf5eca03f94869452946807680d43083adabc4f71c9c03f94869452946807680d4308000000000000c23f94869452946807680d43087a14ae47e17ac43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430860c509297996c13f94869452946807680d4308922449922449c23f94869452946807680d4308adcb3be048d1d03f94869452946807680d430846175d74d145c73f94869452946807680d4308279b6cb2c926cb3f94869452946807680d4308279b6cb2c926cb3f94869452946807680d43088f9ce66bf5eca03f94869452946807680d43083adabc4f71c9c03f94869452946807680d4308000000000000c23f94869452946807680d43087a14ae47e17ac43f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404028c5360000004740400b20d40000004740402f07a60000004740403bb0e2000000474040175200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402dbdac0000004740401377340000004740401b099c0000004740400709fe000000474040231a1200000047404028c5360000004740400b20d40000004740402f07a60000004740403bb0e2000000474040175200000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a49ad90c0000047408b4a5f9e00000047408c4d501860000047408d510b2680000047408e528046800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854196ef60000047408642ce62a00000474087447efc60000047408844ef9c40000047408947213d60000047408a49ad90c0000047408b4a5f9e00000047408c4d501860000047408d510b2680000047408e528046800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a49ad90c0000047408b4a5f9e00000047408c4d501860000047408d510b2680000047408e528046800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854196ef60000047408642ce62a00000474087447efc60000047408844ef9c40000047408947213d60000047408a49ad90c0000047408b4a5f9e00000047408c4d501860000047408d510b2680000047408e528046800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668629259.3604121,\n  \"relative_logdir\": \"tune_hp_757a3_00026_26_batch_size=8,learning_rate=0.0000,model=vgg16_2022-11-16_23-07-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00027\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-08,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"27_batch_size=16,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6970449594350961,\n    \"accuracy\": 59.82905982905983,\n    \"f1_score\": 0.5566037735849056,\n    \"time_this_iter_s\": 32.08751606941223,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00027\",\n    \"experiment_id\": \"180a2eff31db486e9f4e6195356c504e\",\n    \"date\": \"2022-11-16_23-40-05\",\n    \"timestamp\": 1668631205,\n    \"time_total_s\": 966.9682130813599,\n    \"pid\": 22932,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 966.9682130813599,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015625476837158203,\n    \"experiment_tag\": \"27_batch_size=16,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668631205.092912,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.714746589334602,\n      \"min\": 0.6887276804345286,\n      \"avg\": 0.6995256907579905,\n      \"last\": 0.6970449594350961,\n      \"last-5-avg\": 0.703208988548344,\n      \"last-10-avg\": 0.7009401109483507\n    },\n    \"accuracy\": {\n      \"max\": 64.95726495726495,\n      \"min\": 52.13675213675214,\n      \"avg\": 57.6210826210826,\n      \"last\": 59.82905982905983,\n      \"last-5-avg\": 56.75213675213676,\n      \"last-10-avg\": 57.222222222222214\n    },\n    \"f1_score\": {\n      \"max\": 0.6306306306306306,\n      \"min\": 0.463768115942029,\n      \"avg\": 0.5349772686463661,\n      \"last\": 0.5566037735849056,\n      \"last-5-avg\": 0.5232850432260564,\n      \"last-10-avg\": 0.5268468432079145\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.83556389808655,\n      \"min\": 31.711320638656616,\n      \"avg\": 32.232273769378644,\n      \"last\": 32.08751606941223,\n      \"last-5-avg\": 32.30289282798767,\n      \"last-10-avg\": 32.25439593791962\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.9682130813599,\n      \"min\": 34.83556389808655,\n      \"avg\": 500.0944338639577,\n      \"last\": 966.9682130813599,\n      \"last-5-avg\": 902.7695426940918,\n      \"last-10-avg\": 821.7373700380325\n    },\n    \"time_since_restore\": {\n      \"max\": 966.9682130813599,\n      \"min\": 34.83556389808655,\n      \"avg\": 500.0944338639577,\n      \"last\": 966.9682130813599,\n      \"last-5-avg\": 902.7695426940918,\n      \"last-10-avg\": 821.7373700380325\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015625476837158203,\n      \"min\": 0.015625476837158203,\n      \"avg\": 0.015625476837158203,\n      \"last\": 0.015625476837158203,\n      \"last-5-avg\": 0.015625476837158203,\n      \"last-10-avg\": 0.015625476837158203\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6df343d43d43d473fe63ac555555555473fe6c4e4a64a64a6473fe656613b13b13b473fe64e313b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6393299299299473fe6640834834835473fe684f7a87a87a8473fe66d066d66d66d473fe63a59fb9fb9fc473fe6df343d43d43d473fe63ac555555555473fe6c4e4a64a64a6473fe656613b13b13b473fe64e313b13b13b652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b23023023023047404e8e38e38e38e447404a48348348348447404bfdcfdcfdcfdd47404dea1ea1ea1ea2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ec4ec4ec4ec4f47404c34834834834847404bc71c71c71c7247404bc71c71c71c7247404db36b36b36b3747404b23023023023047404e8e38e38e38e447404a48348348348447404bfdcfdcfdcfdd47404dea1ea1ea1ea2652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308875049378ad9df3f94869452946807680d4308d326a014f532e23f94869452946807680d4308db81b97660aedd3f94869452946807680d4308330fc93c24f3e03f94869452946807680d430852138cb7b2cfe13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a02c814dfbc9e23f94869452946807680d4308c65bd9e7909ae03f94869452946807680d4308e2adec73484de03f94869452946807680d4308000000000000e03f94869452946807680d43082b51bb12b52be13f94869452946807680d4308875049378ad9df3f94869452946807680d4308d326a014f532e23f94869452946807680d4308db81b97660aedd3f94869452946807680d4308330fc93c24f3e03f94869452946807680d430852138cb7b2cfe13f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408357860000004740401f2c2e000000474040093c860000004740400ae6020000004740400b33ba000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404001096200000047403fe590700000004740400336240000004740404d1cd80000004740403fa1ea0000004740408357860000004740401f2c2e000000474040093c860000004740400ae6020000004740400b33ba000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a33d6bf80000047408b35c98260000047408c365d4ac0000047408d370baae0000047408e37bee6800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408523757540000047408622a1f8c0000047408722d55b00000047408827a7288000004740892ba14720000047408a33d6bf80000047408b35c98260000047408c365d4ac0000047408d370baae0000047408e37bee6800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a33d6bf80000047408b35c98260000047408c365d4ac0000047408d370baae0000047408e37bee6800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408523757540000047408622a1f8c0000047408722d55b00000047408827a7288000004740892ba14720000047408a33d6bf80000047408b35c98260000047408c365d4ac0000047408d370baae0000047408e37bee6800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000473f90002000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668630234.1884139,\n  \"relative_logdir\": \"tune_hp_757a3_00027_27_batch_size=16,learning_rate=0.0000,model=vgg16_2022-11-16_23-23-54\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00028\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 2,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-15,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"28_batch_size=2,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6808915749574319,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.883155584335327,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00028\",\n    \"experiment_id\": \"49b588b7d92d484ebd59c28a861d5da4\",\n    \"date\": \"2022-11-16_23-56-19\",\n    \"timestamp\": 1668632179,\n    \"time_total_s\": 970.0040354728699,\n    \"pid\": 21336,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 2,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 970.0040354728699,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"28_batch_size=2,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668632179.4709213,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6900991456121461,\n      \"min\": 0.6770715958032852,\n      \"avg\": 0.6835620999675869,\n      \"last\": 0.6808915749574319,\n      \"last-5-avg\": 0.6818471272786457,\n      \"last-10-avg\": 0.6833824027297843\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.435897435897424,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 42.66419458389282,\n      \"min\": 31.618763208389282,\n      \"avg\": 32.33346784909565,\n      \"last\": 31.883155584335327,\n      \"last-5-avg\": 31.84336085319519,\n      \"last-10-avg\": 31.799590158462525\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.0040354728699,\n      \"min\": 42.66419458389282,\n      \"avg\": 507.4259226481119,\n      \"last\": 970.0040354728699,\n      \"last-5-avg\": 906.3890656471252,\n      \"last-10-avg\": 826.8484688043594\n    },\n    \"time_since_restore\": {\n      \"max\": 970.0040354728699,\n      \"min\": 42.66419458389282,\n      \"avg\": 507.4259226481119,\n      \"last\": 970.0040354728699,\n      \"last-5-avg\": 906.3890656471252,\n      \"last-10-avg\": 826.8484688043594\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5b57fb9fb9fba473fe5c9c578578578473fe5d44dcfdcfdd0473fe5fb0532532532473fe5c9dd20d20d21652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5daee38e38e39473fe5d0e6f96f96f9473fe5e2aaf0af0af1473fe5f26f73f73f74473fe6154acdacdace473fe5b57fb9fb9fba473fe5c9c578578578473fe5d44dcfdcfdd0473fe5fb0532532532473fe5c9dd20d20d21652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff648e000000047403fda3ad400000047403fde1e5800000047403fa6c7f400000047403fe2167c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fb6842800000047403ff6627c00000047403fae4bf400000047403f9e674400000047403fcdd91000000047403ff648e000000047403fda3ad400000047403fde1e5800000047403fa6c7f400000047403fe2167c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a55fe86e0000047408b54d05d80000047408c53c15040000047408d50f78fe0000047408e500843c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855dc4c9c000004740865d77dda000004740875aea3d40000047408857dd77600000474089564c3fe0000047408a55fe86e0000047408b54d05d80000047408c53c15040000047408d50f78fe0000047408e500843c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a55fe86e0000047408b54d05d80000047408c53c15040000047408d50f78fe0000047408e500843c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740855dc4c9c000004740865d77dda000004740875aea3d40000047408857dd77600000474089564c3fe0000047408a55fe86e0000047408b54d05d80000047408c53c15040000047408d50f78fe0000047408e500843c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668631205.514688,\n  \"relative_logdir\": \"tune_hp_757a3_00028_28_batch_size=2,learning_rate=0.0000,model=vgg16_2022-11-16_23-40-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00029\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 4,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-15,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"29_batch_size=4,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7059058817023904,\n    \"accuracy\": 45.72649572649573,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.8202121257782,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00029\",\n    \"experiment_id\": \"e5ee55573b9146f88c8502c363ec165f\",\n    \"date\": \"2022-11-17_00-12-31\",\n    \"timestamp\": 1668633151,\n    \"time_total_s\": 967.6515290737152,\n    \"pid\": 18588,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 4,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 967.6515290737152,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"29_batch_size=4,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668633151.1683502,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7107926719209068,\n      \"min\": 0.6946979750934829,\n      \"avg\": 0.7019660580192197,\n      \"last\": 0.7059058817023904,\n      \"last-5-avg\": 0.7026067358815773,\n      \"last-10-avg\": 0.7026928828312802\n    },\n    \"accuracy\": {\n      \"max\": 45.72649572649573,\n      \"min\": 45.72649572649573,\n      \"avg\": 45.726495726495706,\n      \"last\": 45.72649572649573,\n      \"last-5-avg\": 45.72649572649573,\n      \"last-10-avg\": 45.72649572649573\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.94496750831604,\n      \"min\": 31.782090425491333,\n      \"avg\": 32.25505096912382,\n      \"last\": 31.8202121257782,\n      \"last-5-avg\": 31.984149312973024,\n      \"last-10-avg\": 32.02692811489105\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 967.6515290737152,\n      \"min\": 34.94496750831604,\n      \"avg\": 501.8544374624888,\n      \"last\": 967.6515290737152,\n      \"last-5-avg\": 903.6765912532807,\n      \"last-10-avg\": 823.748729467392\n    },\n    \"time_since_restore\": {\n      \"max\": 967.6515290737152,\n      \"min\": 34.94496750831604,\n      \"avg\": 501.8544374624888,\n      \"last\": 967.6515290737152,\n      \"last-5-avg\": 903.6765912532807,\n      \"last-10-avg\": 823.748729467392\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6923b36b36b37473fe672e857857858473fe6700230230230473fe65ed7ee7ee7ee473fe696c7ee7ee7ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe694373f73f73f473fe69750f50f50f5473fe68410af0af0af473fe6782a41a41a42473fe64a1118118118473fe6923b36b36b37473fe672e857857858473fe6700230230230473fe65ed7ee7ee7ee473fe696c7ee7ee7ee652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0474046dcfdcfdcfdd0652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fd6412800000047403ffe16bc0000004740401b1f800000004740400792de00000047403fd1f96c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740403333ac0000004740400f09880000004740400709ee00000047403fc8371400000047403ffe743800000047403fd6412800000047403ffe16bc0000004740401b1f800000004740400792de00000047403fd1f96c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3c8aadc0000047408b3c7b63a0000047408c3e2d5ba0000047408d3ea68980000047408e3d3654e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740853e4212c000004740863f32ab4000004740873fa34a2000004740883de502c000004740893dd8a480000047408a3c8aadc0000047408b3c7b63a0000047408c3e2d5ba0000047408d3ea68980000047408e3d3654e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3c8aadc0000047408b3c7b63a0000047408c3e2d5ba0000047408d3ea68980000047408e3d3654e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740853e4212c000004740863f32ab4000004740873fa34a2000004740883de502c000004740893dd8a480000047408a3c8aadc0000047408b3c7b63a0000047408c3e2d5ba0000047408d3ea68980000047408e3d3654e00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668632179.5958645,\n  \"relative_logdir\": \"tune_hp_757a3_00029_29_batch_size=4,learning_rate=0.0000,model=vgg16_2022-11-16_23-56-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00030\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 8,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-15,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"30_batch_size=8,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6794232751569177,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.26666666666666666,\n    \"time_this_iter_s\": 32.63295316696167,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00030\",\n    \"experiment_id\": \"15b55887ebe7453dbdd8cc2789da4485\",\n    \"date\": \"2022-11-17_00-28-48\",\n    \"timestamp\": 1668634128,\n    \"time_total_s\": 972.7520868778229,\n    \"pid\": 9776,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 8,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 972.7520868778229,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"30_batch_size=8,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668634128.091396,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6984660482814169,\n      \"min\": 0.6764901968149039,\n      \"avg\": 0.6856135724276898,\n      \"last\": 0.6794232751569177,\n      \"last-5-avg\": 0.6838712643354367,\n      \"last-10-avg\": 0.683768554426666\n    },\n    \"accuracy\": {\n      \"max\": 54.700854700854705,\n      \"min\": 44.44444444444444,\n      \"avg\": 49.15954415954414,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 49.31623931623932,\n      \"last-10-avg\": 49.31623931623931\n    },\n    \"f1_score\": {\n      \"max\": 0.38372093023255816,\n      \"min\": 0.12162162162162163,\n      \"avg\": 0.24895213058000412,\n      \"last\": 0.26666666666666666,\n      \"last-5-avg\": 0.25752189839146367,\n      \"last-10-avg\": 0.25325399424469697\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.11991810798645,\n      \"min\": 31.900176286697388,\n      \"avg\": 32.425069562594096,\n      \"last\": 32.63295316696167,\n      \"last-5-avg\": 32.32821440696716,\n      \"last-10-avg\": 32.34569642543793\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 972.7520868778229,\n      \"min\": 35.11991810798645,\n      \"avg\": 503.28605225880926,\n      \"last\": 972.7520868778229,\n      \"last-5-avg\": 907.9711348056793,\n      \"last-10-avg\": 827.0444610595703\n    },\n    \"time_since_restore\": {\n      \"max\": 972.7520868778229,\n      \"min\": 35.11991810798645,\n      \"avg\": 503.28605225880926,\n      \"last\": 972.7520868778229,\n      \"last-5-avg\": 907.9711348056793,\n      \"last-10-avg\": 827.0444610595703\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6307834834835473fe5c2e811811812473fe5cdda41a41a42473fe5ec4d89d89d8a473fe5bdd5e15e15e1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5ea92bc2bc2bc473fe5e6371c71c71c473fe5a5cec4ec4ec5473fe60e3627627627473fe5de2532532532473fe6307834834835473fe5c2e811811812473fe5cdda41a41a42473fe5ec4d89d89d8a473fe5bdd5e15e15e1652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049dacdacdacdae47404936b36b36b36b474048253253253253474047ee7ee7ee7ee8474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404936b36b36b36b4740485be5be5be5be474048253253253253474047b7cb7cb7cb7c474049dacdacdacdae474049dacdacdacdae47404936b36b36b36b474048253253253253474047ee7ee7ee7ee8474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308568a09baab14d33f94869452946807680d4308910669900669d03f94869452946807680d43088ee60f361ecdcf3f94869452946807680d43085dbee55bbee5cb3f94869452946807680d4308111111111111d13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bc12b52b51bbd23f94869452946807680d43089ed8899dd889cd3f94869452946807680d43086294a978ae59cd3f94869452946807680d4308bef05e782fbcc73f94869452946807680d4308b030ab51c4a1d33f94869452946807680d4308568a09baab14d33f94869452946807680d4308910669900669d03f94869452946807680d43088ee60f361ecdcf3f94869452946807680d43085dbee55bbee5cb3f94869452946807680d4308111111111111d13f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040311c900000004740401738a4000000474040119a66000000474040271a7000000047404051049c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400534660000004740401d0892000000474040371af00000004740404bf10c000000474040432634000000474040311c900000004740401738a4000000474040119a66000000474040271a7000000047404051049c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5bf524c0000047408b5d68af00000047408c5e825560000047408d60f3fc60000047408e660446200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854aafafa000004740864c8038c000004740874ff1e7c0000047408854b0f880000047408958e35bc0000047408a5bf524c0000047408b5d68af00000047408c5e825560000047408d60f3fc60000047408e660446200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a5bf524c0000047408b5d68af00000047408c5e825560000047408d60f3fc60000047408e660446200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854aafafa000004740864c8038c000004740874ff1e7c0000047408854b0f880000047408958e35bc0000047408a5bf524c0000047408b5d68af00000047408c5e825560000047408d60f3fc60000047408e660446200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668633151.4495332,\n  \"relative_logdir\": \"tune_hp_757a3_00030_30_batch_size=8,learning_rate=0.0000,model=vgg16_2022-11-17_00-12-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00031\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 16,\n    \"model\": \"vgg16\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-15,\n    \"model\": \"vgg16\"\n  },\n  \"experiment_tag\": \"31_batch_size=16,learning_rate=0.0000,model=vgg16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6917725913545005,\n    \"accuracy\": 49.14529914529914,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.13396239280701,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00031\",\n    \"experiment_id\": \"1ff6c38bd7f0493987e4604e7cc547b4\",\n    \"date\": \"2022-11-17_00-44-54\",\n    \"timestamp\": 1668635094,\n    \"time_total_s\": 960.7013380527496,\n    \"pid\": 27176,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 16,\n      \"model\": \"vgg16\"\n    },\n    \"time_since_restore\": 960.7013380527496,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"31_batch_size=16,learning_rate=0.0000,model=vgg16\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668635094.7132337,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7034060486361512,\n      \"min\": 0.6702629154563969,\n      \"avg\": 0.6924626059681602,\n      \"last\": 0.6917725913545005,\n      \"last-5-avg\": 0.6940570407443577,\n      \"last-10-avg\": 0.6911672934507712\n    },\n    \"accuracy\": {\n      \"max\": 50.0,\n      \"min\": 49.14529914529914,\n      \"avg\": 49.287749287749286,\n      \"last\": 49.14529914529914,\n      \"last-5-avg\": 49.230769230769226,\n      \"last-10-avg\": 49.18803418803419\n    },\n    \"f1_score\": {\n      \"max\": 0.03305785123966942,\n      \"min\": 0.0,\n      \"avg\": 0.005528007346189163,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.003333333333333333,\n      \"last-10-avg\": 0.0016666666666666666\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.36721348762512,\n      \"min\": 31.602309703826904,\n      \"avg\": 32.02337793509165,\n      \"last\": 32.13396239280701,\n      \"last-5-avg\": 31.939962100982665,\n      \"last-10-avg\": 31.87679455280304\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 960.7013380527496,\n      \"min\": 35.36721348762512,\n      \"avg\": 498.10229277610773,\n      \"last\": 960.7013380527496,\n      \"last-5-avg\": 896.776700258255,\n      \"last-10-avg\": 817.0060295581818\n    },\n    \"time_since_restore\": {\n      \"max\": 960.7013380527496,\n      \"min\": 35.36721348762512,\n      \"avg\": 498.10229277610773,\n      \"last\": 960.7013380527496,\n      \"last-5-avg\": 896.776700258255,\n      \"last-10-avg\": 817.0060295581818\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60a03b13b13b1473fe61b60f50f50f5473fe6733b9fb9fba0473fe650f302302302473fe6230046046046652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5e6341a41a41a473fe62954ec4ec4ec473fe5f2f92992992a473fe61c8834834835473fe600cec4ec4ec5473fe60a03b13b13b1473fe61b60f50f50f5473fe6733b9fb9fba0473fe650f302302302473fe6230046046046652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048929929929929474048c94c94c94c95474048929929929929474048929929929929474048929929929929652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048c94c94c94c95474048929929929929474048929929929929474048929929929929652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308111111111111913f94869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308111111111111913f94869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fd12c54000000474040138c6400000047403fda7fd800000047403fbe16780000004740401125ae000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9a30f800000047403fc2187800000047403fce6fe000000047404012930000000047403fc191fc00000047403fd12c54000000474040138c6400000047403fda7fd800000047403fbe16780000004740401125ae000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a068c8380000047408b07c549c0000047408c06994880000047408d0489fc40000047408e059c57200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850c491e4000004740860a59e200000047408708cd6100000047408809f691000000474089080320e0000047408a068c8380000047408b07c549c0000047408c06994880000047408d0489fc40000047408e059c57200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a068c8380000047408b07c549c0000047408c06994880000047408d0489fc40000047408e059c57200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850c491e4000004740860a59e200000047408708cd6100000047408809f691000000474089080320e0000047408a068c8380000047408b07c549c0000047408c06994880000047408d0489fc40000047408e059c57200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668634130.09093,\n  \"relative_logdir\": \"tune_hp_757a3_00031_31_batch_size=16,learning_rate=0.0000,model=vgg16_2022-11-17_00-28-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00032\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.01,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"32_batch_size=2,learning_rate=0.0100,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 2.7432097084501867,\n    \"accuracy\": 59.401709401709404,\n    \"f1_score\": 0.527363184079602,\n    \"time_this_iter_s\": 31.905365467071533,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00032\",\n    \"experiment_id\": \"aa455de3089d49a7805b5bea9baa04c8\",\n    \"date\": \"2022-11-17_01-01-19\",\n    \"timestamp\": 1668636079,\n    \"time_total_s\": 980.2155151367188,\n    \"pid\": 26728,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 980.2155151367188,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"32_batch_size=2,learning_rate=0.0100,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668636079.3964422,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 2.7432110126201925,\n      \"min\": 2.7432081434461804,\n      \"avg\": 2.7432094215327854,\n      \"last\": 2.7432097084501867,\n      \"last-5-avg\": 2.743209291115785,\n      \"last-10-avg\": 2.743209369365986\n    },\n    \"accuracy\": {\n      \"max\": 59.401709401709404,\n      \"min\": 59.401709401709404,\n      \"avg\": 59.4017094017094,\n      \"last\": 59.401709401709404,\n      \"last-5-avg\": 59.4017094017094,\n      \"last-10-avg\": 59.4017094017094\n    },\n    \"f1_score\": {\n      \"max\": 0.527363184079602,\n      \"min\": 0.527363184079602,\n      \"avg\": 0.5273631840796023,\n      \"last\": 0.527363184079602,\n      \"last-5-avg\": 0.527363184079602,\n      \"last-10-avg\": 0.5273631840796021\n    },\n    \"time_this_iter_s\": {\n      \"max\": 53.09402108192444,\n      \"min\": 31.60252547264099,\n      \"avg\": 32.67385050455729,\n      \"last\": 31.905365467071533,\n      \"last-5-avg\": 31.77207202911377,\n      \"last-10-avg\": 31.852498722076415\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 980.2155151367188,\n      \"min\": 53.09402108192444,\n      \"avg\": 517.2561611890793,\n      \"last\": 980.2155151367188,\n      \"last-5-avg\": 916.581326341629,\n      \"last-10-avg\": 837.0798303604126\n    },\n    \"time_since_restore\": {\n      \"max\": 980.2155151367188,\n      \"min\": 53.09402108192444,\n      \"avg\": 517.2561611890793,\n      \"last\": 980.2155151367188,\n      \"last-5-avg\": 916.581326341629,\n      \"last-10-avg\": 837.0798303604126\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474005f21785785785474005f217ee7ee7ee474005f217a87a87a8474005f21785785785474005f217ee7ee7ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474005f21811811812474005f217a87a87a8474005f21785785785474005f217a87a87a8474005f21811811812474005f21785785785474005f217ee7ee7ee474005f217a87a87a8474005f21785785785474005f217ee7ee7ee652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b37652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b3747404db36b36b36b37652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f94869452946807680d4308ec8f97c128e0e03f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fae3d8000000047403fd5e69000000047403f9a3f1c00000047403fd6175c00000047403fe7c608000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ffe131c00000047403fd618c00000004740401b647c00000047403fde16cc00000047403fc1196000000047403fae3d8000000047403fd5e69000000047403f9a3f1c00000047403fd6175c00000047403fe7c608000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408aa8494780000047408ba6f87c00000047408ca3ca74e0000047408da27b2fc0000047408ea1b960000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085ad76cc600000474086ac2792600000474087adddda200000474088acce90800000474089aad75b80000047408aa8494780000047408ba6f87c00000047408ca3ca74e0000047408da27b2fc0000047408ea1b960000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408aa8494780000047408ba6f87c00000047408ca3ca74e0000047408da27b2fc0000047408ea1b960000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085ad76cc600000474086ac2792600000474087adddda200000474088acce90800000474089aad75b80000047408aa8494780000047408ba6f87c00000047408ca3ca74e0000047408da27b2fc0000047408ea1b960000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668635095.2290134,\n  \"relative_logdir\": \"tune_hp_757a3_00032_32_batch_size=2,learning_rate=0.0100,model=resnet50_2022-11-17_00-44-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00033\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.01,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"33_batch_size=4,learning_rate=0.0100,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6993457761585203,\n    \"accuracy\": 45.2991452991453,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.107412576675415,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00033\",\n    \"experiment_id\": \"4de775020b7e4fad8e10015b74866e17\",\n    \"date\": \"2022-11-17_01-17-25\",\n    \"timestamp\": 1668637045,\n    \"time_total_s\": 961.2718505859375,\n    \"pid\": 10416,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.2718505859375,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"33_batch_size=4,learning_rate=0.0100,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668637045.1359885,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6993459717840211,\n      \"min\": 0.6993455805330195,\n      \"avg\": 0.6993457870266035,\n      \"last\": 0.6993457761585203,\n      \"last-5-avg\": 0.6993457370334202,\n      \"last-10-avg\": 0.6993457826793705\n    },\n    \"accuracy\": {\n      \"max\": 45.2991452991453,\n      \"min\": 45.2991452991453,\n      \"avg\": 45.29914529914528,\n      \"last\": 45.2991452991453,\n      \"last-5-avg\": 45.2991452991453,\n      \"last-10-avg\": 45.29914529914531\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.58832764625549,\n      \"min\": 31.508818864822388,\n      \"avg\": 32.04239501953124,\n      \"last\": 32.107412576675415,\n      \"last-5-avg\": 32.10281729698181,\n      \"last-10-avg\": 32.13298306465149\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.2718505859375,\n      \"min\": 34.58832764625549,\n      \"avg\": 496.9699018637339,\n      \"last\": 961.2718505859375,\n      \"last-5-avg\": 897.1354084968567,\n      \"last-10-avg\": 816.7272576093674\n    },\n    \"time_since_restore\": {\n      \"max\": 961.2718505859375,\n      \"min\": 34.58832764625549,\n      \"avg\": 496.9699018637339,\n      \"last\": 961.2718505859375,\n      \"last-5-avg\": 897.1354084968567,\n      \"last-10-avg\": 816.7272576093674\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6610a64a64a65473fe6610a41a41a42473fe6610a64a64a65473fe6610a1ea1ea1f473fe6610a64a64a65652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6610a64a64a65473fe6610a64a64a65473fe6610a64a64a65473fe6610a87a87a88473fe6610acdacdace473fe6610a64a64a65473fe6610a41a41a42473fe6610a64a64a65473fe6610a1ea1ea1f473fe6610a64a64a65652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65474046a64a64a64a65652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404018a7ec00000047404007625600000047404023195800000047403fe1d4940000004740400dbfb2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ff380f80000004740401a8028000000474040146a1a0000004740402994fc000000474040162a9400000047404018a7ec00000047404007625600000047404023195800000047403fe1d4940000004740400dbfb2000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a079a6560000047408b08108ac0000047408c0a422040000047408d0950c4e0000047408e0a2cc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084ff254980000047408600cd4c0000004740870213eda0000047408804ad3d600000474089060fe6a0000047408a079a6560000047408b08108ac0000047408c0a422040000047408d0950c4e0000047408e0a2cc0000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a079a6560000047408b08108ac0000047408c0a422040000047408d0950c4e0000047408e0a2cc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084ff254980000047408600cd4c0000004740870213eda0000047408804ad3d600000474089060fe6a0000047408a079a6560000047408b08108ac0000047408c0a422040000047408d0950c4e0000047408e0a2cc0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668636079.9900672,\n  \"relative_logdir\": \"tune_hp_757a3_00033_33_batch_size=4,learning_rate=0.0100,model=resnet50_2022-11-17_01-01-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00034\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.01,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"34_batch_size=8,learning_rate=0.0100,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.8791705400515826,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.957278728485107,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00034\",\n    \"experiment_id\": \"6ca6e8bf8dc148b0a5faacb128bf3b02\",\n    \"date\": \"2022-11-17_01-33-28\",\n    \"timestamp\": 1668638008,\n    \"time_total_s\": 959.4987237453461,\n    \"pid\": 26656,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 959.4987237453461,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"34_batch_size=8,learning_rate=0.0100,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668638008.9618065,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.8791708660940839,\n      \"min\": 0.8791705400515826,\n      \"avg\": 0.8791707204617659,\n      \"last\": 0.8791705400515826,\n      \"last-5-avg\": 0.8791706965519832,\n      \"last-10-avg\": 0.8791707226353832\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324783,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.539879322052,\n      \"min\": 31.58695960044861,\n      \"avg\": 31.983290791511518,\n      \"last\": 31.957278728485107,\n      \"last-5-avg\": 31.762180852890015,\n      \"last-10-avg\": 31.76695556640625\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 959.4987237453461,\n      \"min\": 34.539879322052,\n      \"avg\": 498.3370814402898,\n      \"last\": 959.4987237453461,\n      \"last-5-avg\": 895.9660558700562,\n      \"last-10-avg\": 816.5835565567016\n    },\n    \"time_since_restore\": {\n      \"max\": 959.4987237453461,\n      \"min\": 34.539879322052,\n      \"avg\": 498.3370814402898,\n      \"last\": 959.4987237453461,\n      \"last-5-avg\": 895.9660558700562,\n      \"last-10-avg\": 816.5835565567016\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec222aaaaaaaab473fec222aaaaaaaab473fec222aaaaaaaab473fec222aaaaaaaab473fec222a41a41a42652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fec222acdacdace473fec222aaaaaaaab473fec222aaaaaaaab473fec222acdacdace473fec222a87a87a88473fec222aaaaaaaab473fec222aaaaaaaab473fec222aaaaaaaab473fec222aaaaaaaab473fec222a41a41a42652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fef6da400000047403faabcfc00000047403f9642fc00000047403faa199800000047403ff51038000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fb878d80000004740400316ac00000047403fb0d76800000047403faa19d800000047403fc2392400000047403fef6da400000047403faabcfc00000047403f9642fc00000047403faa199800000047403ff51038000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a04fc14a0000047408b0251fc80000047408bff041460000047408cfc54e120000047408dfbfd62e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850c65e9a000004740860c97546000004740870a1e0fa00000474088076ede6000004740890580a780000047408a04fc14a0000047408b0251fc80000047408bff041460000047408cfc54e120000047408dfbfd62e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a04fc14a0000047408b0251fc80000047408bff041460000047408cfc54e120000047408dfbfd62e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850c65e9a000004740860c97546000004740870a1e0fa00000474088076ede6000004740890580a780000047408a04fc14a0000047408b0251fc80000047408bff041460000047408cfc54e120000047408dfbfd62e00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668637045.5264926,\n  \"relative_logdir\": \"tune_hp_757a3_00034_34_batch_size=8,learning_rate=0.0100,model=resnet50_2022-11-17_01-17-25\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00035\",\n  \"config\": {\n    \"learning_rate\": 0.01,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.01,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"35_batch_size=16,learning_rate=0.0100,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 6.971179929553953,\n    \"accuracy\": 48.717948717948715,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.441136598587036,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00035\",\n    \"experiment_id\": \"436e9b742e104a429f5c9f900a4ed3a6\",\n    \"date\": \"2022-11-17_01-49-36\",\n    \"timestamp\": 1668638976,\n    \"time_total_s\": 961.6932511329651,\n    \"pid\": 23944,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.01,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.6932511329651,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.01559591293334961,\n    \"experiment_tag\": \"35_batch_size=16,learning_rate=0.0100,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668638976.388055,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 6.971180972889957,\n      \"min\": 6.971179407885951,\n      \"avg\": 6.971180138221153,\n      \"last\": 6.971179929553953,\n      \"last-5-avg\": 6.971180033887554,\n      \"last-10-avg\": 6.971179981720754\n    },\n    \"accuracy\": {\n      \"max\": 48.717948717948715,\n      \"min\": 48.717948717948715,\n      \"avg\": 48.717948717948694,\n      \"last\": 48.717948717948715,\n      \"last-5-avg\": 48.717948717948715,\n      \"last-10-avg\": 48.71794871794872\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.82165455818176,\n      \"min\": 31.509472131729126,\n      \"avg\": 32.05644170443217,\n      \"last\": 32.441136598587036,\n      \"last-5-avg\": 32.10632591247558,\n      \"last-10-avg\": 32.04366252422333\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.6932511329651,\n      \"min\": 33.82165455818176,\n      \"avg\": 497.1689348538716,\n      \"last\": 961.6932511329651,\n      \"last-5-avg\": 897.1943315029145,\n      \"last-10-avg\": 817.228321313858\n    },\n    \"time_since_restore\": {\n      \"max\": 961.6932511329651,\n      \"min\": 33.82165455818176,\n      \"avg\": 497.1689348538716,\n      \"last\": 961.6932511329651,\n      \"last-5-avg\": 897.1943315029145,\n      \"last-10-avg\": 817.228321313858\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.01559591293334961,\n      \"min\": 0.01559591293334961,\n      \"avg\": 0.01559591293334961,\n      \"last\": 0.01559591293334961,\n      \"last-5-avg\": 0.01559591293334961,\n      \"last-10-avg\": 0.01559591293334961\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401be27cfdcfdcfe47401be27cfdcfdcfe47401be27cfdcfdcfe47401be27d20d20d2147401be27cfdcfdcfe652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401be27cfdcfdcfe47401be27cfdcfdcfe47401be27cfdcfdcfe47401be27d20d20d2147401be27cdacdacdb47401be27cfdcfdcfe47401be27cfdcfdcfe47401be27cfdcfdcfe47401be27d20d20d2147401be27cfdcfdcfe652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be4740485be5be5be5be652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403feadfc000000047403fdbf4f00000004740400908ec0000004740401f220200000047404038772a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ffa151c000000474040153d4a00000047403fc2ccc8000000474040191db400000047403fce15ec00000047403feadfc000000047403fdbf4f00000004740400908ec0000004740401f220200000047404038772a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a08a1fe40000047408b0781a5c0000047408c08123480000047408d0a0454a0000047408e0d8bc7400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408509de3ac000004740860b320f600000474087094875a000004740880ada50e00000474089094b0040000047408a08a1fe40000047408b0781a5c0000047408c08123480000047408d0a0454a0000047408e0d8bc7400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a08a1fe40000047408b0781a5c0000047408c08123480000047408d0a0454a0000047408e0d8bc7400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408509de3ac000004740860b320f600000474087094875a000004740880ada50e00000474089094b0040000047408a08a1fe40000047408b0781a5c0000047408c08123480000047408d0a0454a0000047408e0d8bc7400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668638010.8366528,\n  \"relative_logdir\": \"tune_hp_757a3_00035_35_batch_size=16,learning_rate=0.0100,model=resnet50_2022-11-17_01-33-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00036\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"36_batch_size=2,learning_rate=0.0010,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 8.792591062366453,\n    \"accuracy\": 52.13675213675214,\n    \"f1_score\": 0.5971223021582734,\n    \"time_this_iter_s\": 31.587424278259277,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00036\",\n    \"experiment_id\": \"972e16d2860e45a886ef854c18e60b22\",\n    \"date\": \"2022-11-17_02-05-57\",\n    \"timestamp\": 1668639957,\n    \"time_total_s\": 975.2074942588806,\n    \"pid\": 4432,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 975.2074942588806,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"36_batch_size=2,learning_rate=0.0010,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668639957.4546916,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 8.792593149038462,\n      \"min\": 8.79258793235844,\n      \"avg\": 8.792589879918983,\n      \"last\": 8.792591062366453,\n      \"last-5-avg\": 8.79259022769765,\n      \"last-10-avg\": 8.792590540698452\n    },\n    \"accuracy\": {\n      \"max\": 52.13675213675214,\n      \"min\": 52.13675213675214,\n      \"avg\": 52.13675213675216,\n      \"last\": 52.13675213675214,\n      \"last-5-avg\": 52.13675213675215,\n      \"last-10-avg\": 52.13675213675215\n    },\n    \"f1_score\": {\n      \"max\": 0.5971223021582734,\n      \"min\": 0.5971223021582734,\n      \"avg\": 0.5971223021582732,\n      \"last\": 0.5971223021582734,\n      \"last-5-avg\": 0.5971223021582734,\n      \"last-10-avg\": 0.5971223021582733\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.31699204444885,\n      \"min\": 31.555106163024902,\n      \"avg\": 32.506916475296016,\n      \"last\": 31.587424278259277,\n      \"last-5-avg\": 31.82193946838379,\n      \"last-10-avg\": 31.805127382278442\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 975.2074942588806,\n      \"min\": 52.31699204444885,\n      \"avg\": 513.8809534072876,\n      \"last\": 975.2074942588806,\n      \"last-5-avg\": 911.7448042869568,\n      \"last-10-avg\": 832.1160823822022\n    },\n    \"time_since_restore\": {\n      \"max\": 975.2074942588806,\n      \"min\": 52.31699204444885,\n      \"avg\": 513.8809534072876,\n      \"last\": 975.2074942588806,\n      \"last-5-avg\": 911.7448042869568,\n      \"last-10-avg\": 832.1160823822022\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402195ce15e15e1647402195ce7ee7ee7f47402195ce5be5be5c47402195ce7ee7ee7f47402195ce7ee7ee7f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402195cec4ec4ec547402195ce38e38e3947402195ce7ee7ee7f47402195ce7ee7ee7f47402195ce5be5be5c47402195ce15e15e1647402195ce7ee7ee7f47402195ce5be5be5c47402195ce7ee7ee7f47402195ce7ee7ee7f652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a118118118119652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a118118118119652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f94869452946807680d4308aa6cef3aa01be33f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ffea07c00000047403fde355800000047403fe2166c00000047403fc6c77000000047403f966170000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fb6372c00000047403fda804400000047403fd6191800000047403fa2412400000047403fe7f97c00000047403ffea07c00000047403fde355800000047403fe2166c00000047403fc6c77000000047403f966170000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a80bd4da0000047408b7faef860000047408c7ebfabc0000047408d7cf5e740000047408e79a8f2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408586f1a9e0000047408685c5ac000000474087847674c0000047408881887de0000047408980c849c0000047408a80bd4da0000047408b7faef860000047408c7ebfabc0000047408d7cf5e740000047408e79a8f2c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a80bd4da0000047408b7faef860000047408c7ebfabc0000047408d7cf5e740000047408e79a8f2c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408586f1a9e0000047408685c5ac000000474087847674c0000047408881887de0000047408980c849c0000047408a80bd4da0000047408b7faef860000047408c7ebfabc0000047408d7cf5e740000047408e79a8f2c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668638978.3257546,\n  \"relative_logdir\": \"tune_hp_757a3_00036_36_batch_size=2,learning_rate=0.0010,model=resnet50_2022-11-17_01-49-38\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00037\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"37_batch_size=4,learning_rate=0.0010,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7082867744641427,\n    \"accuracy\": 47.008547008547005,\n    \"f1_score\": 0.10144927536231883,\n    \"time_this_iter_s\": 31.94652223587036,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00037\",\n    \"experiment_id\": \"04252e4e9bbc44b89116b3041542305a\",\n    \"date\": \"2022-11-17_02-22-04\",\n    \"timestamp\": 1668640924,\n    \"time_total_s\": 961.0307104587555,\n    \"pid\": 264,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.0307104587555,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"37_batch_size=4,learning_rate=0.0010,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668640924.2340555,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7082869700896435,\n      \"min\": 0.7082866440471421,\n      \"avg\": 0.7082868461934926,\n      \"last\": 0.7082867744641427,\n      \"last-5-avg\": 0.708286865756043,\n      \"last-10-avg\": 0.708286852714343\n    },\n    \"accuracy\": {\n      \"max\": 47.008547008547005,\n      \"min\": 47.008547008547005,\n      \"avg\": 47.008547008547026,\n      \"last\": 47.008547008547005,\n      \"last-5-avg\": 47.008547008547005,\n      \"last-10-avg\": 47.008547008547005\n    },\n    \"f1_score\": {\n      \"max\": 0.10144927536231883,\n      \"min\": 0.10144927536231883,\n      \"avg\": 0.10144927536231878,\n      \"last\": 0.10144927536231883,\n      \"last-5-avg\": 0.10144927536231882,\n      \"last-10-avg\": 0.10144927536231882\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.77354454994202,\n      \"min\": 31.555827379226685,\n      \"avg\": 32.034357015291846,\n      \"last\": 31.94652223587036,\n      \"last-5-avg\": 31.90903296470642,\n      \"last-10-avg\": 31.941962814331056\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.0307104587555,\n      \"min\": 34.77354454994202,\n      \"avg\": 497.441042192777,\n      \"last\": 961.0307104587555,\n      \"last-5-avg\": 897.1933739185333,\n      \"last-10-avg\": 817.2342534542083\n    },\n    \"time_since_restore\": {\n      \"max\": 961.0307104587555,\n      \"min\": 34.77354454994202,\n      \"avg\": 497.441042192777,\n      \"last\": 961.0307104587555,\n      \"last-5-avg\": 897.1933739185333,\n      \"last-10-avg\": 817.2342534542083\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6aa496f96f970473fe6aa492992992a473fe6aa494c94c94d473fe6aa492992992a473fe6aa4906906907652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6aa492992992a473fe6aa494c94c94d473fe6aa492992992a473fe6aa48e38e38e4473fe6aa494c94c94d473fe6aa496f96f970473fe6aa492992992a473fe6aa494c94c94d473fe6aa492992992a473fe6aa4906906907652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f94869452946807680d43089f51e26794f8b93f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fdeb3a800000047403fce3a5800000047404016527a00000047403fbfadb000000047403ff24f48000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fde896800000047403fd6da4400000047403fca8fbc00000047403fde4b6800000047404040cf0200000047403fdeb3a800000047403fce3a5800000047404016527a00000047403fbfadb000000047403ff24f48000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0ad80300000047408b0949d5c0000047408c0aaefd60000047408d08ac6ae0000047408e083ee5200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850bd7ca6000004740860a8e9c80000047408708e31a60000047408807d575a000004740890be265c0000047408a0ad80300000047408b0949d5c0000047408c0aaefd60000047408d08ac6ae0000047408e083ee5200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0ad80300000047408b0949d5c0000047408c0aaefd60000047408d08ac6ae0000047408e083ee5200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850bd7ca6000004740860a8e9c80000047408708e31a60000047408807d575a000004740890be265c0000047408a0ad80300000047408b0949d5c0000047408c0aaefd60000047408d08ac6ae0000047408e083ee5200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668639959.1417956,\n  \"relative_logdir\": \"tune_hp_757a3_00037_37_batch_size=4,learning_rate=0.0010,model=resnet50_2022-11-17_02-05-59\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00038\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"38_batch_size=8,learning_rate=0.0010,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 14.554262862246262,\n    \"accuracy\": 50.427350427350426,\n    \"f1_score\": 0.6704545454545454,\n    \"time_this_iter_s\": 32.024433612823486,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00038\",\n    \"experiment_id\": \"1809d2b5c7b8451fbc3fc65b59e1b2d1\",\n    \"date\": \"2022-11-17_02-38-19\",\n    \"timestamp\": 1668641899,\n    \"time_total_s\": 970.7912800312042,\n    \"pid\": 25128,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 970.7912800312042,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"38_batch_size=8,learning_rate=0.0010,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668641899.3055782,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 14.55426494891827,\n      \"min\": 14.554257645566238,\n      \"avg\": 14.55426237535613,\n      \"last\": 14.554262862246262,\n      \"last-5-avg\": 14.55426307091346,\n      \"last-10-avg\": 14.554262653579059\n    },\n    \"accuracy\": {\n      \"max\": 50.427350427350426,\n      \"min\": 50.427350427350426,\n      \"avg\": 50.427350427350405,\n      \"last\": 50.427350427350426,\n      \"last-5-avg\": 50.427350427350426,\n      \"last-10-avg\": 50.42735042735042\n    },\n    \"f1_score\": {\n      \"max\": 0.6704545454545454,\n      \"min\": 0.6704545454545454,\n      \"avg\": 0.6704545454545454,\n      \"last\": 0.6704545454545454,\n      \"last-5-avg\": 0.6704545454545454,\n      \"last-10-avg\": 0.6704545454545453\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.398165225982666,\n      \"min\": 31.97688364982605,\n      \"avg\": 32.35970933437346,\n      \"last\": 32.024433612823486,\n      \"last-5-avg\": 32.11550064086914,\n      \"last-10-avg\": 32.26196005344391\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.7912800312042,\n      \"min\": 34.398165225982666,\n      \"avg\": 503.046490327517,\n      \"last\": 970.7912800312042,\n      \"last-5-avg\": 906.6009802818298,\n      \"last-10-avg\": 825.9561519861221\n    },\n    \"time_since_restore\": {\n      \"max\": 970.7912800312042,\n      \"min\": 34.398165225982666,\n      \"avg\": 503.046490327517,\n      \"last\": 970.7912800312042,\n      \"last-5-avg\": 906.6009802818298,\n      \"last-10-avg\": 825.9561519861221\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d1bc83483483547402d1bc87a87a87b47402d1bc83483483547402d1bc89d89d89e47402d1bc857857858652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402d1bc83483483547402d1bc85785785847402d1bc83483483547402d1bc83483483547402d1bc85785785847402d1bc83483483547402d1bc87a87a87b47402d1bc83483483547402d1bc89d89d89e47402d1bc857857858652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b47404936b36b36b36b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f94869452946807680d430874d145175d74e53f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400d344a0000004740402124d400000047403ffa64900000004740401b3f960000004740400320a4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404036c0de0000004740403537da0000004740401524300000004740402f0876000000474040553e140000004740400d344a0000004740402124d400000047403ffa64900000004740401b3f960000004740400320a4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a52891540000047408b549b6280000047408c546e8700000047408d56228060000047408e56548aa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408544cba7600000474086481f250000004740874971680000004740884c61ef60000047408951b5d0a0000047408a52891540000047408b549b6280000047408c546e8700000047408d56228060000047408e56548aa00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a52891540000047408b549b6280000047408c546e8700000047408d56228060000047408e56548aa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408544cba7600000474086481f250000004740874971680000004740884c61ef60000047408951b5d0a0000047408a52891540000047408b549b6280000047408c546e8700000047408d56228060000047408e56548aa00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668640924.5777237,\n  \"relative_logdir\": \"tune_hp_757a3_00038_38_batch_size=8,learning_rate=0.0010,model=resnet50_2022-11-17_02-22-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00039\",\n  \"config\": {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"39_batch_size=16,learning_rate=0.0010,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.8515623043744992,\n    \"accuracy\": 61.965811965811966,\n    \"f1_score\": 0.6641509433962264,\n    \"time_this_iter_s\": 31.867626190185547,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00039\",\n    \"experiment_id\": \"1a6b36fc30104df2a7dfee3fd71b1aaa\",\n    \"date\": \"2022-11-17_02-54-28\",\n    \"timestamp\": 1668642868,\n    \"time_total_s\": 964.3013873100281,\n    \"pid\": 25028,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 964.3013873100281,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"39_batch_size=16,learning_rate=0.0010,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668642868.402726,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.8515623695829995,\n      \"min\": 0.8515621739574987,\n      \"avg\": 0.8515622913327995,\n      \"last\": 0.8515623043744992,\n      \"last-5-avg\": 0.8515622782910992,\n      \"last-10-avg\": 0.851562278291099\n    },\n    \"accuracy\": {\n      \"max\": 61.965811965811966,\n      \"min\": 61.965811965811966,\n      \"avg\": 61.96581196581197,\n      \"last\": 61.965811965811966,\n      \"last-5-avg\": 61.965811965811966,\n      \"last-10-avg\": 61.965811965811966\n    },\n    \"f1_score\": {\n      \"max\": 0.6641509433962264,\n      \"min\": 0.6641509433962264,\n      \"avg\": 0.6641509433962263,\n      \"last\": 0.6641509433962264,\n      \"last-5-avg\": 0.6641509433962264,\n      \"last-10-avg\": 0.6641509433962264\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.039628982543945,\n      \"min\": 31.574920892715454,\n      \"avg\": 32.143379577000914,\n      \"last\": 31.867626190185547,\n      \"last-5-avg\": 32.007088088989256,\n      \"last-10-avg\": 32.15595536231994\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 964.3013873100281,\n      \"min\": 34.039628982543945,\n      \"avg\": 498.272486837705,\n      \"last\": 964.3013873100281,\n      \"last-5-avg\": 900.3691608428956,\n      \"last-10-avg\": 820.1145775079727\n    },\n    \"time_since_restore\": {\n      \"max\": 964.3013873100281,\n      \"min\": 34.039628982543945,\n      \"avg\": 498.272486837705,\n      \"last\": 964.3013873100281,\n      \"last-5-avg\": 900.3691608428956,\n      \"last-10-avg\": 820.1145775079727\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feb3fff73f73f74473feb3fff73f73f74473feb3fff96f96f97473feb3fff96f96f97473feb3fff96f96f97652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb3fff73f73f74473feb3fff73f73f74473feb3fff96f96f97473feb3fff96f96f97473feb3fff96f96f97473feb3fff73f73f74473feb3fff73f73f74473feb3fff96f96f97473feb3fff96f96f97473feb3fff96f96f97652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba47404efb9fb9fb9fba652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f94869452946807680d4308a1d1af7ab940e53f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400320480000004740400bc514000000474040071f5400000047403ffeec8000000047403fde1cc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404029ddb60000004740404d20260000004740402d0aa20000004740401f9cb800000047403ffee1dc0000004740400320480000004740400bc514000000474040071f5400000047403ffeec8000000047403fde1cc0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2252ad40000047408b230efe80000047408c2380f3c0000047408d237857c0000047408e22693dc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085188d21e000004740861d5f24400000474087202fce600000474088222999e000004740892220a8c0000047408a2252ad40000047408b230efe80000047408c2380f3c0000047408d237857c0000047408e22693dc00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2252ad40000047408b230efe80000047408c2380f3c0000047408d237857c0000047408e22693dc00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085188d21e000004740861d5f24400000474087202fce600000474088222999e000004740892220a8c0000047408a2252ad40000047408b230efe80000047408c2380f3c0000047408d237857c0000047408e22693dc00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668641900.180479,\n  \"relative_logdir\": \"tune_hp_757a3_00039_39_batch_size=16,learning_rate=0.0010,model=resnet50_2022-11-17_02-38-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00040\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 0.0001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"40_batch_size=2,learning_rate=0.0001,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6292825682550414,\n    \"accuracy\": 62.82051282051282,\n    \"f1_score\": 0.5628140703517587,\n    \"time_this_iter_s\": 31.602032899856567,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00040\",\n    \"experiment_id\": \"e4473a5c382848c4968e5af0349186d0\",\n    \"date\": \"2022-11-17_03-10-53\",\n    \"timestamp\": 1668643853,\n    \"time_total_s\": 980.954183101654,\n    \"pid\": 22536,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 980.954183101654,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"40_batch_size=2,learning_rate=0.0001,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668643853.65282,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6292826986720419,\n      \"min\": 0.6292823726295406,\n      \"avg\": 0.6292825204354745,\n      \"last\": 0.6292825682550414,\n      \"last-5-avg\": 0.6292825291299412,\n      \"last-10-avg\": 0.6292825030465411\n    },\n    \"accuracy\": {\n      \"max\": 62.82051282051282,\n      \"min\": 62.82051282051282,\n      \"avg\": 62.82051282051276,\n      \"last\": 62.82051282051282,\n      \"last-5-avg\": 62.82051282051282,\n      \"last-10-avg\": 62.82051282051282\n    },\n    \"f1_score\": {\n      \"max\": 0.5628140703517587,\n      \"min\": 0.5628140703517587,\n      \"avg\": 0.5628140703517589,\n      \"last\": 0.5628140703517587,\n      \"last-5-avg\": 0.5628140703517587,\n      \"last-10-avg\": 0.5628140703517587\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.52594995498657,\n      \"min\": 31.414599180221558,\n      \"avg\": 32.69847277005513,\n      \"last\": 31.602032899856567,\n      \"last-5-avg\": 31.69245014190674,\n      \"last-10-avg\": 31.702290391922\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 980.954183101654,\n      \"min\": 52.52594995498657,\n      \"avg\": 518.2691422859828,\n      \"last\": 980.954183101654,\n      \"last-5-avg\": 917.5434629440308,\n      \"last-10-avg\": 838.2458414793015\n    },\n    \"time_since_restore\": {\n      \"max\": 980.954183101654,\n      \"min\": 52.52594995498657,\n      \"avg\": 518.2691422859828,\n      \"last\": 980.954183101654,\n      \"last-5-avg\": 917.5434629440308,\n      \"last-10-avg\": 838.2458414793015\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe42314ec4ec4ec473fe42314ec4ec4ec473fe4231532532532473fe4231555555555473fe4231532532532652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe42314ec4ec4ec473fe423150f50f50f473fe423150f50f50f473fe423150f50f50f473fe42314ec4ec4ec473fe42314ec4ec4ec473fe42314ec4ec4ec473fe4231532532532473fe4231555555555473fe4231532532532652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f690690690690652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f69069069069047404f690690690690652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f94869452946807680d430859763ca79202e23f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403f8e216800000047403fb50e7000000047403fdae72400000047403fbe204000000047403f9a1ed4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f6a232c00000047403fc61e0400000047403fbe1cbc00000047404007840000000047403f92210c00000047403f8e216800000047403fb50e7000000047403fdae72400000047403fbe204000000047403f9a1ed4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408ab0608580000047408bae08f900000047408cace03220000047408daad13420000047408ea7a22ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085bac45be00000474086b8f54c000000474087b6e631e00000474088b75e71e00000474089b3ef7a40000047408ab0608580000047408bae08f900000047408cace03220000047408daad13420000047408ea7a22ac00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408ab0608580000047408bae08f900000047408cace03220000047408daad13420000047408ea7a22ac00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085bac45be00000474086b8f54c000000474087b6e631e00000474088b75e71e00000474089b3ef7a40000047408ab0608580000047408bae08f900000047408cace03220000047408daad13420000047408ea7a22ac00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668642868.6995053,\n  \"relative_logdir\": \"tune_hp_757a3_00040_40_batch_size=2,learning_rate=0.0001,model=resnet50_2022-11-17_02-54-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00041\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 0.0001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"41_batch_size=4,learning_rate=0.0001,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6698070428310297,\n    \"accuracy\": 62.39316239316239,\n    \"f1_score\": 0.45679012345679015,\n    \"time_this_iter_s\": 32.49379515647888,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00041\",\n    \"experiment_id\": \"0761f6f47ec94095a85ff6283914fa29\",\n    \"date\": \"2022-11-17_03-27-04\",\n    \"timestamp\": 1668644824,\n    \"time_total_s\": 966.5163445472717,\n    \"pid\": 20328,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 966.5163445472717,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015624761581420898,\n    \"experiment_tag\": \"41_batch_size=4,learning_rate=0.0001,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668644824.4723544,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6698072384565305,\n      \"min\": 0.6698067819970286,\n      \"avg\": 0.6698070037059294,\n      \"last\": 0.6698070428310297,\n      \"last-5-avg\": 0.6698069645808294,\n      \"last-10-avg\": 0.6698070037059295\n    },\n    \"accuracy\": {\n      \"max\": 62.39316239316239,\n      \"min\": 62.39316239316239,\n      \"avg\": 62.39316239316237,\n      \"last\": 62.39316239316239,\n      \"last-5-avg\": 62.39316239316239,\n      \"last-10-avg\": 62.39316239316239\n    },\n    \"f1_score\": {\n      \"max\": 0.45679012345679015,\n      \"min\": 0.45679012345679015,\n      \"avg\": 0.45679012345678993,\n      \"last\": 0.45679012345679015,\n      \"last-5-avg\": 0.4567901234567902,\n      \"last-10-avg\": 0.45679012345679026\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.94670557975769,\n      \"min\": 31.665627002716064,\n      \"avg\": 32.21721148490906,\n      \"last\": 32.49379515647888,\n      \"last-5-avg\": 32.10176415443421,\n      \"last-10-avg\": 32.15952816009521\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.5163445472717,\n      \"min\": 34.94670557975769,\n      \"avg\": 500.6577275117238,\n      \"last\": 966.5163445472717,\n      \"last-5-avg\": 901.9978784561157,\n      \"last-10-avg\": 821.7601962804795\n    },\n    \"time_since_restore\": {\n      \"max\": 966.5163445472717,\n      \"min\": 34.94670557975769,\n      \"avg\": 500.6577275117238,\n      \"last\": 966.5163445472717,\n      \"last-5-avg\": 901.9978784561157,\n      \"last-10-avg\": 821.7601962804795\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015624761581420898,\n      \"min\": 0.015624761581420898,\n      \"avg\": 0.015624761581420898,\n      \"last\": 0.015624761581420898,\n      \"last-5-avg\": 0.015624761581420898,\n      \"last-10-avg\": 0.015624761581420898\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe56f0f0af0af0b473fe56f0f0af0af0b473fe56f0ea1ea1ea2473fe56f0f2df2df2e473fe56f0f2df2df2e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe56f0ee7ee7ee8473fe56f0f96f96f97473fe56f0ee7ee7ee8473fe56f0f73f73f74473fe56f0f0af0af0b473fe56f0f0af0af0b473fe56f0f0af0af0b473fe56f0ea1ea1ea2473fe56f0f2df2df2e473fe56f0f2df2df2e652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f325325325325652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f32532532532547404f325325325325652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f94869452946807680d43086c7e58a40c3cdd3f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403faa66880000004740401dec6e00000047403ff6a7500000004740401379020000004740403f34ae000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040193fe00000004740400d0adc0000004740402226e0000000474040256ec80000004740401d30c200000047403faa66880000004740401dec6e00000047403ff6a7500000004740401379020000004740403f34ae000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2d629ce0000047408b2f4163c0000047408c2ef69e40000047408d302e2e60000047408e342179400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408528f25440000047408629c3020000004740872be5700000004740882e3c5c800000474089300f68a0000047408a2d629ce0000047408b2f4163c0000047408c2ef69e40000047408d302e2e60000047408e342179400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2d629ce0000047408b2f4163c0000047408c2ef69e40000047408d302e2e60000047408e342179400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408528f25440000047408629c3020000004740872be5700000004740882e3c5c800000474089300f68a0000047408a2d629ce0000047408b2f4163c0000047408c2ef69e40000047408d302e2e60000047408e342179400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000473f8fffe000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668643853.9339747,\n  \"relative_logdir\": \"tune_hp_757a3_00041_41_batch_size=4,learning_rate=0.0001,model=resnet50_2022-11-17_03-10-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00042\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 0.0001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"42_batch_size=8,learning_rate=0.0001,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6370310987162794,\n    \"accuracy\": 65.8119658119658,\n    \"f1_score\": 0.6153846153846153,\n    \"time_this_iter_s\": 32.074113607406616,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00042\",\n    \"experiment_id\": \"9ed62f98745e452f8406e49cb874689f\",\n    \"date\": \"2022-11-17_03-43-17\",\n    \"timestamp\": 1668645797,\n    \"time_total_s\": 968.4983162879944,\n    \"pid\": 23916,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 968.4983162879944,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"42_batch_size=8,learning_rate=0.0001,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668645797.547731,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6370310987162794,\n      \"min\": 0.6370309030907786,\n      \"avg\": 0.6370310182924619,\n      \"last\": 0.6370310987162794,\n      \"last-5-avg\": 0.6370310204660791,\n      \"last-10-avg\": 0.6370310139452291\n    },\n    \"accuracy\": {\n      \"max\": 65.8119658119658,\n      \"min\": 65.8119658119658,\n      \"avg\": 65.8119658119658,\n      \"last\": 65.8119658119658,\n      \"last-5-avg\": 65.8119658119658,\n      \"last-10-avg\": 65.8119658119658\n    },\n    \"f1_score\": {\n      \"max\": 0.6153846153846153,\n      \"min\": 0.6153846153846153,\n      \"avg\": 0.6153846153846152,\n      \"last\": 0.6153846153846153,\n      \"last-5-avg\": 0.6153846153846153,\n      \"last-10-avg\": 0.6153846153846152\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.52017641067505,\n      \"min\": 31.788909673690796,\n      \"avg\": 32.28327720959981,\n      \"last\": 32.074113607406616,\n      \"last-5-avg\": 32.06223015785217,\n      \"last-10-avg\": 32.049303841590884\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 968.4983162879944,\n      \"min\": 35.52017641067505,\n      \"avg\": 503.57145121892285,\n      \"last\": 968.4983162879944,\n      \"last-5-avg\": 904.3958548545837,\n      \"last-10-avg\": 824.1598087310791\n    },\n    \"time_since_restore\": {\n      \"max\": 968.4983162879944,\n      \"min\": 35.52017641067505,\n      \"avg\": 503.57145121892285,\n      \"last\": 968.4983162879944,\n      \"last-5-avg\": 904.3958548545837,\n      \"last-10-avg\": 824.1598087310791\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe4628ec4ec4ec5473fe4628ee7ee7ee8473fe4628ee7ee7ee8473fe4628ec4ec4ec5473fe4628f0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4628ee7ee7ee8473fe4628ea1ea1ea2473fe4628ee7ee7ee8473fe4628ee7ee7ee8473fe4628ee7ee7ee8473fe4628ec4ec4ec5473fe4628ee7ee7ee8473fe4628ee7ee7ee8473fe4628ec4ec4ec5473fe4628f0af0af0b652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f47405073f73f73f73f652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f94869452946807680d4308133bb1133bb1e33f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400d0ab200000047404014929800000047403fde3ebc0000004740400d9a94000000474040097c8e000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fee186c00000047403fce467000000047404016e27200000047403fea5a1c0000004740402d092a0000004740400d0ab200000047404014929800000047403fde3ebc0000004740400d9a94000000474040097c8e000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a424ffbc0000047408b43992540000047408c428b1b20000047408d4364c460000047408e43fc8d400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740853f7b928000004740863dedc60000004740873f5bed2000004740883eaebe000000474089417f50a0000047408a424ffbc0000047408b43992540000047408c428b1b20000047408d4364c460000047408e43fc8d400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a424ffbc0000047408b43992540000047408c428b1b20000047408d4364c460000047408e43fc8d400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740853f7b928000004740863dedc60000004740873f5bed2000004740883eaebe000000474089417f50a0000047408a424ffbc0000047408b43992540000047408c428b1b20000047408d4364c460000047408e43fc8d400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668644825.0817068,\n  \"relative_logdir\": \"tune_hp_757a3_00042_42_batch_size=8,learning_rate=0.0001,model=resnet50_2022-11-17_03-27-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00043\",\n  \"config\": {\n    \"learning_rate\": 0.0001,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 0.0001,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"43_batch_size=16,learning_rate=0.0001,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6177212315746862,\n    \"accuracy\": 67.52136752136752,\n    \"f1_score\": 0.6415094339622642,\n    \"time_this_iter_s\": 32.53240418434143,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00043\",\n    \"experiment_id\": \"4e1b530e910c4d3888a52d0d5877f359\",\n    \"date\": \"2022-11-17_03-59-25\",\n    \"timestamp\": 1668646765,\n    \"time_total_s\": 963.1953620910645,\n    \"pid\": 25576,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0001,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 963.1953620910645,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"43_batch_size=16,learning_rate=0.0001,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668646765.585686,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6177213619916867,\n      \"min\": 0.6177212315746862,\n      \"avg\": 0.6177212554844698,\n      \"last\": 0.6177212315746862,\n      \"last-5-avg\": 0.6177212706997863,\n      \"last-10-avg\": 0.6177212641789362\n    },\n    \"accuracy\": {\n      \"max\": 67.52136752136752,\n      \"min\": 67.52136752136752,\n      \"avg\": 67.52136752136748,\n      \"last\": 67.52136752136752,\n      \"last-5-avg\": 67.52136752136752,\n      \"last-10-avg\": 67.52136752136754\n    },\n    \"f1_score\": {\n      \"max\": 0.6415094339622642,\n      \"min\": 0.6415094339622642,\n      \"avg\": 0.641509433962264,\n      \"last\": 0.6415094339622642,\n      \"last-5-avg\": 0.6415094339622642,\n      \"last-10-avg\": 0.6415094339622643\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.994558334350586,\n      \"min\": 31.63323664665222,\n      \"avg\": 32.10651206970214,\n      \"last\": 32.53240418434143,\n      \"last-5-avg\": 32.26814103126526,\n      \"last-10-avg\": 32.149044156074524\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 963.1953620910645,\n      \"min\": 33.994558334350586,\n      \"avg\": 497.7365281422933,\n      \"last\": 963.1953620910645,\n      \"last-5-avg\": 898.5278416156768,\n      \"last-10-avg\": 818.2191068649292\n    },\n    \"time_since_restore\": {\n      \"max\": 963.1953620910645,\n      \"min\": 33.994558334350586,\n      \"avg\": 497.7365281422933,\n      \"last\": 963.1953620910645,\n      \"last-5-avg\": 898.5278416156768,\n      \"last-10-avg\": 818.2191068649292\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3c45f50f50f51473fe3c45f96f96f97473fe3c45f73f73f74473fe3c45f50f50f51473fe3c45f50f50f51652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3c45f50f50f51473fe3c45f50f50f51473fe3c45f73f73f74473fe3c45f50f50f51473fe3c45f73f73f74473fe3c45f50f50f51473fe3c45f96f96f97473fe3c45f73f73f74473fe3c45f50f50f51473fe3c45f50f50f51652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16474050e15e15e15e16652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f94869452946807680d43084e30deca3e87e43f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400e0db80000004740402d3bd600000047404017231e0000004740401509bc0000004740404425d2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740401d097c00000047403ffa15dc00000047403ffe015c000000474040070a8a00000047403fe615dc0000004740400e0db80000004740402d3bd600000047404017231e0000004740401509bc0000004740404425d2000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0fb731e0000047408b128aef40000047408c13fd2120000047408d154dbce0000047408e19901a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850f74452000004740860f44f40000004740870f34fee000004740880fa5a78000004740890ed65660000047408a0fb731e0000047408b128aef40000047408c13fd2120000047408d154dbce0000047408e19901a000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0fb731e0000047408b128aef40000047408c13fd2120000047408d154dbce0000047408e19901a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850f74452000004740860f44f40000004740870f34fee000004740880fa5a78000004740890ed65660000047408a0fb731e0000047408b128aef40000047408c13fd2120000047408d154dbce0000047408e19901a000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668645798.4228094,\n  \"relative_logdir\": \"tune_hp_757a3_00043_43_batch_size=16,learning_rate=0.0001,model=resnet50_2022-11-17_03-43-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00044\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-05,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"44_batch_size=2,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6791250766851963,\n    \"accuracy\": 46.15384615384615,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.02490568161011,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00044\",\n    \"experiment_id\": \"af702233bf674e718a735ad1b6532cbc\",\n    \"date\": \"2022-11-17_04-16-03\",\n    \"timestamp\": 1668647763,\n    \"time_total_s\": 993.6453201770782,\n    \"pid\": 22352,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 993.6453201770782,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"44_batch_size=2,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668647763.7150614,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6791252071021968,\n      \"min\": 0.6791248158511952,\n      \"avg\": 0.6791250353864793,\n      \"last\": 0.6791250766851963,\n      \"last-5-avg\": 0.6791250375600961,\n      \"last-10-avg\": 0.679125024518396\n    },\n    \"accuracy\": {\n      \"max\": 46.15384615384615,\n      \"min\": 46.15384615384615,\n      \"avg\": 46.15384615384615,\n      \"last\": 46.15384615384615,\n      \"last-5-avg\": 46.15384615384615,\n      \"last-10-avg\": 46.153846153846146\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.357340574264526,\n      \"min\": 31.86841082572937,\n      \"avg\": 33.12151067256928,\n      \"last\": 32.02490568161011,\n      \"last-5-avg\": 32.46973934173584,\n      \"last-10-avg\": 33.079825091362\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 993.6453201770782,\n      \"min\": 52.357340574264526,\n      \"avg\": 520.1441374142964,\n      \"last\": 993.6453201770782,\n      \"last-5-avg\": 929.2435862064361,\n      \"last-10-avg\": 846.0626060247421\n    },\n    \"time_since_restore\": {\n      \"max\": 993.6453201770782,\n      \"min\": 52.357340574264526,\n      \"avg\": 520.1441374142964,\n      \"last\": 993.6453201770782,\n      \"last-5-avg\": 929.2435862064361,\n      \"last-10-avg\": 846.0626060247421\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5bb6483483483473fe5bb6483483483473fe5bb643d43d43d473fe5bb6460460460473fe5bb6483483483652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5bb643d43d43d473fe5bb63f73f73f7473fe5bb64a64a64a6473fe5bb6460460460473fe5bb64a64a64a6473fe5bb6483483483473fe5bb6483483483473fe5bb643d43d43d473fe5bb6460460460473fe5bb6483483483652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408aec6e000000474040630526000000474040212ab60000004740401a55b200000047404003301c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040196888000000474040680d6a00000047404156f65e00000047404190dba8000000474040d043060000004740408aec6e000000474040630526000000474040212ab60000004740401a55b200000047404003301c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408b030e4300000047408c093e9560000047408d0b5140c0000047408e0cf69be0000047408f0d299da00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085b85d54c00000474086bede2b600000474087d44d91400000474088ed5b4bc00000474089fa5f7c20000047408b030e4300000047408c093e9560000047408d0b5140c0000047408e0cf69be0000047408f0d299da00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408b030e4300000047408c093e9560000047408d0b5140c0000047408e0cf69be0000047408f0d299da00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085b85d54c00000474086bede2b600000474087d44d91400000474088ed5b4bc00000474089fa5f7c20000047408b030e4300000047408c093e9560000047408d0b5140c0000047408e0cf69be0000047408f0d299da00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668646766.1792984,\n  \"relative_logdir\": \"tune_hp_757a3_00044_44_batch_size=2,learning_rate=0.0000,model=resnet50_2022-11-17_03-59-26\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00045\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-05,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"45_batch_size=4,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6832699897961739,\n    \"accuracy\": 46.58119658119658,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.711785554885864,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00045\",\n    \"experiment_id\": \"3c1efe91db1d4f8db990572df3850ae1\",\n    \"date\": \"2022-11-17_04-32-09\",\n    \"timestamp\": 1668648729,\n    \"time_total_s\": 961.5770363807678,\n    \"pid\": 11580,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.5770363807678,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"45_batch_size=4,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668648729.6192207,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6832703158386753,\n      \"min\": 0.6832697941706731,\n      \"avg\": 0.6832700267476568,\n      \"last\": 0.6832699897961739,\n      \"last-5-avg\": 0.6832700419629741,\n      \"last-10-avg\": 0.6832700093587241\n    },\n    \"accuracy\": {\n      \"max\": 46.58119658119658,\n      \"min\": 46.58119658119658,\n      \"avg\": 46.58119658119655,\n      \"last\": 46.58119658119658,\n      \"last-5-avg\": 46.58119658119658,\n      \"last-10-avg\": 46.581196581196586\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.93077993392944,\n      \"min\": 31.666667222976685,\n      \"avg\": 32.052567879358925,\n      \"last\": 31.711785554885864,\n      \"last-5-avg\": 31.898868131637574,\n      \"last-10-avg\": 31.940487384796143\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.5770363807678,\n      \"min\": 34.93077993392944,\n      \"avg\": 498.1824217796324,\n      \"last\": 961.5770363807678,\n      \"last-5-avg\": 897.7010556697845,\n      \"last-10-avg\": 817.8544365882874\n    },\n    \"time_since_restore\": {\n      \"max\": 961.5770363807678,\n      \"min\": 34.93077993392944,\n      \"avg\": 498.1824217796324,\n      \"last\": 961.5770363807678,\n      \"last-5-avg\": 897.7010556697845,\n      \"last-10-avg\": 817.8544365882874\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5dd5906906907473fe5dd594c94c94d473fe5dd5906906907473fe5dd594c94c94d473fe5dd5906906907652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5dd58e38e38e4473fe5dd589d89d89e473fe5dd592992992a473fe5dd58e38e38e4473fe5dd596f96f970473fe5dd5906906907473fe5dd594c94c94d473fe5dd5906906907473fe5dd594c94c94d473fe5dd5906906907652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403faaaab400000047403fe31bbc0000004740400532fc00000047404018149000000047403fb63794000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ff491b000000047403fe6a9a000000047403fd219c80000004740400d09c400000047404010d80a00000047403faaaab400000047403fe31bbc0000004740400532fc00000047404018149000000047403fb63794000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0dfeb200000047408b0d178fe0000047408c0d6abfa0000047408d0eec08a0000047408e0c9dc5400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085110524400000474086103a714000004740870ecb3f8000004740880f9bdbc0000047408910a95c60000047408a0dfeb200000047408b0d178fe0000047408c0d6abfa0000047408d0eec08a0000047408e0c9dc5400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a0dfeb200000047408b0d178fe0000047408c0d6abfa0000047408d0eec08a0000047408e0c9dc5400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085110524400000474086103a714000004740870ecb3f8000004740880f9bdbc0000047408910a95c60000047408a0dfeb200000047408b0d178fe0000047408c0d6abfa0000047408d0eec08a0000047408e0c9dc5400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668647764.0587306,\n  \"relative_logdir\": \"tune_hp_757a3_00045_45_batch_size=4,learning_rate=0.0000,model=resnet50_2022-11-17_04-16-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00046\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-05,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"46_batch_size=8,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6583763839852097,\n    \"accuracy\": 50.0,\n    \"f1_score\": 0.1702127659574468,\n    \"time_this_iter_s\": 31.71132779121399,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00046\",\n    \"experiment_id\": \"6c444b21d3d14f3ab625d73ca59b4906\",\n    \"date\": \"2022-11-17_04-48-21\",\n    \"timestamp\": 1668649701,\n    \"time_total_s\": 967.2003774642944,\n    \"pid\": 27616,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 967.2003774642944,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.01559591293334961,\n    \"experiment_tag\": \"46_batch_size=8,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668649701.5840707,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6583763839852097,\n      \"min\": 0.6583761883597089,\n      \"avg\": 0.6583763231239427,\n      \"last\": 0.6583763839852097,\n      \"last-5-avg\": 0.6583763709435096,\n      \"last-10-avg\": 0.6583763513809595\n    },\n    \"accuracy\": {\n      \"max\": 50.0,\n      \"min\": 50.0,\n      \"avg\": 50.0,\n      \"last\": 50.0,\n      \"last-5-avg\": 50.0,\n      \"last-10-avg\": 50.0\n    },\n    \"f1_score\": {\n      \"max\": 0.1702127659574468,\n      \"min\": 0.1702127659574468,\n      \"avg\": 0.17021276595744672,\n      \"last\": 0.1702127659574468,\n      \"last-5-avg\": 0.1702127659574468,\n      \"last-10-avg\": 0.1702127659574468\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.477601766586304,\n      \"min\": 31.69573402404785,\n      \"avg\": 32.24001258214314,\n      \"last\": 31.71132779121399,\n      \"last-5-avg\": 31.89608750343323,\n      \"last-10-avg\": 31.87494215965271\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 967.2003774642944,\n      \"min\": 34.477601766586304,\n      \"avg\": 502.34521203041083,\n      \"last\": 967.2003774642944,\n      \"last-5-avg\": 903.6110247611999,\n      \"last-10-avg\": 823.8000546693802\n    },\n    \"time_since_restore\": {\n      \"max\": 967.2003774642944,\n      \"min\": 34.477601766586304,\n      \"avg\": 502.34521203041083,\n      \"last\": 967.2003774642944,\n      \"last-5-avg\": 903.6110247611999,\n      \"last-10-avg\": 823.8000546693802\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.01559591293334961,\n      \"min\": 0.01559591293334961,\n      \"avg\": 0.01559591293334961,\n      \"last\": 0.01559591293334961,\n      \"last-5-avg\": 0.01559591293334961,\n      \"last-10-avg\": 0.01559591293334961\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5116b59b59b5a473fe5116b59b59b5a473fe5116b59b59b5a473fe5116b36b36b37473fe5116b59b59b5a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5116b59b59b5a473fe5116b36b36b37473fe5116b36b36b37473fe5116b36b36b37473fe5116b36b36b37473fe5116b59b59b5a473fe5116b59b59b5a473fe5116b59b59b5a473fe5116b36b36b37473fe5116b59b59b5a652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000474049000000000000652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f94869452946807680d43085710932b88c9c53f9486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400d2eb4000000474040031db200000047403fd9255800000047403fcb263c00000047403fb61994000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ff0a43800000047403fc65db000000047403fd2162800000047403fb21ba000000047404004d43a0000004740400d2eb4000000474040031db200000047403fd9255800000047403fcb263c00000047403fb61994000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3e955b20000047408b3ec73640000047408c3d906100000047408d3be992e0000047408e399a5f800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854320b080000047408641539e0000004740873fe44f4000004740883d752c4000004740893dc26fe0000047408a3e955b20000047408b3ec73640000047408c3d906100000047408d3be992e0000047408e399a5f800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a3e955b20000047408b3ec73640000047408c3d906100000047408d3be992e0000047408e399a5f800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854320b080000047408641539e0000004740873fe44f4000004740883d752c4000004740893dc26fe0000047408a3e955b20000047408b3ec73640000047408c3d906100000047408d3be992e0000047408e399a5f800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000473f8ff0c000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668648730.3377943,\n  \"relative_logdir\": \"tune_hp_757a3_00046_46_batch_size=8,learning_rate=0.0000,model=resnet50_2022-11-17_04-32-10\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00047\",\n  \"config\": {\n    \"learning_rate\": 1e-05,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-05,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"47_batch_size=16,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6860255053919605,\n    \"accuracy\": 50.85470085470085,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.00902771949768,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00047\",\n    \"experiment_id\": \"9096945c35ce4ec7a3bf79eb98ae03fe\",\n    \"date\": \"2022-11-17_05-04-26\",\n    \"timestamp\": 1668650666,\n    \"time_total_s\": 960.3765909671783,\n    \"pid\": 13064,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-05,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 960.3765909671783,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"47_batch_size=16,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668650666.1471262,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6860255706004608,\n      \"min\": 0.68602537497496,\n      \"avg\": 0.6860254771349436,\n      \"last\": 0.6860255053919605,\n      \"last-5-avg\": 0.6860254793085605,\n      \"last-10-avg\": 0.6860254727877103\n    },\n    \"accuracy\": {\n      \"max\": 50.85470085470085,\n      \"min\": 50.85470085470085,\n      \"avg\": 50.854700854700845,\n      \"last\": 50.85470085470085,\n      \"last-5-avg\": 50.85470085470085,\n      \"last-10-avg\": 50.85470085470086\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.27325701713562,\n      \"min\": 31.510327100753784,\n      \"avg\": 32.012553032239275,\n      \"last\": 32.00902771949768,\n      \"last-5-avg\": 31.848454761505128,\n      \"last-10-avg\": 31.987357258796692\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 960.3765909671783,\n      \"min\": 34.27325701713562,\n      \"avg\": 497.2060321887333,\n      \"last\": 960.3765909671783,\n      \"last-5-avg\": 896.4914322376251,\n      \"last-10-avg\": 816.7300883054734\n    },\n    \"time_since_restore\": {\n      \"max\": 960.3765909671783,\n      \"min\": 34.27325701713562,\n      \"avg\": 497.2060321887333,\n      \"last\": 960.3765909671783,\n      \"last-5-avg\": 896.4914322376251,\n      \"last-10-avg\": 816.7300883054734\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5f3eb9fb9fba0473fe5f3eb9fb9fba0473fe5f3ebc2bc2bc3473fe5f3ebc2bc2bc3473fe5f3ebc2bc2bc3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5f3eb9fb9fba0473fe5f3eb9fb9fba0473fe5f3ebc2bc2bc3473fe5f3ebc2bc2bc3473fe5f3eb9fb9fba0473fe5f3eb9fb9fba0473fe5f3eb9fb9fba0473fe5f3ebc2bc2bc3473fe5f3ebc2bc2bc3473fe5f3ebc2bc2bc3652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d64740496d66d66d66d6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fb6198c00000047403f9e1ac400000047403ff0dda000000047403ff6a4140000004740400127d2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040335c340000004740401143fe00000047403fdcfa9400000047403ff6159000000047404022a62200000047403fb6198c00000047403f9e1ac400000047403ff0dda000000047403ff6a4140000004740400127d2000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a06c3e140000047408b03b4b760000047408c033ba460000047408d02f0c500000047408e030342200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085073bf1c00000474086085031a0000047408707380640000047408806e8b2c00000474089091314e0000047408a06c3e140000047408b03b4b760000047408c033ba460000047408d02f0c500000047408e030342200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a06c3e140000047408b03b4b760000047408c033ba460000047408d02f0c500000047408e030342200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085073bf1c00000474086085031a0000047408707380640000047408806e8b2c00000474089091314e0000047408a06c3e140000047408b03b4b760000047408c033ba460000047408d02f0c500000047408e030342200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668649701.7871501,\n  \"relative_logdir\": \"tune_hp_757a3_00047_47_batch_size=16,learning_rate=0.0000,model=resnet50_2022-11-17_04-48-21\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00048\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-06,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"48_batch_size=2,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6857109395866721,\n    \"accuracy\": 51.28205128205128,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.08620810508728,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00048\",\n    \"experiment_id\": \"c344fb0d17c748abb46426bd2c0f5c53\",\n    \"date\": \"2022-11-17_05-20-48\",\n    \"timestamp\": 1668651648,\n    \"time_total_s\": 978.2351474761963,\n    \"pid\": 18624,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 978.2351474761963,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"48_batch_size=2,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668651648.6156862,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6857114612546742,\n      \"min\": 0.6857108743781717,\n      \"avg\": 0.6857111352121731,\n      \"last\": 0.6857109395866721,\n      \"last-5-avg\": 0.6857111091287728,\n      \"last-10-avg\": 0.6857111286913229\n    },\n    \"accuracy\": {\n      \"max\": 51.28205128205128,\n      \"min\": 51.28205128205128,\n      \"avg\": 51.28205128205127,\n      \"last\": 51.28205128205128,\n      \"last-5-avg\": 51.282051282051285,\n      \"last-10-avg\": 51.282051282051285\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 53.035998582839966,\n      \"min\": 31.618186950683594,\n      \"avg\": 32.607838249206544,\n      \"last\": 32.08620810508728,\n      \"last-5-avg\": 31.999318599700928,\n      \"last-10-avg\": 31.92852363586426\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 978.2351474761963,\n      \"min\": 53.035998582839966,\n      \"avg\": 515.7016448895137,\n      \"last\": 978.2351474761963,\n      \"last-5-avg\": 914.1458264350891,\n      \"last-10-avg\": 834.324311375618\n    },\n    \"time_since_restore\": {\n      \"max\": 978.2351474761963,\n      \"min\": 53.035998582839966,\n      \"avg\": 515.7016448895137,\n      \"last\": 978.2351474761963,\n      \"last-5-avg\": 914.1458264350891,\n      \"last-10-avg\": 834.324311375618\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5f1589d89d89e473fe5f1589d89d89e473fe5f1589d89d89e473fe5f15834834835473fe5f15811811812652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5f15834834835473fe5f15857857858473fe5f15834834835473fe5f1592992992a473fe5f1589d89d89e473fe5f1589d89d89e473fe5f1589d89d89e473fe5f1589d89d89e473fe5f15834834835473fe5f15811811812652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff215c400000047403fc24c9c00000047404023225400000047403fee67f40000004740400b08de000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fc6814400000047403fea348000000047403fba16ec000000474040167e3e00000047403fb21b5c00000047403ff215c400000047403fc24c9c00000047404023225400000047403fee67f40000004740400b08de000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a91793d60000047408b8f8ba240000047408c91bdc780000047408d91310720000047408e91e195000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408595cd75200000474086951f1920000047408792efd08000004740889457b460000047408991e88f40000047408a91793d60000047408b8f8ba240000047408c91bdc780000047408d91310720000047408e91e195000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a91793d60000047408b8f8ba240000047408c91bdc780000047408d91310720000047408e91e195000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408595cd75200000474086951f1920000047408792efd08000004740889457b460000047408991e88f40000047408a91793d60000047408b8f8ba240000047408c91bdc780000047408d91310720000047408e91e195000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668650666.3970952,\n  \"relative_logdir\": \"tune_hp_757a3_00048_48_batch_size=2,learning_rate=0.0000,model=resnet50_2022-11-17_05-04-26\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00049\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-06,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"49_batch_size=4,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.7003245557475294,\n    \"accuracy\": 46.15384615384615,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.086928844451904,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00049\",\n    \"experiment_id\": \"4c85e769e96947b9b23f0e4759e9308f\",\n    \"date\": \"2022-11-17_05-37-03\",\n    \"timestamp\": 1668652623,\n    \"time_total_s\": 970.7266888618469,\n    \"pid\": 4136,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 970.7266888618469,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"49_batch_size=4,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668652623.7163804,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.7003247513730302,\n      \"min\": 0.7003244253305289,\n      \"avg\": 0.700324588351779,\n      \"last\": 0.7003245557475294,\n      \"last-5-avg\": 0.7003245818309296,\n      \"last-10-avg\": 0.7003245687892294\n    },\n    \"accuracy\": {\n      \"max\": 46.15384615384615,\n      \"min\": 46.15384615384615,\n      \"avg\": 46.15384615384615,\n      \"last\": 46.15384615384615,\n      \"last-5-avg\": 46.15384615384615,\n      \"last-10-avg\": 46.153846153846146\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.96096587181091,\n      \"min\": 31.75092387199402,\n      \"avg\": 32.3575562953949,\n      \"last\": 32.086928844451904,\n      \"last-5-avg\": 32.22310767173767,\n      \"last-10-avg\": 32.326948595047\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 970.7266888618469,\n      \"min\": 34.96096587181091,\n      \"avg\": 502.0848284085591,\n      \"last\": 970.7266888618469,\n      \"last-5-avg\": 906.3479768276214,\n      \"last-10-avg\": 825.6920001983642\n    },\n    \"time_since_restore\": {\n      \"max\": 970.7266888618469,\n      \"min\": 34.96096587181091,\n      \"avg\": 502.0848284085591,\n      \"last\": 970.7266888618469,\n      \"last-5-avg\": 906.3479768276214,\n      \"last-10-avg\": 825.6920001983642\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6690f2df2df2e473fe6690f50f50f51473fe6690f0af0af0b473fe6690ee7ee7ee8473fe6690f0af0af0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6690f0af0af0b473fe6690f0af0af0b473fe6690f0af0af0b473fe6690f0af0af0b473fe6690f0af0af0b473fe6690f2df2df2e473fe6690f50f50f51473fe6690f0af0af0b473fe6690ee7ee7ee8473fe6690f0af0af0b652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b47404713b13b13b13b652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740402124e20000004740402c31d8000000474040094bda0000004740402d06e60000004740400b207c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740406d04e00000004740403f05d8000000474040311a2e0000004740400b64080000004740402b2ba00000004740402124e20000004740402c31d8000000474040094bda0000004740402d06e60000004740400b207c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4ef5f100000047408b51b90e80000047408c524dcc20000047408d551e3a80000047408e55d042400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854278a8000000474086466905800000474087497aa86000004740884a30e8e000004740894ce3a2e0000047408a4ef5f100000047408b51b90e80000047408c524dcc20000047408d551e3a80000047408e55d042400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a4ef5f100000047408b51b90e80000047408c524dcc20000047408d551e3a80000047408e55d042400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854278a8000000474086466905800000474087497aa86000004740884a30e8e000004740894ce3a2e0000047408a4ef5f100000047408b51b90e80000047408c524dcc20000047408d551e3a80000047408e55d042400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668651649.0531263,\n  \"relative_logdir\": \"tune_hp_757a3_00049_49_batch_size=4,learning_rate=0.0000,model=resnet50_2022-11-17_05-20-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00050\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-06,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"50_batch_size=8,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.697154314090044,\n    \"accuracy\": 47.863247863247864,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.93065071105957,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00050\",\n    \"experiment_id\": \"57f54a52d880468e94b7e195bd388204\",\n    \"date\": \"2022-11-17_05-53-13\",\n    \"timestamp\": 1668653593,\n    \"time_total_s\": 964.5396649837494,\n    \"pid\": 20352,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 964.5396649837494,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015621662139892578,\n    \"experiment_tag\": \"50_batch_size=8,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668653593.1611402,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6971544445070446,\n      \"min\": 0.6971541836730435,\n      \"avg\": 0.697154318437277,\n      \"last\": 0.697154314090044,\n      \"last-5-avg\": 0.6971543532151442,\n      \"last-10-avg\": 0.697154333652594\n    },\n    \"accuracy\": {\n      \"max\": 47.863247863247864,\n      \"min\": 47.863247863247864,\n      \"avg\": 47.86324786324783,\n      \"last\": 47.863247863247864,\n      \"last-5-avg\": 47.863247863247864,\n      \"last-10-avg\": 47.863247863247864\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.086931467056274,\n      \"min\": 31.620788097381592,\n      \"avg\": 32.15132216612496,\n      \"last\": 31.93065071105957,\n      \"last-5-avg\": 31.880258083343506,\n      \"last-10-avg\": 31.93523576259613\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 964.5396649837494,\n      \"min\": 35.086931467056274,\n      \"avg\": 500.05240884621935,\n      \"last\": 964.5396649837494,\n      \"last-5-avg\": 900.7974781990051,\n      \"last-10-avg\": 820.8873418569565\n    },\n    \"time_since_restore\": {\n      \"max\": 964.5396649837494,\n      \"min\": 35.086931467056274,\n      \"avg\": 500.05240884621935,\n      \"last\": 964.5396649837494,\n      \"last-5-avg\": 900.7974781990051,\n      \"last-10-avg\": 820.8873418569565\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015621662139892578,\n      \"min\": 0.015621662139892578,\n      \"avg\": 0.015621662139892578,\n      \"last\": 0.015621662139892578,\n      \"last-5-avg\": 0.015621662139892578,\n      \"last-10-avg\": 0.015621662139892578\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe64f1690690690473fe64f1690690690473fe64f16b36b36b3473fe64f16d66d66d6473fe64f1690690690652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64f1690690690473fe64f164a64a64a473fe64f1690690690473fe64f16b36b36b3473fe64f16b36b36b3473fe64f1690690690473fe64f1690690690473fe64f16b36b36b3473fe64f16d66d66d6473fe64f1690690690652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8474047ee7ee7ee7ee8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fbe410800000047404014d6a400000047403fde529c00000047403fb23aec00000047403fee3f20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404001248600000047403f9eebf800000047404002cef2000000474040073a680000004740401f18b600000047403fbe410800000047404014d6a400000047403fde529c00000047403fb23aec00000047403fee3f20000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a270d6c60000047408b285ad6a0000047408c274d6b80000047408d24df42e0000047408e24513be00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852991e360000047408626894320000047408726b6324000004740882729d8c00000474089291b6420000047408a270d6c60000047408b285ad6a0000047408c274d6b80000047408d24df42e0000047408e24513be00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a270d6c60000047408b285ad6a0000047408c274d6b80000047408d24df42e0000047408e24513be00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852991e360000047408626894320000047408726b6324000004740882729d8c00000474089291b6420000047408a270d6c60000047408b285ad6a0000047408c274d6b80000047408d24df42e0000047408e24513be00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000473f8ffe4000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668652624.684897,\n  \"relative_logdir\": \"tune_hp_757a3_00050_50_batch_size=8,learning_rate=0.0000,model=resnet50_2022-11-17_05-37-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00051\",\n  \"config\": {\n    \"learning_rate\": 1e-06,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-06,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"51_batch_size=16,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6867946396526109,\n    \"accuracy\": 52.13675213675214,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.0281662940979,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00051\",\n    \"experiment_id\": \"2d8e741015bf4ea6a64ebc2231f406c7\",\n    \"date\": \"2022-11-17_06-09-23\",\n    \"timestamp\": 1668654563,\n    \"time_total_s\": 966.6457092761993,\n    \"pid\": 24520,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-06,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 966.6457092761993,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"51_batch_size=16,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668654563.8549404,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6867946396526109,\n      \"min\": 0.6867945092356104,\n      \"avg\": 0.6867945961802773,\n      \"last\": 0.6867946396526109,\n      \"last-5-avg\": 0.6867946266109108,\n      \"last-10-avg\": 0.6867946070483607\n    },\n    \"accuracy\": {\n      \"max\": 52.13675213675214,\n      \"min\": 52.13675213675214,\n      \"avg\": 52.13675213675216,\n      \"last\": 52.13675213675214,\n      \"last-5-avg\": 52.13675213675215,\n      \"last-10-avg\": 52.13675213675215\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.478527307510376,\n      \"min\": 31.78238582611084,\n      \"avg\": 32.22152364253998,\n      \"last\": 32.0281662940979,\n      \"last-5-avg\": 32.04398775100708,\n      \"last-10-avg\": 32.22227516174316\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 966.6457092761993,\n      \"min\": 34.478527307510376,\n      \"avg\": 500.5191512346267,\n      \"last\": 966.6457092761993,\n      \"last-5-avg\": 902.6031179428101,\n      \"last-10-avg\": 822.0918808698655\n    },\n    \"time_since_restore\": {\n      \"max\": 966.6457092761993,\n      \"min\": 34.478527307510376,\n      \"avg\": 500.5191512346267,\n      \"last\": 966.6457092761993,\n      \"last-5-avg\": 902.6031179428101,\n      \"last-10-avg\": 822.0918808698655\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5fa38c08c08c1473fe5fa38c08c08c1473fe5fa389d89d89e473fe5fa38c08c08c1473fe5fa38c08c08c1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5fa387a87a87b473fe5fa38c08c08c1473fe5fa38c08c08c1473fe5fa389d89d89e473fe5fa389d89d89e473fe5fa38c08c08c1473fe5fa38c08c08c1473fe5fa389d89d89e473fe5fa38c08c08c1473fe5fa38c08c08c1652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a118118118119652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a11811811811947404a118118118119652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff613c40000004740403349ec00000047403fca3850000000474040051c0a000000474040039af4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404013087600000047404033077600000047404068279e0000004740402f07aa000000474040231cf800000047403ff613c40000004740403349ec00000047403fca3850000000474040051c0a000000474040039af4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a33189880000047408b364d3740000047408c349ef9c0000047408d34f0ba60000047408e352a69a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852492bf00000047408627c3366000004740872e45b040000047408831362ae000004740893367fa60000047408a33189880000047408b364d3740000047408c349ef9c0000047408d34f0ba60000047408e352a69a00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a33189880000047408b364d3740000047408c349ef9c0000047408d34f0ba60000047408e352a69a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740852492bf00000047408627c3366000004740872e45b040000047408831362ae000004740893367fa60000047408a33189880000047408b364d3740000047408c349ef9c0000047408d34f0ba60000047408e352a69a00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668653593.2392464,\n  \"relative_logdir\": \"tune_hp_757a3_00051_51_batch_size=16,learning_rate=0.0000,model=resnet50_2022-11-17_05-53-13\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00052\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-07,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"52_batch_size=2,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6884875175280448,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.19890832901001,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00052\",\n    \"experiment_id\": \"9e510bccfdaa4d5680e6277c5e6c743e\",\n    \"date\": \"2022-11-17_06-25-49\",\n    \"timestamp\": 1668655549,\n    \"time_total_s\": 980.275315284729,\n    \"pid\": 18860,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 980.275315284729,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"52_batch_size=2,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668655549.0978334,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6884877783620459,\n      \"min\": 0.6884873871110443,\n      \"avg\": 0.6884875457850617,\n      \"last\": 0.6884875175280448,\n      \"last-5-avg\": 0.6884874523195446,\n      \"last-10-avg\": 0.6884875175280448\n    },\n    \"accuracy\": {\n      \"max\": 48.29059829059829,\n      \"min\": 48.29059829059829,\n      \"avg\": 48.2905982905983,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 48.29059829059829,\n      \"last-10-avg\": 48.29059829059828\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.48977756500244,\n      \"min\": 31.66587495803833,\n      \"avg\": 32.675843842824285,\n      \"last\": 32.19890832901001,\n      \"last-5-avg\": 32.23240413665771,\n      \"last-10-avg\": 32.105589747428894\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 980.275315284729,\n      \"min\": 52.48977756500244,\n      \"avg\": 515.7338487466175,\n      \"last\": 980.275315284729,\n      \"last-5-avg\": 915.7683578968048,\n      \"last-10-avg\": 835.4882727861404\n    },\n    \"time_since_restore\": {\n      \"max\": 980.275315284729,\n      \"min\": 52.48977756500244,\n      \"avg\": 515.7338487466175,\n      \"last\": 980.275315284729,\n      \"last-5-avg\": 915.7683578968048,\n      \"last-10-avg\": 835.4882727861404\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60816f96f96f9473fe60816b36b36b3473fe60816d66d66d6473fe60816b36b36b3473fe60816f96f96f9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe60816d66d66d6473fe60816f96f96f9473fe6081785785785473fe60816b36b36b3473fe6081785785785473fe60816f96f96f9473fe60816b36b36b3473fe60816d66d66d6473fe60816b36b36b3473fe60816f96f96f9652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474040095bde000000474040330e240000004740401109540000004740402dd3ee0000004740401975d4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fee52e400000047404016be2a00000047403fe67aa400000047403ffe152c00000047403fe47614000000474040095bde000000474040330e240000004740401109540000004740402dd3ee0000004740401975d4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a997dc4e0000047408b9caea720000047408c9dbf3c60000047408da09c7b40000047408ea233d8800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740859933f54000004740869a9fd7e0000047408799d3ad00000047408899c45660000047408998e80700000047408a997dc4e0000047408b9caea720000047408c9dbf3c60000047408da09c7b40000047408ea233d8800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a997dc4e0000047408b9caea720000047408c9dbf3c60000047408da09c7b40000047408ea233d8800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740859933f54000004740869a9fd7e0000047408799d3ad00000047408899c45660000047408998e80700000047408a997dc4e0000047408b9caea720000047408c9dbf3c60000047408da09c7b40000047408ea233d8800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668654564.870633,\n  \"relative_logdir\": \"tune_hp_757a3_00052_52_batch_size=2,learning_rate=0.0000,model=resnet50_2022-11-17_06-09-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00053\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-07,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"53_batch_size=4,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6903245713975694,\n    \"accuracy\": 49.14529914529914,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.82331895828247,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00053\",\n    \"experiment_id\": \"7880f38e1c404f66b5177b8117ee90de\",\n    \"date\": \"2022-11-17_06-41-54\",\n    \"timestamp\": 1668656514,\n    \"time_total_s\": 961.2403845787048,\n    \"pid\": 4152,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.2403845787048,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015595197677612305,\n    \"experiment_tag\": \"53_batch_size=4,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668656514.8058984,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6903245713975694,\n      \"min\": 0.6903242453550681,\n      \"avg\": 0.6903244692375855,\n      \"last\": 0.6903245713975694,\n      \"last-5-avg\": 0.6903245061890692,\n      \"last-10-avg\": 0.6903244866265191\n    },\n    \"accuracy\": {\n      \"max\": 49.14529914529914,\n      \"min\": 49.14529914529914,\n      \"avg\": 49.145299145299134,\n      \"last\": 49.14529914529914,\n      \"last-5-avg\": 49.14529914529914,\n      \"last-10-avg\": 49.14529914529914\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.92984652519226,\n      \"min\": 31.648841857910156,\n      \"avg\": 32.04134615262349,\n      \"last\": 31.82331895828247,\n      \"last-5-avg\": 31.833223342895508,\n      \"last-10-avg\": 31.813869857788085\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.2403845787048,\n      \"min\": 34.92984652519226,\n      \"avg\": 498.99687400658905,\n      \"last\": 961.2403845787048,\n      \"last-5-avg\": 897.5940214633941,\n      \"last-10-avg\": 818.0354403495788\n    },\n    \"time_since_restore\": {\n      \"max\": 961.2403845787048,\n      \"min\": 34.92984652519226,\n      \"avg\": 498.99687400658905,\n      \"last\": 961.2403845787048,\n      \"last-5-avg\": 897.5940214633941,\n      \"last-10-avg\": 818.0354403495788\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015595197677612305,\n      \"min\": 0.015595197677612305,\n      \"avg\": 0.015595197677612305,\n      \"last\": 0.015595197677612305,\n      \"last-5-avg\": 0.015595197677612305,\n      \"last-10-avg\": 0.015595197677612305\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe617236b36b36b473fe617238e38e38e473fe6172325325325473fe617236b36b36b473fe617238e38e38e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe617238e38e38e473fe6172302302302473fe617236b36b36b473fe6172348348348473fe617236b36b36b473fe617236b36b36b473fe617238e38e38e473fe6172325325325473fe617236b36b36b473fe617238e38e38e652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929474048929929929929652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ff03ba400000047403fca1a3800000047403fb2194800000047403feb527400000047403fd2c508000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fa61a80000000474040015ea000000047403fb6425400000047403fda173c00000047403fbfc9d000000047403ff03ba400000047403fca1a3800000047403fb2194800000047403feb527400000047403fd2c508000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a1019f6e0000047408b0e6ac8a0000047408c0bfb92e0000047408d0b562680000047408e09ec4ec00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085160114c000004740861616fec0000047408713c9116000004740881299cb400000474089109819c0000047408a1019f6e0000047408b0e6ac8a0000047408c0bfb92e0000047408d0b562680000047408e09ec4ec00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a1019f6e0000047408b0e6ac8a0000047408c0bfb92e0000047408d0b562680000047408e09ec4ec00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085160114c000004740861616fec0000047408713c9116000004740881299cb400000474089109819c0000047408a1019f6e0000047408b0e6ac8a0000047408c0bfb92e0000047408d0b562680000047408e09ec4ec00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000473f8ff06000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668655549.5980072,\n  \"relative_logdir\": \"tune_hp_757a3_00053_53_batch_size=4,learning_rate=0.0000,model=resnet50_2022-11-17_06-25-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00054\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-07,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"54_batch_size=8,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6928315121903379,\n    \"accuracy\": 48.29059829059829,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.916862964630127,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00054\",\n    \"experiment_id\": \"9fbd2612fc6945d0b3f0c33ac3e6bcf6\",\n    \"date\": \"2022-11-17_06-58-01\",\n    \"timestamp\": 1668657481,\n    \"time_total_s\": 962.1277213096619,\n    \"pid\": 26764,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 962.1277213096619,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"54_batch_size=8,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668657481.1508842,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6928316426073384,\n      \"min\": 0.6928314469818376,\n      \"avg\": 0.6928315230584213,\n      \"last\": 0.6928315121903379,\n      \"last-5-avg\": 0.692831551315438,\n      \"last-10-avg\": 0.6928315317528879\n    },\n    \"accuracy\": {\n      \"max\": 48.29059829059829,\n      \"min\": 48.29059829059829,\n      \"avg\": 48.2905982905983,\n      \"last\": 48.29059829059829,\n      \"last-5-avg\": 48.29059829059829,\n      \"last-10-avg\": 48.29059829059828\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.42519402503967,\n      \"min\": 31.571096420288086,\n      \"avg\": 32.07092404365539,\n      \"last\": 31.916862964630127,\n      \"last-5-avg\": 31.907085180282593,\n      \"last-10-avg\": 31.99684319496155\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 962.1277213096619,\n      \"min\": 34.42519402503967,\n      \"avg\": 498.71802928447704,\n      \"last\": 962.1277213096619,\n      \"last-5-avg\": 898.2220399856567,\n      \"last-10-avg\": 818.3188776016235\n    },\n    \"time_since_restore\": {\n      \"max\": 962.1277213096619,\n      \"min\": 34.42519402503967,\n      \"avg\": 498.71802928447704,\n      \"last\": 962.1277213096619,\n      \"last-5-avg\": 898.2220399856567,\n      \"last-10-avg\": 818.3188776016235\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe62bad20d20d21473fe62bacdacdacdb473fe62bad43d43d44473fe62bad20d20d21473fe62bacfdcfdcfe652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe62bacdacdacdb473fe62bad20d20d21473fe62bad20d20d21473fe62bacdacdacdb473fe62bacfdcfdcfe473fe62bad20d20d21473fe62bacdacdacdb473fe62bad43d43d44473fe62bad20d20d21473fe62bacfdcfdcfe652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253474048253253253253652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fb6a29c00000047403ffe3e2c00000047403fde42b8000000474040059b5200000047403feab788000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fea39540000004740403240d800000047403ff660400000004740400b1aa200000047404009c47a00000047403fb6a29c00000047403ffe3e2c00000047403fde42b8000000474040059b5200000047403feab788000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a12721a40000047408b12640ba0000047408c11562160000047408d11afd680000047408e110592c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408510980420000047408613bc11a00000474087136f13a000004740881420bdc0000047408914bd0560000047408a12721a40000047408b12640ba0000047408c11562160000047408d11afd680000047408e110592c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a12721a40000047408b12640ba0000047408c11562160000047408d11afd680000047408e110592c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408510980420000047408613bc11a00000474087136f13a000004740881420bdc0000047408914bd0560000047408a12721a40000047408b12640ba0000047408c11562160000047408d11afd680000047408e110592c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668656515.040241,\n  \"relative_logdir\": \"tune_hp_757a3_00054_54_batch_size=8,learning_rate=0.0000,model=resnet50_2022-11-17_06-41-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00055\",\n  \"config\": {\n    \"learning_rate\": 1e-07,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-07,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"55_batch_size=16,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6893139048519298,\n    \"accuracy\": 47.43589743589743,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.339759349823,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00055\",\n    \"experiment_id\": \"c252277c4b7b435c98390e4602bb9ebf\",\n    \"date\": \"2022-11-17_07-14-05\",\n    \"timestamp\": 1668658445,\n    \"time_total_s\": 959.7348139286041,\n    \"pid\": 16520,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-07,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 959.7348139286041,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"55_batch_size=16,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668658445.0253375,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6893140352689303,\n      \"min\": 0.6893138396434295,\n      \"avg\": 0.6893139331089466,\n      \"last\": 0.6893139048519298,\n      \"last-5-avg\": 0.6893139439770299,\n      \"last-10-avg\": 0.6893139309353299\n    },\n    \"accuracy\": {\n      \"max\": 47.43589743589743,\n      \"min\": 47.43589743589743,\n      \"avg\": 47.435897435897424,\n      \"last\": 47.43589743589743,\n      \"last-5-avg\": 47.43589743589743,\n      \"last-10-avg\": 47.43589743589744\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.21148085594177,\n      \"min\": 31.54155993461609,\n      \"avg\": 31.991160464286796,\n      \"last\": 32.339759349823,\n      \"last-5-avg\": 31.917734241485597,\n      \"last-10-avg\": 31.90833685398102\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 959.7348139286041,\n      \"min\": 34.21148085594177,\n      \"avg\": 496.775496840477,\n      \"last\": 959.7348139286041,\n      \"last-5-avg\": 895.545751953125,\n      \"last-10-avg\": 815.9250891447067\n    },\n    \"time_since_restore\": {\n      \"max\": 959.7348139286041,\n      \"min\": 34.21148085594177,\n      \"avg\": 496.775496840477,\n      \"last\": 959.7348139286041,\n      \"last-5-avg\": 895.545751953125,\n      \"last-10-avg\": 815.9250891447067\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe60edc08c08c09473fe60edc2bc2bc2c473fe60edc2bc2bc2c473fe60edc2bc2bc2c473fe60edc08c08c09652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe60edc08c08c09473fe60edc08c08c09473fe60edc2bc2bc2c473fe60edc08c08c09473fe60edc08c08c09473fe60edc08c08c09473fe60edc2bc2bc2c473fe60edc2bc2bc2c473fe60edc2bc2bc2c473fe60edc08c08c09652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c474047b7cb7cb7cb7c652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fc314b400000047403f9e463000000047403fa349a00000004740401d8a160000004740402b7d3c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fe770d000000047403fc2e02400000047404015093e00000047403f8aa3ac0000004740400fceb000000047403fc314b400000047403f9e463000000047403fa349a00000004740401d8a160000004740402b7d3c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089ff43f280000047408afc362400000047408bf9507100000047408cfb291260000047408dfde0e6200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850471af8000004740860288b0a0000047408703d944800000474088002e61e00000474089012b4ce00000474089ff43f280000047408afc362400000047408bf9507100000047408cfb291260000047408dfde0e6200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089ff43f280000047408afc362400000047408bf9507100000047408cfb291260000047408dfde0e6200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740850471af8000004740860288b0a0000047408703d944800000474088002e61e00000474089012b4ce00000474089ff43f280000047408afc362400000047408bf9507100000047408cfb291260000047408dfde0e6200000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668657481.338344,\n  \"relative_logdir\": \"tune_hp_757a3_00055_55_batch_size=16,learning_rate=0.0000,model=resnet50_2022-11-17_06-58-01\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00056\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-08,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"56_batch_size=2,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6989579812074319,\n    \"accuracy\": 42.30769230769231,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.930903673171997,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00056\",\n    \"experiment_id\": \"63bcd2e610154344a6095c579c5c01c4\",\n    \"date\": \"2022-11-17_07-30-27\",\n    \"timestamp\": 1668659427,\n    \"time_total_s\": 978.3657803535461,\n    \"pid\": 27444,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 978.3657803535461,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015648841857910156,\n    \"experiment_tag\": \"56_batch_size=2,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668659427.733814,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6989583072499332,\n      \"min\": 0.6989577855819311,\n      \"avg\": 0.6989580181589152,\n      \"last\": 0.6989579812074319,\n      \"last-5-avg\": 0.6989580203325321,\n      \"last-10-avg\": 0.698957994249132\n    },\n    \"accuracy\": {\n      \"max\": 42.30769230769231,\n      \"min\": 42.30769230769231,\n      \"avg\": 42.30769230769229,\n      \"last\": 42.30769230769231,\n      \"last-5-avg\": 42.30769230769231,\n      \"last-10-avg\": 42.307692307692314\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.832128286361694,\n      \"min\": 31.680649757385254,\n      \"avg\": 32.612192678451514,\n      \"last\": 31.930903673171997,\n      \"last-5-avg\": 31.868696784973146,\n      \"last-10-avg\": 31.96589524745941\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 978.3657803535461,\n      \"min\": 52.832128286361694,\n      \"avg\": 515.2753492911656,\n      \"last\": 978.3657803535461,\n      \"last-5-avg\": 914.6033328533173,\n      \"last-10-avg\": 834.7268999814987\n    },\n    \"time_since_restore\": {\n      \"max\": 978.3657803535461,\n      \"min\": 52.832128286361694,\n      \"avg\": 515.2753492911656,\n      \"last\": 978.3657803535461,\n      \"last-5-avg\": 914.6033328533173,\n      \"last-10-avg\": 834.7268999814987\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015648841857910156,\n      \"min\": 0.015648841857910156,\n      \"avg\": 0.015648841857910156,\n      \"last\": 0.015648841857910156,\n      \"last-5-avg\": 0.015648841857910156,\n      \"last-10-avg\": 0.015648841857910156\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe65ddd66d66d67473fe65ddd43d43d44473fe65ddd20d20d21473fe65ddd20d20d21473fe65ddd20d20d21652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe65ddd20d20d21473fe65ddd43d43d44473fe65ddcfdcfdcfe473fe65ddcfdcfdcfe473fe65ddd20d20d21473fe65ddd66d66d67473fe65ddd43d43d44473fe65ddd20d20d21473fe65ddd20d20d21473fe65ddd20d20d21652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276474045276276276276652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fd6674400000047403fe63bd800000047403fd67f1c00000047403fd67ca400000047403fee4fb4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040052190000000474040070a1200000047403fff8dd40000004740400a5a4a00000047404012147000000047403fd6674400000047403fe63bd800000047403fd67f1c00000047403fd67ca400000047403fee4fb4000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a96e0e3e0000047408b9612c2a0000047408c94c6bb80000047408d937aa0a0000047408e92ed1e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408595f9ae600000474086966a4f8000004740879666be200000474088970c62c00000474089982da9c0000047408a96e0e3e0000047408b9612c2a0000047408c94c6bb80000047408d937aa0a0000047408e92ed1e400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a96e0e3e0000047408b9612c2a0000047408c94c6bb80000047408d937aa0a0000047408e92ed1e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408595f9ae600000474086966a4f8000004740879666be200000474088970c62c00000474089982da9c0000047408a96e0e3e0000047408b9612c2a0000047408c94c6bb80000047408d937aa0a0000047408e92ed1e400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000473f90064000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668658445.4471092,\n  \"relative_logdir\": \"tune_hp_757a3_00056_56_batch_size=2,learning_rate=0.0000,model=resnet50_2022-11-17_07-14-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00057\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-08,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"57_batch_size=4,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6997645451472356,\n    \"accuracy\": 46.58119658119658,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.94564986228943,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00057\",\n    \"experiment_id\": \"0e415d9c6b7548d7af4350b847e4ff1e\",\n    \"date\": \"2022-11-17_07-46-40\",\n    \"timestamp\": 1668660400,\n    \"time_total_s\": 967.9814071655273,\n    \"pid\": 26740,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 967.9814071655273,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.01561737060546875,\n    \"experiment_tag\": \"57_batch_size=4,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668660400.0579731,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6997649363982372,\n      \"min\": 0.6997645451472356,\n      \"avg\": 0.6997647059948694,\n      \"last\": 0.6997645451472356,\n      \"last-5-avg\": 0.699764610355736,\n      \"last-10-avg\": 0.6997646690433861\n    },\n    \"accuracy\": {\n      \"max\": 46.58119658119658,\n      \"min\": 46.58119658119658,\n      \"avg\": 46.58119658119655,\n      \"last\": 46.58119658119658,\n      \"last-5-avg\": 46.58119658119658,\n      \"last-10-avg\": 46.581196581196586\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.57053470611572,\n      \"min\": 31.602802276611328,\n      \"avg\": 32.26604690551757,\n      \"last\": 31.94564986228943,\n      \"last-5-avg\": 31.954491949081422,\n      \"last-10-avg\": 32.120514917373654\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 967.9814071655273,\n      \"min\": 34.57053470611572,\n      \"avg\": 501.1421078602473,\n      \"last\": 967.9814071655273,\n      \"last-5-avg\": 904.1849524021148,\n      \"last-10-avg\": 823.9122923851013\n    },\n    \"time_since_restore\": {\n      \"max\": 967.9814071655273,\n      \"min\": 34.57053470611572,\n      \"avg\": 501.1421078602473,\n      \"last\": 967.9814071655273,\n      \"last-5-avg\": 904.1849524021148,\n      \"last-10-avg\": 823.9122923851013\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.01561737060546875,\n      \"min\": 0.01561737060546875,\n      \"avg\": 0.01561737060546875,\n      \"last\": 0.01561737060546875,\n      \"last-5-avg\": 0.01561737060546875,\n      \"last-10-avg\": 0.01561737060546875\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe66478c08c08c1473fe66478e38e38e4473fe66478e38e38e4473fe664789d89d89e473fe664789d89d89e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe664792992992a473fe66478e38e38e4473fe66478e38e38e4473fe664792992992a473fe66478e38e38e4473fe66478c08c08c1473fe66478e38e38e4473fe66478e38e38e4473fe664789d89d89e473fe664789d89d89e652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400908e60000004740400d30da00000047403fdce6c800000047403fca4f8800000047403ff2161c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474040295cc600000047404027df0a000000474040094a1e0000004740404188720000004740401b53fe0000004740400908e60000004740400d30da00000047403fdce6c800000047403fca4f8800000047403ff2161c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a423c7b00000047408b430f88a0000047408c41f6bee0000047408d40493b20000047408e3fd9ec000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408538cb932000004740863b4983c000004740873bde25a000004740883ff6acc0000047408941abeca0000047408a423c7b00000047408b430f88a0000047408c41f6bee0000047408d40493b20000047408e3fd9ec000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a423c7b00000047408b430f88a0000047408c41f6bee0000047408d40493b20000047408e3fd9ec000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408538cb932000004740863b4983c000004740873bde25a000004740883ff6acc0000047408941abeca0000047408a423c7b00000047408b430f88a0000047408c41f6bee0000047408d40493b20000047408e3fd9ec000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000473f8ffc0000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668659428.1868637,\n  \"relative_logdir\": \"tune_hp_757a3_00057_57_batch_size=4,learning_rate=0.0000,model=resnet50_2022-11-17_07-30-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00058\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-08,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"58_batch_size=8,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6956399118798411,\n    \"accuracy\": 51.28205128205128,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.63388466835022,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00058\",\n    \"experiment_id\": \"c68509fa91924ba3921e1e1bdccd5174\",\n    \"date\": \"2022-11-17_08-02-43\",\n    \"timestamp\": 1668661363,\n    \"time_total_s\": 958.7379560470581,\n    \"pid\": 18828,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 958.7379560470581,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"58_batch_size=8,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668661363.248012,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6956399770883414,\n      \"min\": 0.6956397162543403,\n      \"avg\": 0.6956398336296405,\n      \"last\": 0.6956399118798411,\n      \"last-5-avg\": 0.6956398727547409,\n      \"last-10-avg\": 0.6956398531921908\n    },\n    \"accuracy\": {\n      \"max\": 51.28205128205128,\n      \"min\": 51.28205128205128,\n      \"avg\": 51.28205128205127,\n      \"last\": 51.28205128205128,\n      \"last-5-avg\": 51.282051282051285,\n      \"last-10-avg\": 51.282051282051285\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.656054735183716,\n      \"min\": 31.570735216140747,\n      \"avg\": 31.957931868235267,\n      \"last\": 31.63388466835022,\n      \"last-5-avg\": 31.72535800933838,\n      \"last-10-avg\": 31.793309879302978\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 958.7379560470581,\n      \"min\": 34.656054735183716,\n      \"avg\": 497.5497843901316,\n      \"last\": 958.7379560470581,\n      \"last-5-avg\": 895.3337369918823,\n      \"last-10-avg\": 815.8805560111999\n    },\n    \"time_since_restore\": {\n      \"max\": 958.7379560470581,\n      \"min\": 34.656054735183716,\n      \"avg\": 497.5497843901316,\n      \"last\": 958.7379560470581,\n      \"last-5-avg\": 895.3337369918823,\n      \"last-10-avg\": 815.8805560111999\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe642ae7ee7ee7f473fe642aea1ea1ea2473fe642ae7ee7ee7f473fe642ae7ee7ee7f473fe642aea1ea1ea2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe642aea1ea1ea2473fe642ae7ee7ee7f473fe642ae5be5be5c473fe642ae5be5be5c473fe642ae7ee7ee7f473fe642ae7ee7ee7f473fe642aea1ea1ea2473fe642ae7ee7ee7f473fe642ae7ee7ee7f473fe642aea1ea1ea2652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403faa180400000047403fc6466800000047403ff36ad800000047403f9a65c800000047403fa24644000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403feaabd000000047403fea164000000047403fba3f5000000047403ff0f7c000000047403fce712000000047403faa180400000047403fc6466800000047403ff36ad800000047403f9a65c800000047403fa24644000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089fe346b20000047408afc669e60000047408bfc01f520000047408cf8d52360000047408df5e755800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408505c5b780000047408605166980000047408702e86400000047408802702200000047408900e3ab000000474089fe346b20000047408afc669e60000047408bfc01f520000047408cf8d52360000047408df5e755800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089fe346b20000047408afc669e60000047408bfc01f520000047408cf8d52360000047408df5e755800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408505c5b780000047408605166980000047408702e86400000047408802702200000047408900e3ab000000474089fe346b20000047408afc669e60000047408bfc01f520000047408cf8d52360000047408df5e755800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668660400.6049623,\n  \"relative_logdir\": \"tune_hp_757a3_00058_58_batch_size=8,learning_rate=0.0000,model=resnet50_2022-11-17_07-46-40\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00059\",\n  \"config\": {\n    \"learning_rate\": 1e-08,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-08,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"59_batch_size=16,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6855939555371928,\n    \"accuracy\": 43.58974358974359,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.01089954376221,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00059\",\n    \"experiment_id\": \"ff3d41f82ddc4643b08e13afc919d83a\",\n    \"date\": \"2022-11-17_08-18-45\",\n    \"timestamp\": 1668662325,\n    \"time_total_s\": 957.3089663982391,\n    \"pid\": 27140,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-08,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 957.3089663982391,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"59_batch_size=16,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668662325.1496296,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6855940859541934,\n      \"min\": 0.6855938903286926,\n      \"avg\": 0.6855939990095263,\n      \"last\": 0.6855939555371928,\n      \"last-5-avg\": 0.6855939685788929,\n      \"last-10-avg\": 0.6855939816205929\n    },\n    \"accuracy\": {\n      \"max\": 43.58974358974359,\n      \"min\": 43.58974358974359,\n      \"avg\": 43.58974358974361,\n      \"last\": 43.58974358974359,\n      \"last-5-avg\": 43.58974358974359,\n      \"last-10-avg\": 43.58974358974359\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.01871418952942,\n      \"min\": 31.41515350341797,\n      \"avg\": 31.910298879941305,\n      \"last\": 32.01089954376221,\n      \"last-5-avg\": 32.228006553649905,\n      \"last-10-avg\": 32.153394150733945\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 957.3089663982391,\n      \"min\": 34.01871418952942,\n      \"avg\": 493.72297211488086,\n      \"last\": 957.3089663982391,\n      \"last-5-avg\": 892.926559972763,\n      \"last-10-avg\": 812.4217939615249\n    },\n    \"time_since_restore\": {\n      \"max\": 957.3089663982391,\n      \"min\": 34.01871418952942,\n      \"avg\": 493.72297211488086,\n      \"last\": 957.3089663982391,\n      \"last-5-avg\": 892.926559972763,\n      \"last-10-avg\": 812.4217939615249\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe5f062df2df2df473fe5f062bc2bc2bc473fe5f06299299299473fe5f062df2df2df473fe5f062bc2bc2bc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5f062df2df2df473fe5f062bc2bc2bc473fe5f062bc2bc2bc473fe5f062df2df2df473fe5f062df2df2df473fe5f062df2df2df473fe5f062bc2bc2bc473fe5f06299299299473fe5f062df2df2df473fe5f062bc2bc2bc652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8474045cb7cb7cb7cb8652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740403107880000004740400d09b60000004740401543740000004740403d32be000000474040016528000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fdecee800000047403fee35480000004740402cd8c20000004740402bd6ee00000047403fe673a40000004740403107880000004740400d09b60000004740401543740000004740403d32be000000474040016528000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089e46a7260000047408ae53b0dc0000047408be68f4500000047408cea6270e0000047408dea78c3600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084dd29b7800000474085dc9b61c00000474086df68ede00000474087e2265cc00000474088e159f9e00000474089e46a7260000047408ae53b0dc0000047408be68f4500000047408cea6270e0000047408dea78c3600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474089e46a7260000047408ae53b0dc0000047408be68f4500000047408cea6270e0000047408dea78c3600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474084dd29b7800000474085dc9b61c00000474086df68ede00000474087e2265cc00000474088e159f9e00000474089e46a7260000047408ae53b0dc0000047408be68f4500000047408cea6270e0000047408dea78c3600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668661363.9512892,\n  \"relative_logdir\": \"tune_hp_757a3_00059_59_batch_size=16,learning_rate=0.0000,model=resnet50_2022-11-17_08-02-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00060\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 2,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 2,\n    \"learning_rate\": 1e-15,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"60_batch_size=2,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6922568948859842,\n    \"accuracy\": 49.572649572649574,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.13355755805969,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00060\",\n    \"experiment_id\": \"54ba4559bc61436a8669955b93ec4771\",\n    \"date\": \"2022-11-17_08-35-11\",\n    \"timestamp\": 1668663311,\n    \"time_total_s\": 981.8890919685364,\n    \"pid\": 26072,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 2,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 981.8890919685364,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"60_batch_size=2,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668663311.3189113,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6922570253029848,\n      \"min\": 0.6922566340519831,\n      \"avg\": 0.6922568188094005,\n      \"last\": 0.6922568948859842,\n      \"last-5-avg\": 0.6922568688025841,\n      \"last-10-avg\": 0.692256842719184\n    },\n    \"accuracy\": {\n      \"max\": 49.572649572649574,\n      \"min\": 49.572649572649574,\n      \"avg\": 49.572649572649574,\n      \"last\": 49.572649572649574,\n      \"last-5-avg\": 49.572649572649574,\n      \"last-10-avg\": 49.57264957264958\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.89016914367676,\n      \"min\": 31.742565870285034,\n      \"avg\": 32.7296363989512,\n      \"last\": 32.13355755805969,\n      \"last-5-avg\": 32.119392204284665,\n      \"last-10-avg\": 32.132090425491334\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 981.8890919685364,\n      \"min\": 52.89016914367676,\n      \"avg\": 516.4878758827845,\n      \"last\": 981.8890919685364,\n      \"last-5-avg\": 917.679354763031,\n      \"last-10-avg\": 837.2895056486129\n    },\n    \"time_since_restore\": {\n      \"max\": 981.8890919685364,\n      \"min\": 52.89016914367676,\n      \"avg\": 516.4878758827845,\n      \"last\": 981.8890919685364,\n      \"last-5-avg\": 917.679354763031,\n      \"last-10-avg\": 837.2895056486129\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe626f7a87a87a8473fe626f811811812473fe626f7ee7ee7ee473fe626f7cb7cb7cb473fe626f7ee7ee7ee652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe626f7a87a87a8473fe626f834834835473fe626f7a87a87a8473fe626f785785785473fe626f7cb7cb7cb473fe626f7a87a87a8473fe626f811811812473fe626f7ee7ee7ee473fe626f7cb7cb7cb473fe626f7ee7ee7ee652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95474048c94c94c94c95652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400f099200000047404025dc6a00000047403fee86600000004740400f27a200000047404011186a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ff64dc80000004740401d22ce0000004740401716c00000004740400548340000004740402801860000004740400f099200000047404025dc6a00000047403fee86600000004740400f27a200000047404011186a000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408aab46e1e0000047408bada4a880000047408cad18db80000047408dae0b55a0000047408eaf1cdc400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085a43e14400000474086a61041200000474087a781ad200000474088a7d630600000474089aa5648c0000047408aab46e1e0000047408bada4a880000047408cad18db80000047408dae0b55a0000047408eaf1cdc400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408aab46e1e0000047408bada4a880000047408cad18db80000047408dae0b55a0000047408eaf1cdc400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474085a43e14400000474086a61041200000474087a781ad200000474088a7d630600000474089aa5648c0000047408aab46e1e0000047408bada4a880000047408cad18db80000047408dae0b55a0000047408eaf1cdc400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668662325.2589786,\n  \"relative_logdir\": \"tune_hp_757a3_00060_60_batch_size=2,learning_rate=0.0000,model=resnet50_2022-11-17_08-18-45\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00061\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 4,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 4,\n    \"learning_rate\": 1e-15,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"61_batch_size=4,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6987683548886552,\n    \"accuracy\": 51.28205128205128,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.20435333251953,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00061\",\n    \"experiment_id\": \"649b21f010794cd28db86200a771820d\",\n    \"date\": \"2022-11-17_08-51-20\",\n    \"timestamp\": 1668664280,\n    \"time_total_s\": 964.4700820446014,\n    \"pid\": 13456,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 4,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 964.4700820446014,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.015622377395629883,\n    \"experiment_tag\": \"61_batch_size=4,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668664280.598126,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6987683548886552,\n      \"min\": 0.6987680288461539,\n      \"avg\": 0.6987682027354877,\n      \"last\": 0.6987683548886552,\n      \"last-5-avg\": 0.6987682505550548,\n      \"last-10-avg\": 0.6987682049091045\n    },\n    \"accuracy\": {\n      \"max\": 51.28205128205128,\n      \"min\": 51.28205128205128,\n      \"avg\": 51.28205128205127,\n      \"last\": 51.28205128205128,\n      \"last-5-avg\": 51.282051282051285,\n      \"last-10-avg\": 51.282051282051285\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 35.02659201622009,\n      \"min\": 31.739990234375,\n      \"avg\": 32.149002734820044,\n      \"last\": 32.20435333251953,\n      \"last-5-avg\": 32.05331449508667,\n      \"last-10-avg\": 32.078639888763426\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 964.4700820446014,\n      \"min\": 35.02659201622009,\n      \"avg\": 499.4603560924529,\n      \"last\": 964.4700820446014,\n      \"last-5-avg\": 900.4158581733703,\n      \"last-10-avg\": 820.0994182825089\n    },\n    \"time_since_restore\": {\n      \"max\": 964.4700820446014,\n      \"min\": 35.02659201622009,\n      \"avg\": 499.4603560924529,\n      \"last\": 964.4700820446014,\n      \"last-5-avg\": 900.4158581733703,\n      \"last-10-avg\": 820.0994182825089\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.015622377395629883,\n      \"min\": 0.015622377395629883,\n      \"avg\": 0.015622377395629883,\n      \"last\": 0.015622377395629883,\n      \"last-5-avg\": 0.015622377395629883,\n      \"last-10-avg\": 0.015622377395629883\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe65c4f0af0af0b473fe65c4f0af0af0b473fe65c4f50f50f51473fe65c4f50f50f51473fe65c4f73f73f74652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe65c4ee7ee7ee8473fe65c4f2df2df2e473fe65c4f2df2df2e473fe65c4ec4ec4ec5473fe65c4f2df2df2e473fe65c4f0af0af0b473fe65c4f0af0af0b473fe65c4f50f50f51473fe65c4f50f50f51473fe65c4f73f73f74652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41474049a41a41a41a41652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ffe3ba800000047404040aac000000047403fbe44bc00000047403fd217b40000004740401a2840000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403fde18d400000047403fe266f40000004740403009720000004740400d23e2000000474040251c7400000047403ffe3ba800000047404040aac000000047403fbe44bc00000047403fd217b40000004740401a2840000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2192a6e0000047408b259d52e0000047408c238f78c0000047408d22203660000047408e23c2ba600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740851c68f58000004740861b7c2d2000004740871e7cc44000004740881f4f0260000047408921a0c9a0000047408a2192a6e0000047408b259d52e0000047408c238f78c0000047408d22203660000047408e23c2ba600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a2192a6e0000047408b259d52e0000047408c238f78c0000047408d22203660000047408e23c2ba600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740851c68f58000004740861b7c2d2000004740871e7cc44000004740881f4f0260000047408921a0c9a0000047408a2192a6e0000047408b259d52e0000047408c238f78c0000047408d22203660000047408e23c2ba600000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000473f8ffea000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668663312.1312206,\n  \"relative_logdir\": \"tune_hp_757a3_00061_61_batch_size=4,learning_rate=0.0000,model=resnet50_2022-11-17_08-35-12\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00062\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 8,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"learning_rate\": 1e-15,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"62_batch_size=8,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.6996839474409055,\n    \"accuracy\": 46.58119658119658,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 32.7132933139801,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00062\",\n    \"experiment_id\": \"4842f6ac9f284730b7a558347f9faaed\",\n    \"date\": \"2022-11-17_09-07-39\",\n    \"timestamp\": 1668665259,\n    \"time_total_s\": 973.8438711166382,\n    \"pid\": 25496,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 8,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 973.8438711166382,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"62_batch_size=8,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668665259.1444852,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6996842082749065,\n      \"min\": 0.6996838822324052,\n      \"avg\": 0.6996840278647227,\n      \"last\": 0.6996839474409055,\n      \"last-5-avg\": 0.6996839996077056,\n      \"last-10-avg\": 0.6996839996077057\n    },\n    \"accuracy\": {\n      \"max\": 46.58119658119658,\n      \"min\": 46.58119658119658,\n      \"avg\": 46.58119658119655,\n      \"last\": 46.58119658119658,\n      \"last-5-avg\": 46.58119658119658,\n      \"last-10-avg\": 46.581196581196586\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.9632625579834,\n      \"min\": 31.72756314277649,\n      \"avg\": 32.46146237055461,\n      \"last\": 32.7132933139801,\n      \"last-5-avg\": 32.46814303398132,\n      \"last-10-avg\": 32.4399836063385\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 973.8438711166382,\n      \"min\": 34.9632625579834,\n      \"avg\": 503.85772184530896,\n      \"last\": 973.8438711166382,\n      \"last-5-avg\": 908.8102734088898,\n      \"last-10-avg\": 827.746455526352\n    },\n    \"time_since_restore\": {\n      \"max\": 973.8438711166382,\n      \"min\": 34.9632625579834,\n      \"avg\": 503.85772184530896,\n      \"last\": 973.8438711166382,\n      \"last-5-avg\": 908.8102734088898,\n      \"last-10-avg\": 827.746455526352\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe663cf96f96f97473fe663cfb9fb9fba473fe663cfb9fb9fba473fe663cfdcfdcfdd473fe663cf96f96f97652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe663cfdcfdcfdd473fe663cfb9fb9fba473fe663cf73f73f74473fe663cfb9fb9fba473fe663cfb9fb9fba473fe663cf96f96f97473fe663cfb9fb9fba473fe663cfb9fb9fba473fe663cfdcfdcfdd473fe663cf96f96f97652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a64740474a64a64a64a6652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740405753f00000004740400ac51e0000004740402d1c2a000000474040411a240000004740405b4d32000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740402b07ea0000004740404b06080000004740403175080000004740402107900000004740403f06bc0000004740405753f00000004740400ac51e0000004740402d1c2a000000474040411a240000004740405b4d32000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a617bb5a0000047408b62280780000047408c64f9ca20000047408d690b6c60000047408e6ec03f800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854e3de0e0000047408652ee41600000474087560591e0000047408858160ae000004740895c0676a0000047408a617bb5a0000047408b62280780000047408c64f9ca20000047408d690b6c60000047408e6ec03f800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a617bb5a0000047408b62280780000047408c64f9ca20000047408d690b6c60000047408e6ec03f800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740854e3de0e0000047408652ee41600000474087560591e0000047408858160ae000004740895c0676a0000047408a617bb5a0000047408b62280780000047408c64f9ca20000047408d690b6c60000047408e6ec03f800000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668664281.3324487,\n  \"relative_logdir\": \"tune_hp_757a3_00062_62_batch_size=8,learning_rate=0.0000,model=resnet50_2022-11-17_08-51-21\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_hp\",\n  \"trial_id\": \"757a3_00063\",\n  \"config\": {\n    \"learning_rate\": 1e-15,\n    \"batch_size\": 16,\n    \"model\": \"resnet50\"\n  },\n  \"local_dir\": \"C:\\\\Users\\\\MohammedSB\\\\ray_results\\\\tune_hp_2022-11-16_16-06-18\",\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"learning_rate\": 1e-15,\n    \"model\": \"resnet50\"\n  },\n  \"experiment_tag\": \"63_batch_size=16,learning_rate=0.0000,model=resnet50\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"loss\": 0.695287590352898,\n    \"accuracy\": 47.008547008547005,\n    \"f1_score\": 0.0,\n    \"time_this_iter_s\": 31.86196255683899,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"757a3_00063\",\n    \"experiment_id\": \"371200a8e0d4408fa40a0350c1ec61c3\",\n    \"date\": \"2022-11-17_09-23-45\",\n    \"timestamp\": 1668666225,\n    \"time_total_s\": 961.996178150177,\n    \"pid\": 26204,\n    \"hostname\": \"DESKTOP-G9R02TV\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 1e-15,\n      \"batch_size\": 16,\n      \"model\": \"resnet50\"\n    },\n    \"time_since_restore\": 961.996178150177,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"warmup_time\": 0.0,\n    \"experiment_tag\": \"63_batch_size=16,learning_rate=0.0000,model=resnet50\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1668666225.8270912,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.6952876555613983,\n      \"min\": 0.6952875251443977,\n      \"avg\": 0.6952876033945976,\n      \"last\": 0.695287590352898,\n      \"last-5-avg\": 0.695287564269498,\n      \"last-10-avg\": 0.6952875707903479\n    },\n    \"accuracy\": {\n      \"max\": 47.008547008547005,\n      \"min\": 47.008547008547005,\n      \"avg\": 47.008547008547026,\n      \"last\": 47.008547008547005,\n      \"last-5-avg\": 47.008547008547005,\n      \"last-10-avg\": 47.008547008547005\n    },\n    \"f1_score\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.13404035568237,\n      \"min\": 31.508955478668213,\n      \"avg\": 32.06653927167257,\n      \"last\": 31.86196255683899,\n      \"last-5-avg\": 31.73629117012024,\n      \"last-10-avg\": 31.750057339668274\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 961.996178150177,\n      \"min\": 34.13404035568237,\n      \"avg\": 499.7086369355519,\n      \"last\": 961.996178150177,\n      \"last-5-avg\": 898.4807241439819,\n      \"last-10-avg\": 819.0939692258835\n    },\n    \"time_since_restore\": {\n      \"max\": 961.996178150177,\n      \"min\": 34.13404035568237,\n      \"avg\": 499.7086369355519,\n      \"last\": 961.996178150177,\n      \"last-5-avg\": 898.4807241439819,\n      \"last-10-avg\": 819.0939692258835\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe63fcbc2bc2bc3473fe63fcb9fb9fba0473fe63fcb9fb9fba0473fe63fcbc2bc2bc3473fe63fcbc2bc2bc3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe63fcbc2bc2bc3473fe63fcbc2bc2bc3473fe63fcbc2bc2bc3473fe63fcbc2bc2bc3473fe63fcb9fb9fba0473fe63fcbc2bc2bc3473fe63fcb9fb9fba0473fe63fcb9fb9fba0473fe63fcbc2bc2bc3473fe63fcbc2bc2bc3652e\"\n      }\n    },\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811474047811811811811652e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403fbf22f000000047403f9648a000000047403fea433800000047403f921b8800000047403fdca994000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9a1b1000000047403fe4694800000047403fd29bc400000047403f824ae800000047403ffe46ac00000047403fbf22f000000047403f9648a000000047403fea433800000047403f921b8800000047403fdca994000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a187da4a0000047408b152fe9a0000047408c14820360000047408d1112dfa0000047408e0ff82c400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408520c7d82000004740861feb226000004740871e80008000004740881a9257c000004740891a848d20000047408a187da4a0000047408b152fe9a0000047408c14820360000047408d1112dfa0000047408e0ff82c400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a187da4a0000047408b152fe9a0000047408c14820360000047408d1112dfa0000047408e0ff82c400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847408520c7d82000004740861feb226000004740871e80008000004740881a9257c000004740891a848d20000047408a187da4a0000047408b152fe9a0000047408c14820360000047408d1112dfa0000047408e0ff82c400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1668665259.9727309,\n  \"relative_logdir\": \"tune_hp_757a3_00063_63_batch_size=16,learning_rate=0.0000,model=resnet50_2022-11-17_09-07-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"tune_hp_2022-11-16_16-06-18\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 17,
    "_metric": null,
    "_total_time": 64002.857518196106,
    "_iteration": 13679,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "C:\\Users\\MohammedSB\\ray_results\\tune_hp_2022-11-16_16-06-18",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1668603978.3217142,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-11-16_16-06-18",
    "checkpoint_file": "C:\\Users\\MohammedSB\\ray_results\\tune_hp_2022-11-16_16-06-18\\experiment_state-2022-11-16_16-06-18.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1668603978.3217142,
    "timestamp": 1668666219.2495809
  }
}