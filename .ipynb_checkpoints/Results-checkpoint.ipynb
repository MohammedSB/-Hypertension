{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/MohammedSB/Desktop/projects/Hypertension/Requirements.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\\\MohammedSB\\\\Fundus\\\\\"\n",
    "CSV_PATH = {\"HTNPath\": PATH + r\"HTN\", \"NonHTNPath\": PATH + \"NonHTN\"}\n",
    "\n",
    "MODELS_PATH = r\"C:\\Users\\MohammedSB\\Desktop\\projects\\Hypertension\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize((500, 500)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.3675, 0.1760, 0.1047], std=[0.2289, 0.1180, 0.0748]),\n",
    "])\n",
    "\n",
    "test_dataset = HypertensionDataset(CSV_PATH, test_set, test_transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageModel Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IM_PATH = MODELS_PATH + r\"\\ImageModel_O.pth\"\n",
    "\n",
    "model = get_densenet201(device=device, freeze=True, with_mlp=True)\n",
    "model.load_state_dict(torch.load(IM_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": model,\n",
    "    \"tabular_model\": None,\n",
    "    \"fusion_model\": None\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.to(device).parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Perform bootstrap on the testset\n",
    "\n",
    "N = 2000\n",
    "num_samples = len(test_dataset)\n",
    "trues, probs = [], []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "\n",
    "    sampler = torch.utils.data.RandomSampler(test_dataset, replacement=True, num_samples=num_samples)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, sampler=sampler)\n",
    "    \n",
    "    metrics = test(models=models, criterion=criterion, test_loader=test_loader, device=device, show_output=False)\n",
    "    y_true = metrics[\"y_true\"].squeeze(1).numpy()\n",
    "    y_prob = metrics[\"y_prob\"].squeeze(1).numpy()\n",
    "        \n",
    "    trues.append(y_true) \n",
    "    probs.append(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "for i in range(N):\n",
    "    fpr, tpr, thresholds = roc_curve(trues[i], probs[i])\n",
    "    \n",
    "    f1_scores.append(f1_score(trues[i], probs[i]>=0.5))\n",
    "    auc_scores.append(auc(fpr, tpr))\n",
    "    precision_scores.append(precision_score(trues[i], probs[i]>=0.5))\n",
    "    recall_scores.append(recall_score(trues[i], probs[i]>=0.5))\n",
    "    specificity_scores.append(recall_score(trues[i], probs[i]>=0.5, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: [0.79151943 0.79151943]\n",
      "auroc: [0.81966705 0.81966705]\n",
      "precision: [0.7 0.7]\n",
      "recall: [0.91056911 0.91056911]\n",
      "specificity: [0.54285714 0.54285714]\n"
     ]
    }
   ],
   "source": [
    "print(f\"f1: {np.percentile(f1_scores, [2.5, 97.5])}\") \n",
    "print(f\"auroc: {np.percentile(auc_scores, [2.5, 97.5])}\") \n",
    "print(f\"precision: {np.percentile(precision_scores, [2.5, 97.5])}\") \n",
    "print(f\"recall: {np.percentile(recall_scores, [2.5, 97.5])}\") \n",
    "print(f\"specificity: {np.percentile(specificity_scores, [2.5, 97.5])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabularModel Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TM_PATH = MODELS_PATH + r\"\\TabularModel_O.pth\"\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(TM_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": None,\n",
    "    \"tabular_model\": model,\n",
    "    \"fusion_model\": None\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.to(device).parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bootstrap on the testset\n",
    "\n",
    "N = 2000\n",
    "num_samples = len(test_dataset)\n",
    "auc_scores = []\n",
    "f1_scores = []\n",
    "trues, preds = [], []\n",
    "\n",
    "for i in range(N):\n",
    "\n",
    "    sampler = torch.utils.data.RandomSampler(test_dataset, replacement=True, num_samples=num_samples)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, sampler=sampler)\n",
    "    \n",
    "    metrics = test(models=models, criterion=criterion, test_loader=test_loader, device=device)\n",
    "    y_true = metrics[\"y_true\"].squeeze(1).numpy()\n",
    "    y_prob = metrics[\"y_prob\"].squeeze(1).numpy()\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    \n",
    "    f1_one_epoch = metrics['F1 Score']\n",
    "    auc_one_epoch = auc(fpr, tpr)\n",
    "    \n",
    "    auc_scores.append(auc_one_epoch)\n",
    "    f1_scores.append(f1_one_epoch)\n",
    "    \n",
    "    trues.append(y_true) \n",
    "    preds.append(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
