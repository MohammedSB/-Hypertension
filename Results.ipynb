{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/MohammedSB/Desktop/projects/Hypertension/Requirements.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\\\MohammedSB\\\\Fundus\\\\\"\n",
    "CSV_PATH = {\"HTNPath\": PATH + r\"HTN\", \"NonHTNPath\": PATH + \"NonHTN\"}\n",
    "\n",
    "MODELS_PATH = r\"C:\\Users\\MohammedSB\\Desktop\\projects\\Hypertension\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((500, 500)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.3675, 0.1760, 0.1047], std=[0.2289, 0.1180, 0.0748]),\n",
    "])\n",
    "\n",
    "train_dataset = HypertensionDataset(CSV_PATH, train_set, train_transform=transform)\n",
    "test_dataset = HypertensionDataset(CSV_PATH, test_set, test_transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(N, trues, probs, threshold=0.5):\n",
    "    \n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    pr_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    specificity_scores = []\n",
    "\n",
    "    for i in range(N):\n",
    "        fpr, tpr, _ = roc_curve(trues[i], probs[i])\n",
    "        precision, recall, _ = precision_recall_curve(trues[i], probs[i])\n",
    "\n",
    "        f1_scores.append(f1_score(trues[i], np.array(probs[i])>=threshold))\n",
    "        auc_scores.append(auc(fpr, tpr))\n",
    "        pr_scores.append(auc(recall, precision))\n",
    "        precision_scores.append(precision_score(trues[i], np.array(probs[i])>=threshold))\n",
    "        recall_scores.append(recall_score(trues[i], np.array(probs[i])>=threshold))\n",
    "        specificity_scores.append(recall_score(trues[i], np.array(probs[i])>=threshold, pos_label=0))\n",
    "    \n",
    "    print(f\"f1: {[round(s, 3) for s in np.percentile(f1_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(f1_scores, [2.5, 97.5]).mean(), 3)}\") \n",
    "    print(f\"auroc: {[round(s, 3) for s in np.percentile(auc_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(auc_scores, [2.5, 97.5]).mean(), 3)}\") \n",
    "    print(f\"auprc: {[round(s, 3) for s in np.percentile(pr_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(pr_scores, [2.5, 97.5]).mean(), 3)}\") \n",
    "    print(f\"precision: {[round(s, 3) for s in np.percentile(precision_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(precision_scores, [2.5, 97.5]).mean(), 3)}\") \n",
    "    print(f\"recall: {[round(s, 3) for s in np.percentile(recall_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(recall_scores, [2.5, 97.5]).mean(), 3)}\")\n",
    "    print(f\"specificity: {[round(s, 3) for s in np.percentile(specificity_scores, [2.5, 97.5])]}\",\n",
    "            f\"average: {round(np.percentile(specificity_scores, [2.5, 97.5]).mean(), 3)}\")\n",
    "    \n",
    "    \n",
    "def bootstrap(N, models, data_set, device, criterion=None, method=\"torch\"):\n",
    "    num_samples = len(data_set)\n",
    "    trues, probs = dict(), dict()\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "\n",
    "        if method == \"torch\":\n",
    "            sampler = torch.utils.data.RandomSampler(data_set, replacement=True, num_samples=num_samples)\n",
    "            data_loader = DataLoader(data_set, batch_size=8, sampler=sampler)\n",
    "\n",
    "            metrics = test(models=models, criterion=criterion, test_loader=data_loader, device=device, show_output=False)\n",
    "            y_true = metrics[\"y_true\"].squeeze(1).numpy()\n",
    "            y_prob = metrics[\"y_prob\"].squeeze(1).numpy()\n",
    "\n",
    "            trues[i] = y_true.tolist()\n",
    "            probs[i] = y_prob.tolist()\n",
    "        elif method == \"sklearn\":\n",
    "            bootstrapped_data = resample(data_set, replace=True, n_samples=num_samples)\n",
    "            x, y = bootstrapped_data[:, :-1], bootstrapped_data[:, -1]\n",
    "            probas = boost.predict_proba(x)[:, 1]\n",
    "            \n",
    "            trues[i] = y.tolist()\n",
    "            probs[i] = probas.tolist()\n",
    "    \n",
    "    return trues, probs\n",
    "\n",
    "\n",
    "def bootstrap_session(N, models, data_set, device, criterion, show_results=True, method=\"torch\", loc=None):\n",
    "    \n",
    "    trues, probs = bootstrap(N, models, data_set, device, criterion, method=method)\n",
    "    \n",
    "    if show_results:\n",
    "        print(\"Results:\")\n",
    "        calculate_results(N, trues, probs, 0.5) \n",
    "    \n",
    "    if loc is not None:\n",
    "        results = dict()\n",
    "        results[\"true\"] = trues\n",
    "        results[\"prob\"] = probs\n",
    "        with open(loc, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        return trues, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "\n",
    "FM_PATH = MODELS_PATH + r\"\\FundusModel.pth\"\n",
    "DM_PATH = MODELS_PATH + r\"\\DemographicFCNN.pth\"\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FundusModel Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = get_densenet201(device=device, freeze=True, with_mlp=True)\n",
    "image_model.load_state_dict(torch.load(FM_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": image_model,\n",
    "    \"tabular_model\": None,\n",
    "    \"fusion_model\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FundusModel***\n",
      "f1: [0.677, 0.789] average: 0.733\n",
      "auroc: [0.705, 0.828] average: 0.766\n",
      "auprc: [0.641, 0.824] average: 0.732\n",
      "precision: [0.54, 0.687] average: 0.613\n",
      "recall: [0.864, 0.965] average: 0.914\n",
      "specificity: [0.333, 0.518] average: 0.426\n"
     ]
    }
   ],
   "source": [
    "print(\"***FundusModel***\")\n",
    "result_path = 'Results/FundusModel.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_dataset, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DemographicModels Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_set[[\"Age\", \"Gender\"]], train_set[\"Hypertension\"]\n",
    "test_x, test_y = test_set[[\"Age\", \"Gender\"]], test_set[\"Hypertension\"]\n",
    "\n",
    "combined_test = np.hstack([test_x, np.expand_dims(test_y, -1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+'/DemographicXGBParams.json') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "boost = xgb.XGBClassifier(**params, objective=\"binary:logistic\")\n",
    "\n",
    "boost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***DemographicXGB***\n",
      "f1: [0.677, 0.796] average: 0.736\n",
      "auroc: [0.679, 0.804] average: 0.742\n",
      "auprc: [0.531, 0.765] average: 0.648\n",
      "precision: [0.565, 0.718] average: 0.642\n",
      "recall: [0.807, 0.926] average: 0.866\n",
      "specificity: [0.426, 0.614] average: 0.52\n"
     ]
    }
   ],
   "source": [
    "print(\"***DemographicXGB***\")\n",
    "result_path = 'Results/DemographicXGB.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=boost, data_set=combined_test, device=device, criterion=criterion,\\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+'/DemographicSVMParams.json') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "svm = SVC(**params)\n",
    "\n",
    "svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***DemographicSVM***\n",
      "f1: [0.674, 0.79] average: 0.732\n",
      "auroc: [0.674, 0.802] average: 0.738\n",
      "auprc: [0.525, 0.765] average: 0.645\n",
      "precision: [0.561, 0.715] average: 0.638\n",
      "recall: [0.804, 0.925] average: 0.864\n",
      "specificity: [0.431, 0.607] average: 0.519\n"
     ]
    }
   ],
   "source": [
    "print(\"***DemographicSVM***\")\n",
    "result_path = 'Results/DemographicSVM.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=svm, data_set=combined_test, device=device, criterion=criterion, \\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "tabular_model = tabular_model.to(device)\n",
    "tabular_model.load_state_dict(torch.load(DM_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": None,\n",
    "    \"tabular_model\": tabular_model,\n",
    "    \"fusion_model\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***DemographicFCNN***\n",
      "f1: [0.677, 0.791] average: 0.734\n",
      "auroc: [0.699, 0.819] average: 0.759\n",
      "auprc: [0.65, 0.811] average: 0.73\n",
      "precision: [0.555, 0.698] average: 0.627\n",
      "recall: [0.832, 0.946] average: 0.889\n",
      "specificity: [0.388, 0.571] average: 0.48\n"
     ]
    }
   ],
   "source": [
    "print(\"***DemographicFCNN***\")\n",
    "result_path = 'Results/DemographicFCNN.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_dataset, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FusionModel Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombineFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_path = MODELS_PATH + r\"\\CombineFeatures\\DemographicPath.pth\"\n",
    "img_path = MODELS_PATH + r\"\\CombineFeatures\\FundusPath.pth\"\n",
    "fm_path = MODELS_PATH + r\"\\CombineFeatures\\FusionPath.pth\"\n",
    "\n",
    "\n",
    "tabular_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    ")\n",
    "\n",
    "image_model = get_densenet201(device=device, freeze=True, with_mlp=False, outputs=32)\n",
    "\n",
    "fusion_model = nn.Sequential(\n",
    "    nn.Linear(in_features=64, out_features=128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=128, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=16, out_features=1),\n",
    ")\n",
    "\n",
    "tabular_model, image_model, fusion_model = tabular_model.to(device).float(), image_model.to(device).float(),\\\n",
    "                                                fusion_model.to(device).float()\n",
    "\n",
    "tabular_model.load_state_dict(torch.load(tm_path))\n",
    "image_model.load_state_dict(torch.load(img_path))\n",
    "fusion_model.load_state_dict(torch.load(fm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": image_model,\n",
    "    \"tabular_model\": tabular_model,\n",
    "    \"fusion_model\": fusion_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CombineFeatures***\n",
      "f1: [0.654, 0.775] average: 0.714\n",
      "auroc: [0.735, 0.848] average: 0.791\n",
      "auprc: [0.694, 0.851] average: 0.772\n",
      "precision: [0.532, 0.681] average: 0.606\n",
      "recall: [0.815, 0.935] average: 0.875\n",
      "specificity: [0.35, 0.535] average: 0.443\n"
     ]
    }
   ],
   "source": [
    "print(\"***CombineFeatures***\")\n",
    "result_path = 'Results/CombineFeatures.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_dataset, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombineOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_path = MODELS_PATH + r\"\\CombineOutputs\\DemographicPath.pth\"\n",
    "img_path = MODELS_PATH + r\"\\CombineOutputs\\FundusPath.pth\"\n",
    "fm_path = MODELS_PATH + r\"\\CombineOutputs\\FusionPath.pth\"\n",
    "\n",
    "tabular_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "image_model = get_densenet201(device=device, freeze=True, with_mlp=True, outputs=1)\n",
    "\n",
    "fusion_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=4),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=4, out_features=1),\n",
    ")\n",
    "\n",
    "tabular_model, image_model, fusion_model = tabular_model.to(device).float(), image_model.to(device).float(),\\\n",
    "                                                fusion_model.to(device).float()\n",
    "\n",
    "tabular_model.load_state_dict(torch.load(tm_path))\n",
    "image_model.load_state_dict(torch.load(img_path))\n",
    "fusion_model.load_state_dict(torch.load(fm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": image_model,\n",
    "    \"tabular_model\": tabular_model,\n",
    "    \"fusion_model\": fusion_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CombineOutputs***\n",
      "f1: [0.655, 0.763] average: 0.709\n",
      "auroc: [0.622, 0.716] average: 0.669\n",
      "auprc: [0.749, 0.824] average: 0.787\n",
      "precision: [0.493, 0.623] average: 0.558\n",
      "recall: [0.953, 1.0] average: 0.976\n",
      "specificity: [0.164, 0.309] average: 0.237\n"
     ]
    }
   ],
   "source": [
    "print(\"***CombineOutputs***\")\n",
    "result_path = 'Results/CombineOutputs.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_dataset, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeepFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = get_densenet201(device=device, freeze=True, with_mlp=True)\n",
    "image_model.load_state_dict(torch.load(FM_PATH))\n",
    "\n",
    "image_model = image_model.to(device).float()\n",
    "\n",
    "models = {\n",
    "    \"image_model\": image_model,\n",
    "    \"tabular_model\": None,\n",
    "    \"fusion_model\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = build_tabular_dataset(models, train_dataset, method=\"keep_features\")\n",
    "\n",
    "test_x, test_y = build_tabular_dataset(models, test_dataset, method=\"keep_features\")\n",
    "test_fusion_set = InputOutputDataset(test_x, test_y)\n",
    "\n",
    "combined_test = np.hstack([test_x, np.expand_dims(test_y, -1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+ '/KeepFeatures/XGBParams.json') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "boost = xgb.XGBClassifier(**params, objective=\"binary:logistic\")\n",
    "\n",
    "boost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***KeepFeaturesXGB***\n",
      "f1: [0.667, 0.79] average: 0.728\n",
      "auroc: [0.677, 0.8] average: 0.739\n",
      "auprc: [0.523, 0.772] average: 0.647\n",
      "precision: [0.556, 0.72] average: 0.638\n",
      "recall: [0.792, 0.92] average: 0.856\n",
      "specificity: [0.42, 0.602] average: 0.511\n"
     ]
    }
   ],
   "source": [
    "print(\"***KeepFeaturesXGB***\")\n",
    "result_path = 'Results/KeepFeaturesXGB.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=boost, data_set=combined_test, device=device, criterion=criterion,\\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+ '/KeepFeatures/SVMParams.json') as f:\n",
    "    params = json.load(f)\n",
    "        \n",
    "svm = SVC(**params)\n",
    "\n",
    "svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***KeepFeaturesSVM***\n",
      "f1: [0.669, 0.787] average: 0.728\n",
      "auroc: [0.677, 0.803] average: 0.74\n",
      "auprc: [0.526, 0.771] average: 0.649\n",
      "precision: [0.558, 0.712] average: 0.635\n",
      "recall: [0.792, 0.92] average: 0.856\n",
      "specificity: [0.43, 0.608] average: 0.519\n"
     ]
    }
   ],
   "source": [
    "print(\"***KeepFeaturesSVM***\")\n",
    "result_path = 'Results/KeepFeaturesSVM.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=svm, data_set=combined_test, device=device, criterion=criterion,\\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_path = MODELS_PATH + r\"\\KeepFeatures\\FusionPath.pth\"\n",
    "\n",
    "fusion_model = nn.Sequential(\n",
    "    nn.Linear(in_features=3, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "fusion_model = fusion_model.to(device).float()\n",
    "fusion_model.load_state_dict(torch.load(fm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": None,\n",
    "    \"tabular_model\": None,\n",
    "    \"fusion_model\": fusion_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***KeepFeaturesFCNN***\n",
      "f1: [0.667, 0.78] average: 0.723\n",
      "auroc: [0.688, 0.809] average: 0.748\n",
      "auprc: [0.62, 0.79] average: 0.705\n",
      "precision: [0.549, 0.697] average: 0.623\n",
      "recall: [0.807, 0.928] average: 0.868\n",
      "specificity: [0.404, 0.575] average: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"***KeepFeaturesFCNN***\")\n",
    "result_path = 'Results/KeepFeaturesFCNN.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_fusion_set, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and Tabular model\n",
    "image_model = get_densenet201(device=device, freeze=True, with_mlp=True, outputs=1)\n",
    "\n",
    "tabular_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "image_model.load_state_dict(torch.load(FM_PATH))\n",
    "tabular_model.load_state_dict(torch.load(DM_PATH))\n",
    "\n",
    "image_model, tabular_model = image_model.to(device).float(), tabular_model.to(device).float()\n",
    "\n",
    "# load fusion model\n",
    "tabular_path = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    ")\n",
    "\n",
    "image_path = get_densenet201(device=device, freeze=True, with_mlp=False, outputs=32)\n",
    "\n",
    "fusion_path = nn.Sequential(\n",
    "    nn.Linear(in_features=64, out_features=128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=128, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=16, out_features=1),\n",
    ")\n",
    "\n",
    "image_path.load_state_dict(torch.load(MODELS_PATH + \"\\CombineFeatures\\FundusPath.pth\"))\n",
    "tabular_path.load_state_dict(torch.load(MODELS_PATH + \"\\CombineFeatures\\DemographicPath.pth\"))\n",
    "fusion_path.load_state_dict(torch.load(MODELS_PATH + \"\\CombineFeatures\\FusionPath.pth\"))\n",
    "\n",
    "tabular_path, image_path, fusion_path = tabular_path.to(device).float(), image_path.to(device).float(),\\\n",
    "                                                fusion_path.to(device).float()\n",
    "\n",
    "fusion_model = dict()\n",
    "fusion_model[\"image_path\"], fusion_model[\"tabular_path\"], fusion_model[\"fusion_path\"] = image_path, \\\n",
    "                                                                                    tabular_path, fusion_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": image_model,\n",
    "    \"tabular_model\": tabular_model,\n",
    "    \"fusion_model\": fusion_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = build_tabular_dataset(models, train_dataset, method=\"voting_features\")\n",
    "\n",
    "test_x, test_y = build_tabular_dataset(models, test_dataset, method=\"voting_features\")\n",
    "test_fusion_set = InputOutputDataset(test_x, test_y)\n",
    "\n",
    "combined_test = np.hstack([test_x, np.expand_dims(test_y, -1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+'/VotingFeatures/XGBParams.json') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "boost = xgb.XGBClassifier(**params, objective=\"binary:logistic\")\n",
    "\n",
    "boost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***VotingFeaturesXGB***\n",
      "f1: [0.645, 0.769] average: 0.707\n",
      "auroc: [0.664, 0.791] average: 0.727\n",
      "auprc: [0.617, 0.797] average: 0.707\n",
      "precision: [0.531, 0.68] average: 0.606\n",
      "recall: [0.782, 0.911] average: 0.846\n",
      "specificity: [0.373, 0.545] average: 0.459\n"
     ]
    }
   ],
   "source": [
    "print(\"***VotingFeaturesXGB***\")\n",
    "result_path = 'Results/VotingFeaturesXGB.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=boost, data_set=combined_test, device=device, criterion=criterion,\\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH+ '/KeepFeatures/SVMParams.json') as f:\n",
    "    params = json.load(f)\n",
    "        \n",
    "svm = SVC(**params)\n",
    "\n",
    "svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***VotingFeaturesSVM***\n",
      "f1: [0.64, 0.77] average: 0.705\n",
      "auroc: [0.662, 0.792] average: 0.727\n",
      "auprc: [0.625, 0.799] average: 0.712\n",
      "precision: [0.53, 0.693] average: 0.612\n",
      "recall: [0.775, 0.915] average: 0.845\n",
      "specificity: [0.372, 0.557] average: 0.464\n"
     ]
    }
   ],
   "source": [
    "print(\"***VotingFeaturesSVM***\")\n",
    "result_path = 'Results/VotingFeaturesSVM.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=svm, data_set=combined_test, device=device, criterion=criterion,\\\n",
    "                  method=\"sklearn\", loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_path = MODELS_PATH + \"\\VotingFeatures\\FusionPath.pth\"\n",
    "\n",
    "fusion_model = nn.Sequential(\n",
    "    nn.Linear(in_features=3, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=32, out_features=16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=8, out_features=1),\n",
    ")\n",
    "\n",
    "fusion_model = fusion_model.to(device).float()\n",
    "fusion_model.load_state_dict(torch.load(fm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"image_model\": None,\n",
    "    \"tabular_model\": None,\n",
    "    \"fusion_model\": fusion_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***VotingFeaturesFCNN***\n",
      "f1: [0.664, 0.776] average: 0.72\n",
      "auroc: [0.682, 0.815] average: 0.749\n",
      "auprc: [0.619, 0.798] average: 0.708\n",
      "precision: [0.525, 0.671] average: 0.598\n",
      "recall: [0.861, 0.962] average: 0.911\n",
      "specificity: [0.316, 0.5] average: 0.408\n"
     ]
    }
   ],
   "source": [
    "print(\"***VotingFeaturesFCNN***\")\n",
    "result_path = 'Results/VotingFeaturesFCNN.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    bootstrap_session(N, models=models, data_set=test_fusion_set, device=device, criterion=criterion, loc=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = nn.Sigmoid()\n",
    "\n",
    "tensored_x, tensored_y = torch.tensor(test_x), torch.tensor(test_y)\n",
    "probs = sig(tensored_x)\n",
    "\n",
    "average = torch.mean(probs, axis=1)\n",
    "\n",
    "esnemble_average = torch.stack([average, tensored_y], axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***VotingFeaturesEnsemble***\n",
      "f1: [0.661, 0.783] average: 0.722\n",
      "auroc: [0.649, 0.78] average: 0.715\n",
      "auprc: [0.557, 0.753] average: 0.655\n",
      "precision: [0.528, 0.679] average: 0.603\n",
      "recall: [0.847, 0.953] average: 0.9\n",
      "specificity: [0.333, 0.516] average: 0.425\n"
     ]
    }
   ],
   "source": [
    "print(\"***VotingFeaturesEnsemble***\")\n",
    "result_path = 'Results/VotingFeaturesEnsemble.json'\n",
    "\n",
    "if Path(os.getcwd() + \"/\" + result_path).is_file():\n",
    "    f = open(os.getcwd() + \"/\" + result_path)\n",
    "    data_json = json.load(f) \n",
    "    for y in data_json:\n",
    "        data_json[y] = {int(k):[i for i in v] for k,v in data_json[y].items()}\n",
    "    trues, probs = data_json['true'], data_json['prob'] \n",
    "    calculate_results(N, trues, probs)\n",
    "else:\n",
    "    trues, probs = dict(), dict()\n",
    "    results = dict()\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        bootstrapped_data = resample(esnemble_average, replace=True, n_samples=len(esnemble_average))\n",
    "        x, y = bootstrapped_data[:, :-1], bootstrapped_data[:, -1]\n",
    "\n",
    "        trues[i] = y.tolist()\n",
    "        probs[i] = x.tolist()\n",
    "\n",
    "    results[\"true\"] = trues\n",
    "    results[\"prob\"] = probs\n",
    "    \n",
    "    with open('Results/VotingFeaturesEnsemble.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    trues, probs = [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        trues += results[\"true\"][i]\n",
    "        probs += results[\"prob\"][i]\n",
    "\n",
    "    calculate_results(N, results['true'], results['prob'], 0.5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
